#!/usr/bin/env python3
"""
è¯Šæ–­è‹±æ–‡åµŒå…¥å‘é‡é—®é¢˜
ç¡®å®šä¸ºä»€ä¹ˆè‹±æ–‡åµŒå…¥å‘é‡ä¸ºç©º
"""

import sys
import os
from pathlib import Path
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_encoder_loading():
    """æµ‹è¯•ç¼–ç å™¨åŠ è½½"""
    print("=" * 80)
    print("ğŸ” æµ‹è¯•ç¼–ç å™¨åŠ è½½")
    print("=" * 80)
    
    try:
        from xlm.components.encoder.encoder import Encoder
        
        # æµ‹è¯•è‹±æ–‡ç¼–ç å™¨åŠ è½½
        print("æµ‹è¯•è‹±æ–‡ç¼–ç å™¨åŠ è½½...")
        encoder_en = Encoder(
            model_name="models/finetuned_tatqa_mixed_enhanced",
            device="cuda:0"
        )
        print(f"âœ… è‹±æ–‡ç¼–ç å™¨åŠ è½½æˆåŠŸ")
        print(f"  æ¨¡å‹åç§°: {encoder_en.model_name}")
        print(f"  è®¾å¤‡: {encoder_en.device}")
        print(f"  åµŒå…¥ç»´åº¦: {encoder_en.model.get_sentence_embedding_dimension()}")
        
        # æµ‹è¯•ç®€å•ç¼–ç 
        print("\næµ‹è¯•ç®€å•ç¼–ç ...")
        test_text = "This is a test sentence."
        test_embedding = encoder_en.encode([test_text])
        print(f"âœ… ç®€å•ç¼–ç æˆåŠŸï¼Œå½¢çŠ¶: {test_embedding.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç¼–ç å™¨åŠ è½½å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_document_format():
    """æµ‹è¯•æ–‡æ¡£æ ¼å¼"""
    print("\n" + "=" * 80)
    print("ğŸ” æµ‹è¯•æ–‡æ¡£æ ¼å¼")
    print("=" * 80)
    
    try:
        # æ£€æŸ¥è‹±æ–‡æ•°æ®æ ¼å¼
        data_path = Path("data/unified/tatqa_knowledge_base_combined.jsonl")
        
        if not data_path.exists():
            print(f"âŒ è‹±æ–‡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            return False
        
        print(f"ğŸ“ è‹±æ–‡æ•°æ®æ–‡ä»¶: {data_path}")
        
        # è¯»å–å‰å‡ è¡ŒJSONLæ•°æ®
        english_records = []
        chinese_records = []
        
        with open(data_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= 10:  # åªæ£€æŸ¥å‰10è¡Œ
                    break
                if line.strip():
                    import json
                    record = json.loads(line)
                    content = record.get('content', '')
                    if content:
                        # ç®€å•æ£€æµ‹è¯­è¨€ï¼ˆæ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼‰
                        if any('\u4e00' <= char <= '\u9fff' for char in content):
                            chinese_records.append(record)
                        else:
                            english_records.append(record)
        
        print(f"ğŸ“Š å‰10æ¡è®°å½•åˆ†æ:")
        print(f"  è‹±æ–‡è®°å½•: {len(english_records)}")
        print(f"  ä¸­æ–‡è®°å½•: {len(chinese_records)}")
        
        if english_records:
            print(f"\nğŸ“‹ è‹±æ–‡è®°å½•ç¤ºä¾‹:")
            for i, record in enumerate(english_records[:3]):
                content = record.get('content', '')[:100] + "..." if len(record.get('content', '')) > 100 else record.get('content', '')
                print(f"  {i+1}. contenté•¿åº¦: {len(record.get('content', ''))}, å†…å®¹: {content}")
        
        if chinese_records:
            print(f"\nğŸ“‹ ä¸­æ–‡è®°å½•ç¤ºä¾‹:")
            for i, record in enumerate(chinese_records[:3]):
                content = record.get('content', '')[:100] + "..." if len(record.get('content', '')) > 100 else record.get('content', '')
                print(f"  {i+1}. contenté•¿åº¦: {len(record.get('content', ''))}, å†…å®¹: {content}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡æ¡£æ ¼å¼æ£€æŸ¥å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_batch_encoding():
    """æµ‹è¯•æ‰¹é‡ç¼–ç """
    print("\n" + "=" * 80)
    print("ğŸ” æµ‹è¯•æ‰¹é‡ç¼–ç ")
    print("=" * 80)
    
    try:
        from xlm.components.encoder.encoder import Encoder
        
        # åŠ è½½ç¼–ç å™¨
        encoder = Encoder(
            model_name="models/finetuned_tatqa_mixed_enhanced",
            device="cuda:0"
        )
        
        # å‡†å¤‡æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "This is the first test sentence.",
            "This is the second test sentence.",
            "This is the third test sentence.",
            "This is the fourth test sentence.",
            "This is the fifth test sentence."
        ]
        
        print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬æ•°é‡: {len(test_texts)}")
        
        # æµ‹è¯•å°æ‰¹é‡ç¼–ç 
        print("\næµ‹è¯•å°æ‰¹é‡ç¼–ç ...")
        embeddings = encoder.encode(test_texts)
        print(f"âœ… å°æ‰¹é‡ç¼–ç æˆåŠŸï¼Œå½¢çŠ¶: {embeddings.shape}")
        
        # æµ‹è¯•å¤§æ‰¹é‡ç¼–ç 
        print("\næµ‹è¯•å¤§æ‰¹é‡ç¼–ç ...")
        large_texts = test_texts * 100  # 500ä¸ªæ–‡æœ¬
        print(f"ğŸ“ å¤§æ‰¹é‡æ–‡æœ¬æ•°é‡: {len(large_texts)}")
        
        embeddings_large = encoder.encode(large_texts)
        print(f"âœ… å¤§æ‰¹é‡ç¼–ç æˆåŠŸï¼Œå½¢çŠ¶: {embeddings_large.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡ç¼–ç æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_gpu_memory():
    """æµ‹è¯•GPUå†…å­˜"""
    print("\n" + "=" * 80)
    print("ğŸ” æµ‹è¯•GPUå†…å­˜")
    print("=" * 80)
    
    try:
        import torch
        
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨")
            print(f"  GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"  å½“å‰GPU: {torch.cuda.current_device()}")
            print(f"  GPUåç§°: {torch.cuda.get_device_name()}")
            
            # æ£€æŸ¥GPUå†…å­˜
            for i in range(torch.cuda.device_count()):
                memory_allocated = torch.cuda.memory_allocated(i) / 1024**3
                memory_reserved = torch.cuda.memory_reserved(i) / 1024**3
                memory_total = torch.cuda.get_device_properties(i).total_memory / 1024**3
                
                print(f"  GPU {i}:")
                print(f"    æ€»å†…å­˜: {memory_total:.2f} GB")
                print(f"    å·²åˆ†é…: {memory_allocated:.2f} GB")
                print(f"    å·²ä¿ç•™: {memory_reserved:.2f} GB")
                print(f"    å¯ç”¨: {memory_total - memory_reserved:.2f} GB")
        else:
            print("âŒ CUDAä¸å¯ç”¨")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ GPUå†…å­˜æ£€æŸ¥å¤±è´¥: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è‹±æ–‡åµŒå…¥å‘é‡é—®é¢˜è¯Šæ–­")
    
    # æµ‹è¯•1: ç¼–ç å™¨åŠ è½½
    test1_passed = test_encoder_loading()
    
    # æµ‹è¯•2: æ–‡æ¡£æ ¼å¼
    test2_passed = test_document_format()
    
    # æµ‹è¯•3: æ‰¹é‡ç¼–ç 
    test3_passed = test_batch_encoding()
    
    # æµ‹è¯•4: GPUå†…å­˜
    test4_passed = test_gpu_memory()
    
    print("\n" + "=" * 80)
    print("ï¿½ï¿½ è¯Šæ–­ç»“æœ")
    print("=" * 80)
    print(f"âœ… ç¼–ç å™¨åŠ è½½: {'é€šè¿‡' if test1_passed else 'å¤±è´¥'}")
    print(f"âœ… æ–‡æ¡£æ ¼å¼: {'é€šè¿‡' if test2_passed else 'å¤±è´¥'}")
    print(f"âœ… æ‰¹é‡ç¼–ç : {'é€šè¿‡' if test3_passed else 'å¤±è´¥'}")
    print(f"âœ… GPUå†…å­˜: {'é€šè¿‡' if test4_passed else 'å¤±è´¥'}")
    
    if all([test1_passed, test2_passed, test3_passed, test4_passed]):
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œè‹±æ–‡åµŒå…¥å‘é‡é—®é¢˜å¯èƒ½æ˜¯å…¶ä»–åŸå› ")
    else:
        print("\nâŒ å‘ç°é—®é¢˜ï¼Œè¯·æ ¹æ®å¤±è´¥çš„æµ‹è¯•è¿›è¡Œä¿®å¤")
    
    print("=" * 80) 