#!/usr/bin/env python3
"""
Linuxç®€åŒ–æµ‹è¯•è„šæœ¬ - æµ‹è¯•åŸºç¡€RAGåŠŸèƒ½
"""

import os
import sys
import traceback
from pathlib import Path

# Add current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_basic_imports():
    """æµ‹è¯•åŸºç¡€å¯¼å…¥"""
    print("=== åŸºç¡€å¯¼å…¥æµ‹è¯• ===")
    
    try:
        from config.parameters import Config
        print("âœ… é…ç½®å¯¼å…¥æˆåŠŸ")
        
        from xlm.dto.dto import DocumentWithMetadata
        print("âœ… DTOå¯¼å…¥æˆåŠŸ")
        
        from xlm.components.encoder.encoder import Encoder
        print("âœ… ç¼–ç å™¨å¯¼å…¥æˆåŠŸ")
        
        from xlm.components.retriever.sbert_retriever import SBERTRetriever
        print("âœ… æ£€ç´¢å™¨å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_simple_rag():
    """æµ‹è¯•ç®€å•RAGåŠŸèƒ½"""
    print("\n=== ç®€å•RAGæµ‹è¯• ===")
    
    try:
        from xlm.components.encoder.encoder import Encoder
        from xlm.components.retriever.sbert_retriever import SBERTRetriever
        from xlm.dto.dto import DocumentWithMetadata, DocumentMetadata
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        test_docs = [
            DocumentWithMetadata(
                content="å‡€åˆ©æ¶¦æ˜¯å…¬å¸åœ¨ä¸€å®šæœŸé—´å†…çš„æ€»æ”¶å…¥å‡å»æ€»æˆæœ¬åçš„ä½™é¢ã€‚",
                metadata=DocumentMetadata(source="test", created_at="2024", author="test")
            ),
            DocumentWithMetadata(
                content="Net income is the total revenue minus total costs of a company over a period.",
                metadata=DocumentMetadata(source="test", created_at="2024", author="test")
            ),
            DocumentWithMetadata(
                content="è¥ä¸šæ”¶å…¥æ˜¯æŒ‡ä¼ä¸šåœ¨æ­£å¸¸ç»è¥æ´»åŠ¨ä¸­äº§ç”Ÿçš„æ”¶å…¥ã€‚",
                metadata=DocumentMetadata(source="test", created_at="2024", author="test")
            ),
            DocumentWithMetadata(
                content="Revenue refers to income generated from normal business activities.",
                metadata=DocumentMetadata(source="test", created_at="2024", author="test")
            )
        ]
        
        # åˆå§‹åŒ–ç¼–ç å™¨
        print("åˆå§‹åŒ–ç¼–ç å™¨...")
        encoder = Encoder(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            device="cuda" if torch.cuda.is_available() else "cpu"
        )
        
        # åˆå§‹åŒ–æ£€ç´¢å™¨
        print("åˆå§‹åŒ–æ£€ç´¢å™¨...")
        retriever = SBERTRetriever(
            encoder=encoder,
            corpus_documents=test_docs,
            use_faiss=False  # é¿å…FAISSé—®é¢˜
        )
        
        # æµ‹è¯•æ£€ç´¢
        print("æµ‹è¯•æ£€ç´¢åŠŸèƒ½...")
        queries = [
            "ä»€ä¹ˆæ˜¯å‡€åˆ©æ¶¦ï¼Ÿ",
            "What is net income?",
            "è¥ä¸šæ”¶å…¥æ˜¯ä»€ä¹ˆï¼Ÿ",
            "What is revenue?"
        ]
        
        for query in queries:
            print(f"\næŸ¥è¯¢: {query}")
            try:
                results = retriever.retrieve(text=query, top_k=2)
                print(f"  æ‰¾åˆ° {len(results)} ä¸ªæ–‡æ¡£:")
                for i, doc in enumerate(results):
                    print(f"    {i+1}. {doc.content[:50]}...")
            except Exception as e:
                print(f"  æ£€ç´¢å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç®€å•RAGæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\n=== æ•°æ®åŠ è½½æµ‹è¯• ===")
    
    # æ£€æŸ¥ä¸­æ–‡æ•°æ®
    chinese_data_paths = [
        "data/alphafin/alphafin_rag_ready_generated_cleaned.json",
        "evaluate_mrr/alphafin_train_qc.jsonl"
    ]
    
    print("ä¸­æ–‡æ•°æ®æ–‡ä»¶:")
    for path in chinese_data_paths:
        if os.path.exists(path):
            size = os.path.getsize(path) / (1024**2)  # MB
            print(f"  âœ… {path} ({size:.1f} MB)")
        else:
            print(f"  âŒ {path} (ä¸å­˜åœ¨)")
    
    # æ£€æŸ¥è‹±æ–‡æ•°æ®
    english_data_paths = [
        "data/tatqa_dataset_raw/tatqa_dataset_train.json",
        "evaluate_mrr/tatqa_train_qc.jsonl"
    ]
    
    print("\nè‹±æ–‡æ•°æ®æ–‡ä»¶:")
    for path in english_data_paths:
        if os.path.exists(path):
            size = os.path.getsize(path) / (1024**2)  # MB
            print(f"  âœ… {path} ({size:.1f} MB)")
        else:
            print(f"  âŒ {path} (ä¸å­˜åœ¨)")
    
    return chinese_data_paths, english_data_paths

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Linuxç®€åŒ–RAGç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # 1. æµ‹è¯•åŸºç¡€å¯¼å…¥
    imports_ok = test_basic_imports()
    
    # 2. æµ‹è¯•æ•°æ®åŠ è½½
    chinese_paths, english_paths = test_data_loading()
    
    # 3. æµ‹è¯•ç®€å•RAG
    rag_ok = test_simple_rag()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    
    if imports_ok and rag_ok:
        print("âœ… åŸºç¡€åŠŸèƒ½å¯ä»¥æ­£å¸¸è¿è¡Œ")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œ: python run_ui.py")
        print("  2. æˆ–è€…è¿è¡Œ: python test_simple_rag.py")
    else:
        print("âŒ ç³»ç»Ÿå­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    print(f"\næµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"  åŸºç¡€å¯¼å…¥: {'âœ…' if imports_ok else 'âŒ'}")
    print(f"  ç®€å•RAG: {'âœ…' if rag_ok else 'âŒ'}")

if __name__ == "__main__":
    import torch
    main() 