#!/usr/bin/env python3
"""
æµ‹è¯•å¥å­å®Œæ•´æ€§æ£€æµ‹å’ŒåŠ¨æ€tokenè°ƒæ•´åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from xlm.components.generator.local_llm_generator import LocalLLMGenerator
from config.parameters import Config

def test_sentence_completion():
    """æµ‹è¯•å¥å­å®Œæ•´æ€§æ£€æµ‹åŠŸèƒ½"""
    
    print("ğŸ” æµ‹è¯•å¥å­å®Œæ•´æ€§æ£€æµ‹åŠŸèƒ½...")
    
    # åˆå§‹åŒ–é…ç½®
    config = Config()
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = LocalLLMGenerator()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        # å®Œæ•´å¥å­
        "å¾·èµ›ç”µæ± ä¸šç»©å¢é•¿ä¸»è¦æºäºiPhoneéœ€æ±‚å¼ºåŠ²å’Œæ–°å“ç›ˆåˆ©èƒ½åŠ›æå‡ã€‚",
        "å…¬å¸è¥æ”¶åŒæ¯”å¢é•¿15%ï¼Œå‡€åˆ©æ¶¦å¢é•¿20%ã€‚",
        
        # ä¸å®Œæ•´å¥å­
        "å¾·èµ›ç”µæ± ä¸šç»©å¢é•¿ä¸»è¦æºäºiPhoneéœ€æ±‚å¼ºåŠ²å’Œæ–°å“ç›ˆåˆ©èƒ½åŠ›æ",
        "å…¬å¸è¥æ”¶åŒæ¯”å¢é•¿15%ï¼Œå‡€åˆ©æ¶¦å¢é•¿",
        "æ ¹æ®è´¢åŠ¡æŠ¥å‘Šæ˜¾ç¤ºï¼Œå…¬å¸",
        
        # è‹±æ–‡å®Œæ•´å¥å­
        "The company's revenue increased by 15% year-over-year.",
        "Net profit grew by 20% compared to last year.",
        
        # è‹±æ–‡ä¸å®Œæ•´å¥å­
        "The company's revenue increased by 15% year-over-",
        "Net profit grew by 20% compared to",
        
        # ç©ºå­—ç¬¦ä¸²
        "",
        "   ",
    ]
    
    print("\nğŸ“ å¥å­å®Œæ•´æ€§æ£€æµ‹ç»“æœ:")
    print("-" * 60)
    
    for i, text in enumerate(test_cases, 1):
        is_complete = generator._is_sentence_complete(text)
        status = "âœ… å®Œæ•´" if is_complete else "âŒ ä¸å®Œæ•´"
        print(f"{i:2d}. {status} | {repr(text)}")
    
    print("\n" + "=" * 60)

def test_dynamic_token_generation():
    """æµ‹è¯•åŠ¨æ€tokenç”ŸæˆåŠŸèƒ½"""
    
    print("ğŸš€ æµ‹è¯•åŠ¨æ€tokenç”ŸæˆåŠŸèƒ½...")
    
    # åˆå§‹åŒ–é…ç½®
    config = Config()
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = LocalLLMGenerator()
    
    # æµ‹è¯•prompt
    test_prompt = """
è¯·åˆ†æå¾·èµ›ç”µæ± çš„ä¸šç»©è¡¨ç°ï¼Œé‡ç‚¹å…³æ³¨è¥æ”¶å¢é•¿å’Œç›ˆåˆ©èƒ½åŠ›ã€‚
"""
    
    print(f"\nğŸ“‹ æµ‹è¯•Prompt: {test_prompt.strip()}")
    print("-" * 60)
    
    try:
        # ç”Ÿæˆå›ç­”
        response = generator.generate([test_prompt])[0]
        
        print(f"âœ… ç”ŸæˆæˆåŠŸ!")
        print(f"ğŸ“Š å›ç­”é•¿åº¦: {len(response)} å­—ç¬¦")
        print(f"ğŸ“ å›ç­”å†…å®¹: {response}")
        
        # æ£€æŸ¥å¥å­å®Œæ•´æ€§
        is_complete = generator._is_sentence_complete(response)
        print(f"ğŸ” å¥å­å®Œæ•´æ€§: {'âœ… å®Œæ•´' if is_complete else 'âŒ ä¸å®Œæ•´'}")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")

def test_token_optimization():
    """æµ‹è¯•tokenä¼˜åŒ–æ•ˆæœ"""
    
    print("âš¡ æµ‹è¯•tokenä¼˜åŒ–æ•ˆæœ...")
    
    # åˆå§‹åŒ–é…ç½®
    config = Config()
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = LocalLLMGenerator()
    
    # æµ‹è¯•ä¸åŒmax_new_tokensçš„æ•ˆæœ
    test_cases = [
        ("å¾·èµ›ç”µæ± ä¸šç»©å¦‚ä½•ï¼Ÿ", 100),
        ("åˆ†æå…¬å¸è¥æ”¶å¢é•¿åŸå› ", 150),
        ("è¯¦ç»†è¯´æ˜ç›ˆåˆ©èƒ½åŠ›å˜åŒ–", 200),
        ("ç»¼åˆè¯„ä¼°å…¬å¸å‘å±•å‰æ™¯", 250),
    ]
    
    print("\nğŸ“Š ä¸åŒtokenæ•°é‡çš„ç”Ÿæˆæ•ˆæœå¯¹æ¯”:")
    print("-" * 80)
    
    for query, max_tokens in test_cases:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        print(f"ğŸ¯ ç›®æ ‡tokenæ•°: {max_tokens}")
        
        # ä¸´æ—¶ä¿®æ”¹max_new_tokens
        original_max_tokens = generator.max_new_tokens
        generator.max_new_tokens = max_tokens
        
        try:
            response = generator.generate([query])[0]
            is_complete = generator._is_sentence_complete(response)
            
            print(f"ğŸ“ å›ç­”: {response}")
            print(f"ğŸ“Š é•¿åº¦: {len(response)} å­—ç¬¦")
            print(f"âœ… å®Œæ•´æ€§: {'å®Œæ•´' if is_complete else 'ä¸å®Œæ•´'}")
            
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
        
        # æ¢å¤åŸå§‹è®¾ç½®
        generator.max_new_tokens = original_max_tokens
        
        print("-" * 40)

if __name__ == "__main__":
    print("ğŸ§ª å¥å­å®Œæ•´æ€§æ£€æµ‹å’ŒåŠ¨æ€tokenè°ƒæ•´æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•å¥å­å®Œæ•´æ€§æ£€æµ‹
    test_sentence_completion()
    
    # æµ‹è¯•åŠ¨æ€tokenç”Ÿæˆ
    test_dynamic_token_generation()
    
    # æµ‹è¯•tokenä¼˜åŒ–æ•ˆæœ
    test_token_optimization()
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!") 