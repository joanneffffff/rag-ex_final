#!/usr/bin/env python3
"""
è¿è¡ŒAlphaFinæ¨¡å‹æ¯”è¾ƒçš„ç¤ºä¾‹è„šæœ¬
ä½¿ç”¨çœŸå®çš„AlphaFiné—®é¢˜æ¥æ¯”è¾ƒä¸åŒæ¨¡å‹
"""

import subprocess
import sys
import os

def run_model_comparison():
    """è¿è¡Œæ¨¡å‹æ¯”è¾ƒ"""
    print("ğŸš€ å¼€å§‹AlphaFinæ¨¡å‹æ¯”è¾ƒæµ‹è¯•")
    print("=" * 50)
    
    # ç¤ºä¾‹1ï¼šå¿«é€Ÿæ¯”è¾ƒQwen3-8Bå’ŒFin-R1
    print("\nğŸ“Š ç¤ºä¾‹1ï¼šå¿«é€Ÿæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹")
    print("ä½¿ç”¨3ä¸ªAlphaFiné—®é¢˜æ¯”è¾ƒQwen3-8Bå’ŒFin-R1")
    
    cmd1 = [
        "python", "compare_models_with_alphafin.py",
        "--model_names", "Qwen/Qwen3-8B", "SUFE-AIFLM-Lab/Fin-R1",
        "--max_questions", "3",
        "--output_dir", "quick_comparison_results"
    ]
    
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd1)}")
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦æ‰§è¡Œ
    try:
        choice = input("\nğŸ¤” æ˜¯å¦æ‰§è¡Œç¤ºä¾‹1ï¼Ÿ(y/n): ").lower().strip()
        if choice in ['y', 'yes', 'æ˜¯']:
            print("\nğŸ”§ æ‰§è¡Œç¤ºä¾‹1...")
            result = subprocess.run(cmd1, capture_output=True, text=True)
            print("è¾“å‡º:", result.stdout)
            if result.stderr:
                print("é”™è¯¯:", result.stderr)
        else:
            print("è·³è¿‡ç¤ºä¾‹1")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
        return
    
    # ç¤ºä¾‹2ï¼šè¯¦ç»†æ¯”è¾ƒå¤šä¸ªæ¨¡å‹
    print("\nğŸ“Š ç¤ºä¾‹2ï¼šè¯¦ç»†æ¯”è¾ƒå¤šä¸ªæ¨¡å‹")
    print("ä½¿ç”¨5ä¸ªAlphaFiné—®é¢˜æ¯”è¾ƒå¤šä¸ªæ¨¡å‹")
    
    cmd2 = [
        "python", "compare_models_with_alphafin.py",
        "--model_names", "Qwen/Qwen3-8B", "Qwen/Qwen2-7B",
        "--max_questions", "5",
        "--output_dir", "detailed_comparison_results"
    ]
    
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd2)}")
    
    try:
        choice = input("\nğŸ¤” æ˜¯å¦æ‰§è¡Œç¤ºä¾‹2ï¼Ÿ(y/n): ").lower().strip()
        if choice in ['y', 'yes', 'æ˜¯']:
            print("\nğŸ”§ æ‰§è¡Œç¤ºä¾‹2...")
            result = subprocess.run(cmd2, capture_output=True, text=True)
            print("è¾“å‡º:", result.stdout)
            if result.stderr:
                print("é”™è¯¯:", result.stderr)
        else:
            print("è·³è¿‡ç¤ºä¾‹2")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
        return
    
    # ç¤ºä¾‹3ï¼šä½¿ç”¨è¯„ä¼°æ•°æ®é›†
    print("\nğŸ“Š ç¤ºä¾‹3ï¼šä½¿ç”¨è¯„ä¼°æ•°æ®é›†")
    print("ä½¿ç”¨alphafin_eval.jsonlä¸­çš„é—®é¢˜")
    
    cmd3 = [
        "python", "compare_models_with_alphafin.py",
        "--model_names", "Qwen/Qwen3-8B",
        "--data_path", "evaluate_mrr/alphafin_eval.jsonl",
        "--max_questions", "3",
        "--output_dir", "eval_comparison_results"
    ]
    
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd3)}")
    
    try:
        choice = input("\nğŸ¤” æ˜¯å¦æ‰§è¡Œç¤ºä¾‹3ï¼Ÿ(y/n): ").lower().strip()
        if choice in ['y', 'yes', 'æ˜¯']:
            print("\nğŸ”§ æ‰§è¡Œç¤ºä¾‹3...")
            result = subprocess.run(cmd3, capture_output=True, text=True)
            print("è¾“å‡º:", result.stdout)
            if result.stderr:
                print("é”™è¯¯:", result.stderr)
        else:
            print("è·³è¿‡ç¤ºä¾‹3")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
        return
    
    print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
    print("\nğŸ“ ç”Ÿæˆçš„ç»“æœæ–‡ä»¶:")
    print("   - quick_comparison_results/")
    print("   - detailed_comparison_results/")
    print("   - eval_comparison_results/")
    
    print("\nğŸ’¡ æŸ¥çœ‹ç»“æœ:")
    print("   cat quick_comparison_results/model_comparison_report.md")
    print("   cat detailed_comparison_results/model_comparison_report.md")
    print("   cat eval_comparison_results/model_comparison_report.md")

def show_available_models():
    """æ˜¾ç¤ºå¯ç”¨çš„æ¨¡å‹"""
    print("\nğŸ“‹ å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨:")
    print("=" * 30)
    
    models = [
        ("Qwen/Qwen3-8B", "Qwen3-8BåŸºç¡€ç‰ˆæœ¬ï¼Œæ¨èä½¿ç”¨"),
        ("Qwen/Qwen2-7B", "Qwen2-7Bç‰ˆæœ¬ï¼Œè¾ƒå°ä½†å¿«é€Ÿ"),
        ("Qwen/Qwen2-1.5B", "Qwen2-1.5Bç‰ˆæœ¬ï¼Œæœ€å°ä½†æœ€å¿«"),
        ("SUFE-AIFLM-Lab/Fin-R1", "é‡‘èä¸“ç”¨æ¨¡å‹ï¼Œä½†å†…å­˜éœ€æ±‚é«˜"),
        ("Llama2-7B-chat-hf", "Llama2-7BèŠå¤©ç‰ˆæœ¬"),
        ("microsoft/DialoGPT-medium", "å¾®è½¯å¯¹è¯æ¨¡å‹ï¼Œè¾ƒå°"),
    ]
    
    for model_name, description in models:
        print(f"   {model_name}")
        print(f"      {description}")
        print()

def show_usage_examples():
    """æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print("=" * 20)
    
    examples = [
        ("åŸºæœ¬æ¯”è¾ƒ", "python compare_models_with_alphafin.py"),
        ("æŒ‡å®šæ¨¡å‹", "python compare_models_with_alphafin.py --model_names Qwen/Qwen3-8B Qwen/Qwen2-7B"),
        ("ä½¿ç”¨è¯„ä¼°æ•°æ®", "python compare_models_with_alphafin.py --data_path evaluate_mrr/alphafin_eval.jsonl"),
        ("é™åˆ¶é—®é¢˜æ•°é‡", "python compare_models_with_alphafin.py --max_questions 3"),
        ("ä½¿ç”¨ä¸åŒGPU", "python compare_models_with_alphafin.py --device cuda:0"),
        ("è‡ªå®šä¹‰è¾“å‡ºç›®å½•", "python compare_models_with_alphafin.py --output_dir my_results"),
    ]
    
    for title, cmd in examples:
        print(f"   {title}:")
        print(f"      {cmd}")
        print()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª AlphaFinæ¨¡å‹æ¯”è¾ƒå·¥å…·")
    print("=" * 30)
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. è¿è¡Œæ¨¡å‹æ¯”è¾ƒç¤ºä¾‹")
        print("2. æŸ¥çœ‹å¯ç”¨æ¨¡å‹")
        print("3. æŸ¥çœ‹ä½¿ç”¨ç¤ºä¾‹")
        print("4. é€€å‡º")
        
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
            
            if choice == "1":
                run_model_comparison()
            elif choice == "2":
                show_available_models()
            elif choice == "3":
                show_usage_examples()
            elif choice == "4":
                print("ğŸ‘‹ å†è§ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main() 