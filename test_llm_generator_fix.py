#!/usr/bin/env python3
"""
æµ‹è¯•LLMç”Ÿæˆå™¨ä¿®å¤æ˜¯å¦æœ‰æ•ˆ
éªŒè¯å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿä¸­çš„LLMç”Ÿæˆå™¨æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def test_llm_generator():
    """æµ‹è¯•LLMç”Ÿæˆå™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("=== æµ‹è¯•LLMç”Ÿæˆå™¨ä¿®å¤ ===")
    
    try:
        # å¯¼å…¥å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿ
        from alphafin_data_process.multi_stage_retrieval_final import MultiStageRetrievalSystem
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        data_path = Path("data/alphafin/alphafin_merged_generated_qa.json")
        print(f"æ­£åœ¨åˆå§‹åŒ–å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿ...")
        print(f"æ•°æ®è·¯å¾„: {data_path}")
        
        retrieval_system = MultiStageRetrievalSystem(
            data_path=data_path,
            dataset_type="chinese",
            use_existing_config=True
        )
        
        # æ£€æŸ¥LLMç”Ÿæˆå™¨çŠ¶æ€
        if retrieval_system.llm_generator:
            print("âœ… LLMç”Ÿæˆå™¨å·²æˆåŠŸåˆå§‹åŒ–")
            
            # æµ‹è¯•ç”Ÿæˆå™¨åŠŸèƒ½
            test_prompt = "åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\n\nå¾·èµ›ç”µæ± æ˜¯ä¸€å®¶ä¸“æ³¨äºç”µæ± åˆ¶é€ çš„å…¬å¸ã€‚\n\né—®é¢˜ï¼šå¾·èµ›ç”µæ± çš„ä¸»è¦ä¸šåŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ\n\nå›ç­”ï¼š"
            
            print("æ­£åœ¨æµ‹è¯•LLMç”Ÿæˆå™¨...")
            try:
                response = retrieval_system.llm_generator.generate(texts=[test_prompt])
                if response and len(response) > 0:
                    print("âœ… LLMç”Ÿæˆå™¨æ­£å¸¸å·¥ä½œ")
                    print(f"ç”Ÿæˆçš„å›ç­”: {response[0][:100]}...")
                else:
                    print("âŒ LLMç”Ÿæˆå™¨è¿”å›ç©ºå“åº”")
            except Exception as e:
                print(f"âŒ LLMç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        else:
            print("âŒ LLMç”Ÿæˆå™¨æœªåˆå§‹åŒ–")
            return False
        
        # æµ‹è¯•å®Œæ•´çš„æ£€ç´¢å’Œç”Ÿæˆæµç¨‹
        print("\n=== æµ‹è¯•å®Œæ•´æ£€ç´¢å’Œç”Ÿæˆæµç¨‹ ===")
        test_query = "å¾·èµ›ç”µæ± ï¼ˆ000049ï¼‰2021å¹´åˆ©æ¶¦æŒç»­å¢é•¿çš„ä¸»è¦åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ"
        print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        results = retrieval_system.search(
            query=test_query,
            company_name="å¾·èµ›ç”µæ± ",
            stock_code="000049",
            report_date="2021",
            top_k=5
        )
        
        # æ£€æŸ¥ç»“æœ
        if isinstance(results, dict) and 'llm_answer' in results:
            llm_answer = results['llm_answer']
            if llm_answer and llm_answer != "æœªé…ç½®LLMç”Ÿæˆå™¨ã€‚":
                print("âœ… å®Œæ•´æµç¨‹æµ‹è¯•æˆåŠŸ")
                print(f"LLMç”Ÿæˆçš„ç­”æ¡ˆ: {llm_answer[:200]}...")
                return True
            else:
                print("âŒ LLMç”Ÿæˆå™¨æœªç”Ÿæˆç­”æ¡ˆ")
                print(f"è¿”å›çš„ç­”æ¡ˆ: {llm_answer}")
                return False
        else:
            print("âŒ æ£€ç´¢ç»“æœæ ¼å¼é”™è¯¯")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•LLMç”Ÿæˆå™¨ä¿®å¤...")
    
    success = test_llm_generator()
    
    if success:
        print("\nğŸ‰ æµ‹è¯•æˆåŠŸï¼LLMç”Ÿæˆå™¨ä¿®å¤æœ‰æ•ˆ")
        print("ç°åœ¨å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿå¯ä»¥æ­£å¸¸ç”Ÿæˆç­”æ¡ˆäº†")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼LLMç”Ÿæˆå™¨ä»æœ‰é—®é¢˜")
    
    return success

if __name__ == "__main__":
    main() 