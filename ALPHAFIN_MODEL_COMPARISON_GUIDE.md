# AlphaFinæ•°æ®é›†æ¨¡å‹æ¯”è¾ƒæŒ‡å—

## ğŸ¯ æ¦‚è¿°

è¿™ä¸ªè„šæœ¬ä½¿ç”¨AlphaFinæ•°æ®é›†ä¸­çš„çœŸå®é—®é¢˜æ¥æ¯”è¾ƒä¸åŒç”Ÿæˆå™¨æ¨¡å‹çš„æ•ˆæœï¼Œæ”¯æŒé€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šä¸åŒçš„æ¨¡å‹ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ç”¨æ³•

```bash
# ä½¿ç”¨é»˜è®¤æ¨¡å‹æ¯”è¾ƒï¼ˆQwen3-8B vs Fin-R1ï¼‰
python compare_models_with_alphafin.py

# æŒ‡å®šç‰¹å®šæ¨¡å‹
python compare_models_with_alphafin.py --model_names Qwen/Qwen3-8B Qwen/Qwen2-7B

# æŒ‡å®šæ›´å¤šå‚æ•°
python compare_models_with_alphafin.py \
    --model_names Qwen/Qwen3-8B SUFE-AIFLM-Lab/Fin-R1 \
    --max_questions 10 \
    --device cuda:1 \
    --output_dir my_comparison_results
```

### æ”¯æŒçš„æ¨¡å‹

```bash
# Qwenç³»åˆ—
python compare_models_with_alphafin.py --model_names Qwen/Qwen3-8B Qwen/Qwen2-7B Qwen/Qwen2-1.5B

# é‡‘èä¸“ç”¨æ¨¡å‹
python compare_models_with_alphafin.py --model_names SUFE-AIFLM-Lab/Fin-R1 Qwen/Qwen3-8B

# æ··åˆæ¯”è¾ƒ
python compare_models_with_alphafin.py --model_names Qwen/Qwen3-8B Llama2-7B-chat-hf SUFE-AIFLM-Lab/Fin-R1
```

## ğŸ“‹ å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--model_names` | list | `["Qwen/Qwen3-8B", "SUFE-AIFLM-Lab/Fin-R1"]` | è¦æµ‹è¯•çš„æ¨¡å‹åç§°åˆ—è¡¨ |
| `--data_path` | str | `"evaluate_mrr/alphafin_train_qc.jsonl"` | AlphaFinæ•°æ®æ–‡ä»¶è·¯å¾„ |
| `--max_questions` | int | `5` | æœ€å¤§æµ‹è¯•é—®é¢˜æ•°é‡ |
| `--device` | str | `"cuda:1"` | GPUè®¾å¤‡ |
| `--output_dir` | str | `"model_comparison_results"` | è¾“å‡ºç›®å½• |

## ğŸ“Š è¾“å‡ºç»“æœ

### 1. å•ä¸ªæ¨¡å‹ç»“æœæ–‡ä»¶
- `Qwen_Qwen3_8B_alphafin_results.json`
- `SUFE_AIFLM_Lab_Fin_R1_alphafin_results.json`

### 2. æ¯”è¾ƒæŠ¥å‘Š
- `model_comparison_report.md`

### 3. ç»“æœæ ¼å¼

```json
{
  "model_name": "Qwen/Qwen3-8B",
  "device": "cuda:1",
  "success_count": 5,
  "total_time": 195.5,
  "avg_tokens": 31.6,
  "memory_usage": 5.98,
  "questions": [
    {
      "question": "ä»€ä¹ˆæ˜¯è‚¡ç¥¨æŠ•èµ„ï¼Ÿ",
      "response": "è‚¡ç¥¨æŠ•èµ„æ˜¯æŒ‡é€šè¿‡è´­ä¹°å…¬å¸çš„è‚¡ä»½...",
      "tokens": 38,
      "time": 39.42,
      "success": true
    }
  ]
}
```

## ğŸ§ª ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå¿«é€Ÿæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹

```bash
python compare_models_with_alphafin.py \
    --model_names Qwen/Qwen3-8B SUFE-AIFLM-Lab/Fin-R1 \
    --max_questions 3
```

### ç¤ºä¾‹2ï¼šè¯¦ç»†æ¯”è¾ƒå¤šä¸ªæ¨¡å‹

```bash
python compare_models_with_alphafin.py \
    --model_names Qwen/Qwen3-8B Qwen/Qwen2-7B Llama2-7B-chat-hf \
    --max_questions 10 \
    --output_dir detailed_comparison
```

### ç¤ºä¾‹3ï¼šä½¿ç”¨ä¸åŒGPU

```bash
python compare_models_with_alphafin.py \
    --model_names Qwen/Qwen3-8B \
    --device cuda:0 \
    --max_questions 5
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

è„šæœ¬ä¼šè®¡ç®—ä»¥ä¸‹æ€§èƒ½æŒ‡æ ‡ï¼š

1. **æˆåŠŸç‡**: æˆåŠŸç”Ÿæˆçš„é—®é¢˜æ•°é‡ / æ€»é—®é¢˜æ•°é‡
2. **å¹³å‡ç”Ÿæˆæ—¶é—´**: æ‰€æœ‰æˆåŠŸç”Ÿæˆçš„å¹³å‡æ—¶é—´
3. **å¹³å‡Tokenæ•°**: ç”Ÿæˆå›ç­”çš„å¹³å‡é•¿åº¦
4. **GPUå†…å­˜ä½¿ç”¨**: æ¨¡å‹å ç”¨çš„GPUå†…å­˜

## ğŸ”§ æŠ€æœ¯ç‰¹æ€§

### å†…å­˜ç®¡ç†
- è‡ªåŠ¨æ¸…ç†GPUå†…å­˜
- 4bité‡åŒ–æ”¯æŒ
- åˆ†ç¦»æ¨¡å‹æµ‹è¯•é¿å…å†…å­˜å†²çª

### é”™è¯¯å¤„ç†
- ä¼˜é›…å¤„ç†æ¨¡å‹åŠ è½½å¤±è´¥
- è‡ªåŠ¨å›é€€åˆ°é»˜è®¤é—®é¢˜
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

### æ•°æ®åŠ è½½
- è‡ªåŠ¨ä»AlphaFinæ•°æ®é›†åŠ è½½é—®é¢˜
- æ”¯æŒå¤šç§æ•°æ®æ ¼å¼
- å¯é…ç½®é—®é¢˜æ•°é‡

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å†…å­˜ä¼˜åŒ–
```bash
# å¯¹äºå†…å­˜å—é™çš„ç¯å¢ƒï¼Œä½¿ç”¨è¾ƒå°‘çš„æµ‹è¯•é—®é¢˜
python compare_models_with_alphafin.py --max_questions 3

# ä½¿ç”¨4bité‡åŒ–ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
# è„šæœ¬ä¼šè‡ªåŠ¨åº”ç”¨4bité‡åŒ–ä»¥èŠ‚çœå†…å­˜
```

### 2. æ¨¡å‹é€‰æ‹©
```bash
# æ¨èç»„åˆï¼šQwen3-8B + å…¶ä»–æ¨¡å‹
python compare_models_with_alphafin.py \
    --model_names Qwen/Qwen3-8B Qwen/Qwen2-7B

# é¿å…åŒæ—¶æµ‹è¯•å¤šä¸ªå¤§æ¨¡å‹
# å»ºè®®ä¸€æ¬¡åªæµ‹è¯•2-3ä¸ªæ¨¡å‹
```

### 3. ç»“æœåˆ†æ
```bash
# æŸ¥çœ‹ç”Ÿæˆçš„æ¯”è¾ƒæŠ¥å‘Š
cat model_comparison_results/model_comparison_report.md

# åˆ†æå•ä¸ªæ¨¡å‹ç»“æœ
cat Qwen_Qwen3_8B_alphafin_results.json | jq '.success_count'
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **å†…å­˜è¦æ±‚**: ç¡®ä¿GPUæœ‰è¶³å¤Ÿå†…å­˜è¿è¡Œé€‰æ‹©çš„æ¨¡å‹
2. **æ¨¡å‹å¯ç”¨æ€§**: ç¡®ä¿æ¨¡å‹åç§°æ­£ç¡®ä¸”å¯è®¿é—®
3. **æ•°æ®æ–‡ä»¶**: ç¡®ä¿AlphaFinæ•°æ®æ–‡ä»¶å­˜åœ¨
4. **ç½‘ç»œè¿æ¥**: é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDA OOMé”™è¯¯**
   ```bash
   # å‡å°‘æµ‹è¯•é—®é¢˜æ•°é‡
   python compare_models_with_alphafin.py --max_questions 2
   
   # ä½¿ç”¨CPUï¼ˆè¾ƒæ…¢ä½†ç¨³å®šï¼‰
   python compare_models_with_alphafin.py --device cpu
   ```

2. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®
   # ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
   # å°è¯•ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
   ```

3. **æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨**
   ```bash
   # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
   ls evaluate_mrr/alphafin_train_qc.jsonl
   
   # ä½¿ç”¨å…¶ä»–æ•°æ®æ–‡ä»¶
   python compare_models_with_alphafin.py --data_path your_data.jsonl
   ```

## ğŸ“ æ‰©å±•åŠŸèƒ½

### è‡ªå®šä¹‰é—®é¢˜
å¯ä»¥ä¿®æ”¹è„šæœ¬ä¸­çš„`load_alphafin_questions`å‡½æ•°æ¥åŠ è½½è‡ªå®šä¹‰é—®é¢˜ï¼š

```python
def load_custom_questions():
    return [
        "ä½ çš„è‡ªå®šä¹‰é—®é¢˜1",
        "ä½ çš„è‡ªå®šä¹‰é—®é¢˜2",
        # ...
    ]
```

### æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡
å¯ä»¥åœ¨`test_model_with_alphafin_questions`å‡½æ•°ä¸­æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ï¼š
- å›ç­”ç›¸å…³æ€§è¯„åˆ†
- äº‹å®å‡†ç¡®æ€§æ£€æŸ¥
- è¯­è¨€æµç•…åº¦è¯„ä¼°

## ğŸ‰ æ€»ç»“

è¿™ä¸ªè„šæœ¬æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„æ¡†æ¶æ¥æ¯”è¾ƒä¸åŒç”Ÿæˆå™¨æ¨¡å‹åœ¨AlphaFinæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œå¸®åŠ©æ‚¨é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚ 