#!/usr/bin/env python3
"""
ä»AlphaFinç”Ÿæˆæ•°æ®ä¸­æå–ä¸åŸå§‹è¯„ä¼°æ•°æ®åŒ¹é…çš„æ ·æœ¬
ç”¨äºè¯„ä¼°ç”Ÿæˆæ•°æ®çš„è´¨é‡
"""

import json
import argparse
from pathlib import Path
from typing import List, Dict
import re
from difflib import SequenceMatcher

def normalize_text(text: str) -> str:
    """æ ‡å‡†åŒ–æ–‡æœ¬ç”¨äºæ¯”è¾ƒ"""
    if not text:
        return ""
    # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
    text = re.sub(r'\s+', ' ', text.strip())
    # è½¬æ¢ä¸ºå°å†™
    text = text.lower()
    return text

def calculate_similarity(text1: str, text2: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
    if not text1 or not text2:
        return 0.0
    
    norm1 = normalize_text(text1)
    norm2 = normalize_text(text2)
    
    if not norm1 or not norm2:
        return 0.0
    
    # ä½¿ç”¨åºåˆ—åŒ¹é…å™¨è®¡ç®—ç›¸ä¼¼åº¦
    similarity = SequenceMatcher(None, norm1, norm2).ratio()
    return similarity

def extract_key_info(text: str) -> Dict[str, str]:
    """æå–æ–‡æœ¬ä¸­çš„å…³é”®ä¿¡æ¯"""
    info = {
        "company": "",
        "stock_code": "",
        "date": "",
        "numbers": []
    }
    
    # æå–å…¬å¸åç§°å’Œè‚¡ç¥¨ä»£ç 
    company_pattern = r'([^ï¼ˆ]+)ï¼ˆ([0-9]{6}ï¼‰)'
    match = re.search(company_pattern, text)
    if match:
        info["company"] = match.group(1).strip()
        info["stock_code"] = match.group(2).strip()
    
    # æå–æ—¥æœŸ
    date_pattern = r'(\d{4}-\d{2}-\d{2})'
    dates = re.findall(date_pattern, text)
    if dates:
        info["date"] = dates[0]
    
    # æå–æ•°å­—
    number_pattern = r'\d+\.?\d*'
    numbers = re.findall(number_pattern, text)
    info["numbers"] = [float(n) for n in numbers[:10]]  # åªå–å‰10ä¸ªæ•°å­—
    
    return info

def calculate_structured_similarity(original: Dict, generated: Dict) -> float:
    """è®¡ç®—ç»“æ„åŒ–ç›¸ä¼¼åº¦"""
    original_info = extract_key_info(original.get("question", "") + " " + original.get("context", ""))
    generated_info = extract_key_info(generated.get("question", "") + " " + generated.get("context", ""))
    
    # å…¬å¸åç§°ç›¸ä¼¼åº¦
    company_sim = calculate_similarity(original_info["company"], generated_info["company"])
    
    # è‚¡ç¥¨ä»£ç åŒ¹é…
    stock_match = 1.0 if original_info["stock_code"] == generated_info["stock_code"] else 0.0
    
    # æ—¥æœŸåŒ¹é…
    date_match = 1.0 if original_info["date"] == generated_info["date"] else 0.0
    
    # æ•°å­—ç›¸ä¼¼åº¦ï¼ˆå–å‰5ä¸ªæ•°å­—æ¯”è¾ƒï¼‰
    number_sim = 0.0
    if original_info["numbers"] and generated_info["numbers"]:
        common_count = 0
        for orig_num in original_info["numbers"][:5]:
            for gen_num in generated_info["numbers"][:5]:
                if abs(float(orig_num) - float(gen_num)) < 0.01:  # å…è®¸å°çš„æ•°å€¼å·®å¼‚
                    common_count += 1
        number_sim = common_count / min(len(original_info["numbers"][:5]), len(generated_info["numbers"][:5]))
    
    # åŠ æƒå¹³å‡
    structured_sim = (
        company_sim * 0.3 +
        stock_match * 0.3 +
        date_match * 0.2 +
        number_sim * 0.2
    )
    
    return structured_sim

def find_matching_samples(original_eval_data: List[Dict], generated_data: List[Dict], 
                         similarity_threshold: float = 0.4) -> List[Dict]:
    """ä»ç”Ÿæˆæ•°æ®ä¸­æ‰¾åˆ°ä¸åŸå§‹è¯„ä¼°æ•°æ®åŒ¹é…çš„æ ·æœ¬"""
    print(f"ğŸ” å¼€å§‹åŒ¹é…æ ·æœ¬...")
    print(f"åŸå§‹è¯„ä¼°æ•°æ®: {len(original_eval_data)} ä¸ªæ ·æœ¬")
    print(f"ç”Ÿæˆæ•°æ®: {len(generated_data)} ä¸ªæ ·æœ¬")
    
    matched_samples = []
    unmatched_count = 0
    
    for i, original_sample in enumerate(original_eval_data):
        if i % 100 == 0:
            print(f"å¤„ç†è¿›åº¦: {i}/{len(original_eval_data)}")
        
        original_question = original_sample.get("query", "")  # æ³¨æ„ï¼šåŸå§‹æ•°æ®ä½¿ç”¨"query"å­—æ®µ
        original_context = original_sample.get("context", "")
        original_answer = original_sample.get("answer", "")
        
        best_match = None
        best_similarity = 0.0
        
        # åœ¨ç”Ÿæˆæ•°æ®ä¸­å¯»æ‰¾æœ€ä½³åŒ¹é…
        for generated_sample in generated_data:
            generated_question = generated_sample.get("question", "")
            generated_context = generated_sample.get("context", "")
            generated_answer = generated_sample.get("answer", "")
            
            # è®¡ç®—é—®é¢˜ç›¸ä¼¼åº¦
            question_similarity = calculate_similarity(original_question, generated_question)
            
            # è®¡ç®—ä¸Šä¸‹æ–‡ç›¸ä¼¼åº¦
            context_similarity = calculate_similarity(original_context, generated_context)
            
            # è®¡ç®—ç­”æ¡ˆç›¸ä¼¼åº¦
            answer_similarity = calculate_similarity(original_answer, generated_answer)
            
            # è®¡ç®—ç»“æ„åŒ–ç›¸ä¼¼åº¦
            structured_similarity = calculate_structured_similarity(
                {"question": original_question, "context": original_context},
                {"question": generated_question, "context": generated_context}
            )
            
            # ç»¼åˆç›¸ä¼¼åº¦ï¼ˆåŠ æƒå¹³å‡ï¼‰
            overall_similarity = (
                question_similarity * 0.3 + 
                context_similarity * 0.2 + 
                answer_similarity * 0.2 +
                structured_similarity * 0.3
            )
            
            if overall_similarity > best_similarity:
                best_similarity = overall_similarity
                best_match = {
                    "generated_sample": generated_sample,
                    "similarity_scores": {
                        "question": question_similarity,
                        "context": context_similarity,
                        "answer": answer_similarity,
                        "structured": structured_similarity,
                        "overall": overall_similarity
                    }
                }
        
        # å¦‚æœæ‰¾åˆ°è¶³å¤Ÿç›¸ä¼¼çš„åŒ¹é…
        if best_match and best_match["similarity_scores"]["overall"] >= similarity_threshold:
            matched_sample = {
                "original_sample": original_sample,
                "matched_sample": best_match["generated_sample"],
                "similarity_scores": best_match["similarity_scores"],
                "match_quality": "high" if best_match["similarity_scores"]["overall"] >= 0.7 else "medium"
            }
            matched_samples.append(matched_sample)
        else:
            unmatched_count += 1
            if unmatched_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªæœªåŒ¹é…çš„æ ·æœ¬
                print(f"æœªæ‰¾åˆ°åŒ¹é…: åŸå§‹é—®é¢˜='{original_question[:50]}...' (æœ€ä½³ç›¸ä¼¼åº¦: {best_similarity:.3f})")
    
    print(f"âœ… åŒ¹é…å®Œæˆ:")
    print(f"  - æˆåŠŸåŒ¹é…: {len(matched_samples)} ä¸ªæ ·æœ¬")
    print(f"  - æœªåŒ¹é…: {unmatched_count} ä¸ªæ ·æœ¬")
    print(f"  - åŒ¹é…ç‡: {len(matched_samples)/len(original_eval_data)*100:.1f}%")
    
    return matched_samples

def analyze_matching_quality(matched_samples: List[Dict]):
    """åˆ†æåŒ¹é…è´¨é‡"""
    print(f"\nğŸ“Š åŒ¹é…è´¨é‡åˆ†æ:")
    
    high_quality = [s for s in matched_samples if s["match_quality"] == "high"]
    medium_quality = [s for s in matched_samples if s["match_quality"] == "medium"]
    
    print(f"  - é«˜è´¨é‡åŒ¹é… (â‰¥0.7): {len(high_quality)} ä¸ª")
    print(f"  - ä¸­ç­‰è´¨é‡åŒ¹é… (0.4-0.7): {len(medium_quality)} ä¸ª")
    
    if matched_samples:
        avg_similarities = {
            "question": sum(s["similarity_scores"]["question"] for s in matched_samples) / len(matched_samples),
            "context": sum(s["similarity_scores"]["context"] for s in matched_samples) / len(matched_samples),
            "answer": sum(s["similarity_scores"]["answer"] for s in matched_samples) / len(matched_samples),
            "structured": sum(s["similarity_scores"]["structured"] for s in matched_samples) / len(matched_samples),
            "overall": sum(s["similarity_scores"]["overall"] for s in matched_samples) / len(matched_samples)
        }
        
        print(f"  - å¹³å‡ç›¸ä¼¼åº¦:")
        print(f"    é—®é¢˜: {avg_similarities['question']:.3f}")
        print(f"    ä¸Šä¸‹æ–‡: {avg_similarities['context']:.3f}")
        print(f"    ç­”æ¡ˆ: {avg_similarities['answer']:.3f}")
        print(f"    ç»“æ„åŒ–: {avg_similarities['structured']:.3f}")
        print(f"    ç»¼åˆ: {avg_similarities['overall']:.3f}")

def save_matched_samples(matched_samples: List[Dict], output_file: str):
    """ä¿å­˜åŒ¹é…çš„æ ·æœ¬"""
    print(f"\nğŸ’¾ ä¿å­˜åŒ¹é…æ ·æœ¬åˆ°: {output_file}")
    
    # è½¬æ¢ä¸ºè¯„ä¼°æ ¼å¼
    eval_samples = []
    for match in matched_samples:
        generated_sample = match["matched_sample"]
        
        # æå–è¯„ä¼°æ‰€éœ€å­—æ®µ
        eval_sample = {
            "query": generated_sample.get("question", ""),
            "context": generated_sample.get("context", ""),
            "answer": generated_sample.get("answer", ""),
            "doc_id": generated_sample.get("doc_id", ""),
            "relevant_doc_ids": generated_sample.get("relevant_doc_ids", []),
            "answer_from": generated_sample.get("answer_from", "unknown"),
            "similarity_scores": match["similarity_scores"],
            "match_quality": match["match_quality"]
        }
        eval_samples.append(eval_sample)
    
    # ä¿å­˜ä¸ºJSONLæ ¼å¼
    with open(output_file, 'w', encoding='utf-8') as f:
        for sample in eval_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    print(f"âœ… ä¿å­˜äº† {len(eval_samples)} ä¸ªè¯„ä¼°æ ·æœ¬")

def show_examples(matched_samples: List[Dict], num_examples: int = 3):
    """æ˜¾ç¤ºåŒ¹é…ç¤ºä¾‹"""
    print(f"\nğŸ“ åŒ¹é…ç¤ºä¾‹ (æ˜¾ç¤ºå‰{num_examples}ä¸ª):")
    
    for i, match in enumerate(matched_samples[:num_examples]):
        original = match["original_sample"]
        generated = match["matched_sample"]
        scores = match["similarity_scores"]
        
        print(f"\n--- ç¤ºä¾‹ {i+1} ---")
        print(f"åŒ¹é…è´¨é‡: {match['match_quality']}")
        print(f"ç»¼åˆç›¸ä¼¼åº¦: {scores['overall']:.3f}")
        print(f"åŸå§‹é—®é¢˜: {original.get('query', '')[:100]}...")
        print(f"ç”Ÿæˆé—®é¢˜: {generated.get('question', '')[:100]}...")
        print(f"åŸå§‹ç­”æ¡ˆ: {original.get('answer', '')[:50]}...")
        print(f"ç”Ÿæˆç­”æ¡ˆ: {generated.get('answer', '')[:50]}...")

def main():
    parser = argparse.ArgumentParser(description="ä»AlphaFinç”Ÿæˆæ•°æ®ä¸­æå–è¯„ä¼°æ ·æœ¬")
    parser.add_argument("--original_eval", type=str, 
                       default="evaluate_mrr/alphafin_eval.jsonl",
                       help="åŸå§‹è¯„ä¼°æ•°æ®æ–‡ä»¶")
    parser.add_argument("--generated_data", type=str,
                       default="data/alphafin/alphafin_merged_generated_qa_full_dedup.json",
                       help="LLMç”Ÿæˆçš„æ•°æ®æ–‡ä»¶")
    parser.add_argument("--output", type=str,
                       default="evaluate_mrr/alphafin_eval_from_generated.jsonl",
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--similarity_threshold", type=float, default=0.4,
                       help="ç›¸ä¼¼åº¦é˜ˆå€¼")
    parser.add_argument("--show_examples", action="store_true",
                       help="æ˜¾ç¤ºåŒ¹é…ç¤ºä¾‹")
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹ä»AlphaFinç”Ÿæˆæ•°æ®ä¸­æå–è¯„ä¼°æ ·æœ¬")
    print(f"ğŸ“Š é…ç½®:")
    print(f"  - åŸå§‹è¯„ä¼°æ•°æ®: {args.original_eval}")
    print(f"  - ç”Ÿæˆæ•°æ®: {args.generated_data}")
    print(f"  - è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"  - ç›¸ä¼¼åº¦é˜ˆå€¼: {args.similarity_threshold}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.original_eval).exists():
        print(f"âŒ åŸå§‹è¯„ä¼°æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.original_eval}")
        return
    
    if not Path(args.generated_data).exists():
        print(f"âŒ ç”Ÿæˆæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.generated_data}")
        return
    
    # åŠ è½½åŸå§‹è¯„ä¼°æ•°æ®
    print(f"\nğŸ“– åŠ è½½åŸå§‹è¯„ä¼°æ•°æ®: {args.original_eval}")
    original_eval_data = []
    with open(args.original_eval, 'r', encoding='utf-8') as f:
        for line in f:
            original_eval_data.append(json.loads(line))
    print(f"âœ… åŠ è½½äº† {len(original_eval_data)} ä¸ªåŸå§‹è¯„ä¼°æ ·æœ¬")
    
    # åŠ è½½ç”Ÿæˆæ•°æ®
    print(f"\nğŸ“– åŠ è½½ç”Ÿæˆæ•°æ®: {args.generated_data}")
    generated_data = []
    
    # å°è¯•ä¸åŒçš„åŠ è½½æ–¹å¼
    try:
        # é¦–å…ˆå°è¯•ä½œä¸ºJSONLæ ¼å¼åŠ è½½
        with open(args.generated_data, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    generated_data.append(json.loads(line))
        print(f"âœ… ä½œä¸ºJSONLæ ¼å¼åŠ è½½äº† {len(generated_data)} ä¸ªç”Ÿæˆæ ·æœ¬")
    except json.JSONDecodeError:
        # å¦‚æœJSONLå¤±è´¥ï¼Œå°è¯•ä½œä¸ºå•ä¸ªJSONæ–‡ä»¶åŠ è½½
        generated_data = []
        with open(args.generated_data, 'r', encoding='utf-8') as f:
            content = f.read()
            data = json.loads(content)
            if isinstance(data, list):
                generated_data = data
                print(f"âœ… ä½œä¸ºJSONæ•°ç»„åŠ è½½äº† {len(generated_data)} ä¸ªç”Ÿæˆæ ·æœ¬")
            elif isinstance(data, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œå¯èƒ½åŒ…å«æ•°æ®åˆ—è¡¨
                for key, value in data.items():
                    if isinstance(value, list):
                        generated_data = value
                        print(f"âœ… ä»JSONå¯¹è±¡ä¸­åŠ è½½äº† {len(generated_data)} ä¸ªç”Ÿæˆæ ·æœ¬ (é”®: {key})")
                        break
                if not generated_data:
                    print(f"âŒ æ— æ³•ä»JSONå¯¹è±¡ä¸­æ‰¾åˆ°æ•°æ®åˆ—è¡¨")
                    return
            else:
                print(f"âŒ ä¸æ”¯æŒçš„JSONæ ¼å¼: {type(data)}")
                return
    
    # æŸ¥æ‰¾åŒ¹é…æ ·æœ¬
    matched_samples = find_matching_samples(original_eval_data, generated_data, args.similarity_threshold)
    
    if not matched_samples:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ ·æœ¬ï¼Œè¯·é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼")
        return
    
    # åˆ†æåŒ¹é…è´¨é‡
    analyze_matching_quality(matched_samples)
    
    # æ˜¾ç¤ºç¤ºä¾‹
    if args.show_examples:
        show_examples(matched_samples)
    
    # ä¿å­˜åŒ¹é…æ ·æœ¬
    save_matched_samples(matched_samples, args.output)
    
    print(f"\nğŸ‰ å®Œæˆï¼æå–äº† {len(matched_samples)} ä¸ªè¯„ä¼°æ ·æœ¬")

if __name__ == "__main__":
    main() 