#!/usr/bin/env python3
"""
AlphaFinæ•°æ®è¯„ä¼°è„šæœ¬ï¼Œæ”¯æŒå…ƒæ•°æ®è¿‡æ»¤
åŸºäºä¸­æ–‡è¯„ä¼°è„šæœ¬ä½†é€‚é…AlphaFinæ•°æ®ç»“æ„
"""

import json
import argparse
import torch
import torch.nn.functional as F
import numpy as np
from pathlib import Path
from tqdm import tqdm
import re
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def extract_alphafin_metadata(context_text: str) -> dict:
    """ä»AlphaFinä¸Šä¸‹æ–‡æ–‡æœ¬ä¸­æå–å…ƒæ•°æ®"""
    metadata = {
        "company_name": "",
        "stock_code": "",
        "report_date": "",
        "report_title": ""
    }
    
    # æå–å…¬å¸åç§°å’Œè‚¡ç¥¨ä»£ç 
    company_pattern = r'([^ï¼ˆ]+)ï¼ˆ([0-9]{6}ï¼‰)'
    match = re.search(company_pattern, context_text)
    if match:
        metadata["company_name"] = match.group(1).strip()
        metadata["stock_code"] = match.group(2).strip()
    
    # æå–æŠ¥å‘Šæ—¥æœŸ
    date_pattern = r'(\d{4}-\d{2}-\d{2})'
    dates = re.findall(date_pattern, context_text)
    if dates:
        metadata["report_date"] = dates[0]
    
    # æå–æŠ¥å‘Šæ ‡é¢˜
    title_pattern = r'ç ”ç©¶æŠ¥å‘Šï¼Œå…¶æ ‡é¢˜æ˜¯ï¼š"([^"]+)"'
    title_match = re.search(title_pattern, context_text)
    if title_match:
        metadata["report_title"] = title_match.group(1).strip()
    
    return metadata

def filter_corpus_by_metadata(corpus_documents: dict, target_metadata: dict) -> dict:
    """æ ¹æ®å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢åº“"""
    if not target_metadata or not any(target_metadata.values()):
        return corpus_documents
    
    filtered_corpus = {}
    filter_criteria = []
    
    # æ„å»ºè¿‡æ»¤æ¡ä»¶
    if target_metadata.get("company_name"):
        filter_criteria.append(("company_name", target_metadata["company_name"]))
    if target_metadata.get("stock_code"):
        filter_criteria.append(("stock_code", target_metadata["stock_code"]))
    if target_metadata.get("report_date"):
        filter_criteria.append(("report_date", target_metadata["report_date"]))
    
    if not filter_criteria:
        return corpus_documents
    
    print(f"ğŸ” åº”ç”¨å…ƒæ•°æ®è¿‡æ»¤: {filter_criteria}")
    
    for doc_id, content in corpus_documents.items():
        content_metadata = extract_alphafin_metadata(content)
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ‰€æœ‰è¿‡æ»¤æ¡ä»¶
        matches_all = True
        for field, value in filter_criteria:
            if content_metadata.get(field) != value:
                matches_all = False
                break
        
        if matches_all:
            filtered_corpus[doc_id] = content
    
    print(f"ğŸ“Š è¿‡æ»¤ç»“æœ: {len(filtered_corpus)}/{len(corpus_documents)} ä¸ªæ–‡æ¡£")
    return filtered_corpus

def calculate_mrr(rankings):
    """è®¡ç®—MRRåˆ†æ•°"""
    if not rankings:
        return 0.0
    
    reciprocal_ranks = []
    for rank in rankings:
        if rank > 0:
            reciprocal_ranks.append(1.0 / rank)
        else:
            reciprocal_ranks.append(0.0)
    
    return np.mean(reciprocal_ranks)

def mean_pooling(model_output, attention_mask):
    """å¹³å‡æ± åŒ–"""
    token_embeddings = model_output[0]
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

def load_encoder_model(model_name: str, device: str):
    """åŠ è½½ç¼–ç å™¨æ¨¡å‹"""
    try:
        from transformers import AutoTokenizer, AutoModel
        print(f"ğŸ“– åŠ è½½ç¼–ç å™¨æ¨¡å‹: {model_name}")
        
        tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir="cache")
        model = AutoModel.from_pretrained(model_name, cache_dir="cache").to(device)
        
        # è®¾ç½®ç‰¹æ®Štoken
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        return tokenizer, model
    except Exception as e:
        print(f"âŒ åŠ è½½ç¼–ç å™¨æ¨¡å‹å¤±è´¥: {e}")
        return None, None

def load_reranker_model(model_name: str, device: str):
    """åŠ è½½é‡æ’åºæ¨¡å‹"""
    try:
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        print(f"ğŸ“– åŠ è½½é‡æ’åºæ¨¡å‹: {model_name}")
        
        tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir="cache")
        model = AutoModelForSequenceClassification.from_pretrained(model_name, cache_dir="cache").to(device)
        
        return tokenizer, model
    except Exception as e:
        print(f"âŒ åŠ è½½é‡æ’åºæ¨¡å‹å¤±è´¥: {e}")
        return None, None

def main():
    parser = argparse.ArgumentParser(description="AlphaFinæ•°æ®è¯„ä¼°è„šæœ¬")
    parser.add_argument("--eval_data", type=str, 
                       default="evaluate_mrr/alphafin_eval.jsonl",
                       help="è¯„ä¼°æ•°æ®æ–‡ä»¶")
    parser.add_argument("--corpus_data", type=str,
                       default="data/alphafin/alphafin_merged_generated_qa_full_dedup.json",
                       help="æ£€ç´¢åº“æ•°æ®æ–‡ä»¶")
    parser.add_argument("--encoder_model", type=str,
                       default="microsoft/DialoGPT-medium",
                       help="ç¼–ç å™¨æ¨¡å‹åç§°")
    parser.add_argument("--reranker_model", type=str,
                       default="microsoft/DialoGPT-medium",
                       help="é‡æ’åºæ¨¡å‹åç§°")
    parser.add_argument("--top_k_retrieval", type=int, default=100,
                       help="æ£€ç´¢top-k")
    parser.add_argument("--top_k_rerank", type=int, default=10,
                       help="é‡æ’åºtop-k")
    parser.add_argument("--max_samples", type=int, default=100,
                       help="æœ€å¤§è¯„ä¼°æ ·æœ¬æ•°")
    parser.add_argument("--use_metadata_filter", action="store_true",
                       help="æ˜¯å¦ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤")
    parser.add_argument("--device", type=str, default="cuda",
                       help="è®¾å¤‡é€‰æ‹©")
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹AlphaFinæ•°æ®è¯„ä¼°")
    print(f"ğŸ“Š é…ç½®:")
    print(f"  - è¯„ä¼°æ•°æ®: {args.eval_data}")
    print(f"  - æ£€ç´¢åº“æ•°æ®: {args.corpus_data}")
    print(f"  - ç¼–ç å™¨æ¨¡å‹: {args.encoder_model}")
    print(f"  - é‡æ’åºæ¨¡å‹: {args.reranker_model}")
    print(f"  - æœ€å¤§æ ·æœ¬æ•°: {args.max_samples}")
    print(f"  - å…ƒæ•°æ®è¿‡æ»¤: {'å¯ç”¨' if args.use_metadata_filter else 'ç¦ç”¨'}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.eval_data).exists():
        print(f"âŒ è¯„ä¼°æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.eval_data}")
        return
    
    if not Path(args.corpus_data).exists():
        print(f"âŒ æ£€ç´¢åº“æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.corpus_data}")
        return
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    encoder_tokenizer, encoder_model = load_encoder_model(args.encoder_model, device)
    reranker_tokenizer, reranker_model = load_reranker_model(args.reranker_model, device)
    
    if encoder_tokenizer is None or encoder_model is None:
        print("âŒ ç¼–ç å™¨æ¨¡å‹åŠ è½½å¤±è´¥")
        return
    
    if reranker_tokenizer is None or reranker_model is None:
        print("âŒ é‡æ’åºæ¨¡å‹åŠ è½½å¤±è´¥")
        return
    
    # åŠ è½½æ£€ç´¢åº“æ•°æ®
    print(f"ğŸ“– åŠ è½½æ£€ç´¢åº“æ•°æ®: {args.corpus_data}")
    with open(args.corpus_data, 'r', encoding='utf-8') as f:
        corpus_data = json.load(f)
    
    # æ„å»ºæ£€ç´¢åº“
    corpus_documents = {}
    for idx, item in enumerate(corpus_data):
        doc_id = str(idx)
        context = item.get('original_context', '')
        if context:
            corpus_documents[doc_id] = context
    
    print(f"âœ… æ„å»ºäº† {len(corpus_documents)} ä¸ªæ£€ç´¢åº“æ–‡æ¡£")
    
    # åŠ è½½è¯„ä¼°æ•°æ®
    print(f"ğŸ“– åŠ è½½è¯„ä¼°æ•°æ®: {args.eval_data}")
    eval_data = []
    with open(args.eval_data, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= args.max_samples:
                break
            eval_data.append(json.loads(line))
    
    print(f"âœ… åŠ è½½äº† {len(eval_data)} ä¸ªè¯„ä¼°æ ·æœ¬")
    
    # ç”Ÿæˆæ£€ç´¢åº“åµŒå…¥
    print("ğŸ”„ ç”Ÿæˆæ£€ç´¢åº“åµŒå…¥...")
    corpus_ids = list(corpus_documents.keys())
    corpus_texts = [corpus_documents[doc_id] for doc_id in corpus_ids]
    corpus_embeddings = []
    
    batch_size = 4
    max_length = 512
    
    for i in tqdm(range(0, len(corpus_texts), batch_size), desc="ç”Ÿæˆæ£€ç´¢åº“åµŒå…¥"):
        batch_texts = corpus_texts[i:i + batch_size]
        with torch.no_grad():
            encoded_input = encoder_tokenizer(
                batch_texts,
                padding='max_length',
                truncation=True,
                max_length=max_length,
                return_tensors='pt'
            ).to(device)
            
            model_output = encoder_model(**encoded_input)
            embeddings = mean_pooling(model_output, encoded_input['attention_mask'])
            embeddings = F.normalize(embeddings, p=2, dim=1)
            corpus_embeddings.append(embeddings.cpu())
    
    corpus_embeddings = torch.cat(corpus_embeddings, dim=0).to(device)
    print(f"âœ… ç”Ÿæˆäº† {corpus_embeddings.shape[0]} ä¸ªæ£€ç´¢åº“åµŒå…¥")
    
    # å¼€å§‹è¯„ä¼°
    all_retrieval_ranks = []
    all_rerank_ranks = []
    skipped_queries_count = 0
    
    print("ğŸš€ å¼€å§‹è¯„ä¼°...")
    for item in tqdm(eval_data, desc="è¯„ä¼°æŸ¥è¯¢"):
        query_text = item.get('query', '').strip()
        ground_truth_context = item.get('context', '')
        ground_truth_answer = item.get('answer', '')
        
        if not query_text or not ground_truth_context:
            skipped_queries_count += 1
            continue
        
        # åº”ç”¨å…ƒæ•°æ®è¿‡æ»¤
        if args.use_metadata_filter:
            query_metadata = extract_alphafin_metadata(ground_truth_context)
            filtered_corpus = filter_corpus_by_metadata(corpus_documents, query_metadata)
            
            if not filtered_corpus:
                print(f"âš ï¸  æŸ¥è¯¢ '{query_text[:50]}...' æ— åŒ¹é…çš„è¿‡æ»¤æ–‡æ¡£ï¼Œä½¿ç”¨å®Œæ•´æ£€ç´¢åº“")
                filtered_corpus = corpus_documents
        else:
            filtered_corpus = corpus_documents
        
        # æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆçš„æ–‡æ¡£ID
        ground_truth_doc_id = None
        for doc_id, content in filtered_corpus.items():
            if content == ground_truth_context:
                ground_truth_doc_id = doc_id
                break
        
        if ground_truth_doc_id is None:
            skipped_queries_count += 1
            continue
        
        # 1. æ£€ç´¢é˜¶æ®µ
        with torch.no_grad():
            query_encoded = encoder_tokenizer(
                query_text,
                padding='max_length',
                truncation=True,
                max_length=max_length,
                return_tensors='pt'
            ).to(device)
            
            model_output = encoder_model(**query_encoded)
            embeddings = mean_pooling(model_output, query_encoded['attention_mask'])
            query_embedding = F.normalize(embeddings, p=2, dim=1)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = torch.matmul(query_embedding, corpus_embeddings.transpose(0, 1))
            
            # è·å–top-kæ£€ç´¢ç»“æœ
            top_k_values, top_k_indices = torch.topk(
                similarities, 
                min(args.top_k_retrieval, len(corpus_documents)), 
                dim=1
            )
            
            retrieved_doc_ids_and_scores = []
            for i, idx in enumerate(top_k_indices[0]):
                doc_id = corpus_ids[idx.item()]
                if doc_id in filtered_corpus:  # åªè€ƒè™‘è¿‡æ»¤åçš„æ–‡æ¡£
                    score = top_k_values[0][i].item()
                    retrieved_doc_ids_and_scores.append((doc_id, score))
        
        # è®¡ç®—æ£€ç´¢æ’å
        retrieval_rank = 0
        for rank, (doc_id, _) in enumerate(retrieved_doc_ids_and_scores, 1):
            if doc_id == ground_truth_doc_id:
                retrieval_rank = rank
                break
        all_retrieval_ranks.append(retrieval_rank)
        
        # 2. é‡æ’åºé˜¶æ®µ
        if reranker_model and retrieved_doc_ids_and_scores:
            rerank_data = []
            for doc_id, _ in retrieved_doc_ids_and_scores[:args.top_k_rerank]:
                doc_text = filtered_corpus.get(doc_id, "")
                if doc_text:
                    # æ„å»ºé‡æ’åºè¾“å…¥
                    rerank_input = f"Query: {query_text}\nDocument: {doc_text}"
                    rerank_data.append((rerank_input, doc_id))
            
            if rerank_data:
                reranked_results = []
                reranker_batch_size = 4
                
                for j in range(0, len(rerank_data), reranker_batch_size):
                    batch_inputs = [item[0] for item in rerank_data[j:j + reranker_batch_size]]
                    batch_doc_ids = [item[1] for item in rerank_data[j:j + reranker_batch_size]]
                    
                    with torch.no_grad():
                        encoded_input = reranker_tokenizer(
                            batch_inputs,
                            padding='max_length',
                            truncation=True,
                            max_length=max_length,
                            return_tensors='pt'
                        ).to(device)
                        
                        outputs = reranker_model(**encoded_input)
                        scores = torch.softmax(outputs.logits, dim=1)[:, 1].tolist()
                        
                        for k, score in enumerate(scores):
                            reranked_results.append({
                                'doc_id': batch_doc_ids[k],
                                'score': score
                            })
                
                # æŒ‰åˆ†æ•°æ’åº
                reranked_results.sort(key=lambda x: x['score'], reverse=True)
                
                # è®¡ç®—é‡æ’åºæ’å
                rerank_rank = 0
                for rank, res in enumerate(reranked_results, 1):
                    if res['doc_id'] == ground_truth_doc_id:
                        rerank_rank = rank
                        break
                all_rerank_ranks.append(rerank_rank)
            else:
                all_rerank_ranks.append(0)
        else:
            all_rerank_ranks.append(0)
    
    # è®¡ç®—MRRåˆ†æ•°
    mrr_retrieval = calculate_mrr(all_retrieval_ranks)
    mrr_rerank = calculate_mrr(all_rerank_ranks)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*50)
    print("ğŸ“Š è¯„ä¼°ç»“æœ")
    print("="*50)
    print(f"æ€»æŸ¥è¯¢æ•°: {len(eval_data)}")
    print(f"è·³è¿‡çš„æŸ¥è¯¢æ•°: {skipped_queries_count}")
    print(f"æœ‰æ•ˆæŸ¥è¯¢æ•°: {len(eval_data) - skipped_queries_count}")
    print(f"æ£€ç´¢MRR @{args.top_k_retrieval}: {mrr_retrieval:.4f}")
    print(f"é‡æ’åºMRR @{args.top_k_rerank}: {mrr_rerank:.4f}")
    
    if args.use_metadata_filter:
        print(f"âœ… å…ƒæ•°æ®è¿‡æ»¤å·²å¯ç”¨")
    else:
        print(f"â„¹ï¸  å…ƒæ•°æ®è¿‡æ»¤æœªå¯ç”¨")

if __name__ == "__main__":
    main() 