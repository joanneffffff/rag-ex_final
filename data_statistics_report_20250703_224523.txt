
================================================================================
📊 完整数据概况总结报告
================================================================================
=== AlphaFin原始数据分析 ===

📊 原始样本总数: 167,362 个样本
📁 文件大小: 425M
📋 字段列表: ['instruction', 'input', 'output', 'split']

📝 示例记录:
{
  "instruction": "我是一位股票分析师，我需要利用以下新闻信息来更好地完成金融分析，请你对下列新闻提取出可能对我有帮助的关键信息，形成更精简的新闻摘要。新闻具体内容如下：\n",
  "input": "2023-08-10 10:06:52_;莫斯科市长：俄罗斯的防空系统击落了两架朝莫斯科方向飞行的军用无人机。",
  "output": "莫斯科市长宣布，俄罗斯的防空系统成功击落了两架朝莫斯科方向飞行的军用无人机。",
  "split": "train"
}...

=== AlphaFin过滤后数据分析 ===

📊 过滤后样本数: 33,524 个样本
🗑️  过滤率: 80.0% (133,838/167,362)

=== AlphaFin LLM处理后数据分析 ===

📊 LLM处理后样本数: 27,596 个样本
📋 元数据覆盖率:
   company_name: 25,927/27,596 (94.0%)
   stock_code: 25,407/27,596 (92.1%)
   report_date: 3,549/27,596 (12.9%)
📊 总体元数据覆盖率: 100.0%

📏 长度统计:
   Context平均长度: 1609.1 字符
   Answer平均长度: 46.3 字符
   Question平均长度: 244.0 字符
   Context长度范围: 73 - 12012 字符
   Answer长度范围: 4 - 1373 字符
   Question长度范围: 9 - 5390 字符

=== TatQA原始数据分析 ===

📊 原始样本总数: 2,757 个样本
  训练集: 2,201 个样本
  验证集: 278 个样本
  测试集: 278 个样本
📁 文件大小: 18M
❓ 原始问题总数: 16,552 个问题

📝 示例记录:
{
  "table": {
    "uid": "e78f8b29-6085-43de-b32f-be1a68641be3",
    "table": [
      [
        "",
        "2019 %",
        "2018 %",
        "2017 %"
      ],
      [
        "Weighted average actuarial assumptions used at 31 March1:",
        "",
        "",
        ""
      ],
      [
        "Rate of inflation2",
        "2.9",
        "2.9",
        "3.0"
      ],
      [
        "Rate of increase in salaries",
        "2.7",
        "2.7",
        "2.6"
      ],
      [
        "Discount rate",
        "2.3",
        "2.5",
        "2.6"
      ]
    ]
  },
  "paragraphs": [
    {
      "uid": "62be4f5a-1693-4e6b-8bb4-0a4e1e40b409",
      "order": 1,
      "text": "Actuarial assumptions"
    },
    {
      "uid": "c63e6ed5-8fe5-46e4-a02a-f923e90e8067",
      "order": 2,
      "text...

=== TatQA转换后数据分析 ===

📊 转换后样本总数: 16,546 个样本
  训练集: 14,883 个样本
  评估集: 1,663 个样本

📋 答案来源分布 (评估集):
   text: 381 (22.9%)
   table-text: 546 (32.8%)
   table: 736 (44.3%)

📏 长度统计 (评估集):
   Context平均长度: 693.0 字符
   Answer平均长度: 26.9 字符
   Question平均长度: 72.7 字符

📊 元数据覆盖率:
   doc_id覆盖率: 100.0%
   relevant_doc_ids覆盖率: 100.0%

================================================================================
📋 最终统计总结
================================================================================

● 1.1 原始数据概况 (Raw Data Overview):
  中文数据 (AlphaFin): 167,362 个样本，425M
  英文数据 (TatQA): 2,757 个样本，18M
  TatQA原始问题总数: 16,552 个问题

● 1.2 LLM (Qwen2-7B) 自动化数据处理:
  核心功能:
    - 元数据提取器: 自动提取company_name, stock_code, report_date
    - 问题生成器: 基于Context和Answer生成Question
    - 摘要生成器: 基于Context生成Summary
  元数据覆盖率: 94.0% (company_name)

● 1.3 处理后数据统计 (Processed Data Statistics):
  中文 (QCA): 27,596 个样本
  英文 (QCA): 16,546 个样本 (训练: 14,883, 评估: 1,663)

● 1.4 TatQA 数据转换过程与质量:
  关键步骤: Table Textualization将表格转换为自然语言
  转换率: 100.0% (16,546/16,552)
  过滤率: 0.0%
  主要原因: answer_type=table但rel_paragraphs为空，表格转换逻辑缺陷

● AlphaFin 数据处理流程:
  原始数据过滤率: 80.0%
  LLM处理后样本数: 27,596
  元数据覆盖率: company_name(94.0%), stock_code(92.1%), report_date(12.9%)

================================================================================
✅ 数据概况分析完成
================================================================================
