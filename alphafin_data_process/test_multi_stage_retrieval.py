#!/usr/bin/env python3
"""
æµ‹è¯•å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿ
"""

import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

def test_multi_stage_retrieval():
    """æµ‹è¯•å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿ"""
    try:
        # å¯¼å…¥å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿ
        from multi_stage_retrieval_final import MultiStageRetrievalSystem
        
        # æ•°æ®æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
        data_path = Path("../data/alphafin/alphafin_merged_generated_qa.json")
        
        if not data_path.exists():
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨")
            return
        
        print("âœ… å¼€å§‹æµ‹è¯•å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿ...")
        print(f"æ•°æ®æ–‡ä»¶: {data_path}")
        
        # åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿï¼ˆä¸­æ–‡æ•°æ®ï¼‰
        print("\nğŸ“Š åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ...")
        retrieval_system = MultiStageRetrievalSystem(
            data_path=data_path, 
            dataset_type="chinese"
        )
        
        # æµ‹è¯•æ£€ç´¢åŠŸèƒ½
        print("\nğŸ” æµ‹è¯•æ£€ç´¢åŠŸèƒ½...")
        
        # æµ‹è¯•1ï¼šåŸºäºå…¬å¸åç§°çš„æ£€ç´¢
        print("\næµ‹è¯•1: åŸºäºå…¬å¸åç§°çš„æ£€ç´¢")
        results1 = retrieval_system.search(
            query="å…¬å¸ä¸šç»©è¡¨ç°å¦‚ä½•ï¼Ÿ",
            company_name="ä¸­å›½å®æ­¦",
            top_k=3
        )
        
        print(f"æ‰¾åˆ° {len(results1)} æ¡ç»“æœ:")
        for i, result in enumerate(results1):
            print(f"  {i+1}. {result['company_name']} ({result['stock_code']}) - åˆ†æ•°: {result['combined_score']:.4f}")
        
        # æµ‹è¯•2ï¼šé€šç”¨æ£€ç´¢
        print("\næµ‹è¯•2: é€šç”¨æ£€ç´¢")
        results2 = retrieval_system.search(
            query="é’¢é“è¡Œä¸šå‘å±•è¶‹åŠ¿",
            top_k=3
        )
        
        print(f"æ‰¾åˆ° {len(results2)} æ¡ç»“æœ:")
        for i, result in enumerate(results2):
            print(f"  {i+1}. {result['company_name']} ({result['stock_code']}) - åˆ†æ•°: {result['combined_score']:.4f}")
        
        # æµ‹è¯•3ï¼šè‹±æ–‡æŸ¥è¯¢ï¼ˆåº”è¯¥ä¹Ÿèƒ½å·¥ä½œï¼‰
        print("\næµ‹è¯•3: è‹±æ–‡æŸ¥è¯¢")
        results3 = retrieval_system.search(
            query="steel industry development",
            top_k=3
        )
        
        print(f"æ‰¾åˆ° {len(results3)} æ¡ç»“æœ:")
        for i, result in enumerate(results3):
            print(f"  {i+1}. {result['company_name']} ({result['stock_code']}) - åˆ†æ•°: {result['combined_score']:.4f}")
        
        print("\nâœ… å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å®‰è£…äº†å¿…è¦çš„ä¾èµ–:")
        print("pip install faiss-cpu sentence-transformers torch")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_english_dataset():
    """æµ‹è¯•è‹±æ–‡æ•°æ®é›†ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰è‹±æ–‡æ•°æ®æ–‡ä»¶ - ä½¿ç”¨åŸå§‹tatqaæ•°æ®
        english_data_path = Path("../data/tatqa_dataset_raw/tatqa_dataset_train.json")
        
        if not english_data_path.exists():
            print(f"âŒ è‹±æ–‡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {english_data_path}")
            return
        
        print("\nğŸŒ æµ‹è¯•è‹±æ–‡æ•°æ®é›†...")
        print("æ³¨æ„ï¼šåŸå§‹tatqaæ•°æ®æ ¼å¼å¯èƒ½ä¸åŒï¼Œéœ€è¦é¢„å¤„ç†")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ tatqaæ•°æ®çš„é¢„å¤„ç†é€»è¾‘
        print("tatqaæ•°æ®éœ€è¦å…ˆè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼æ‰èƒ½ä½¿ç”¨å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿ")
        
    except Exception as e:
        print(f"âŒ è‹±æ–‡æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤šé˜¶æ®µæ£€ç´¢ç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•ä¸­æ–‡æ•°æ®é›†
    test_multi_stage_retrieval()
    
    # æµ‹è¯•è‹±æ–‡æ•°æ®é›†
    test_english_dataset()
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main() 