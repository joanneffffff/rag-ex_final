#!/usr/bin/env python3
"""
ä»TatQAè¯„ä¼°æ•°æ®é›†ä¸­ç­‰é‡æŠ½å–ä¸‰ç±»æ ·æœ¬ç”Ÿæˆæµ‹è¯•é›†
æŒ‰answer_fromå­—æ®µåˆ†ç»„ï¼štext/table/table+textï¼Œæ¯ç»„ç­‰é‡æŠ½å–ï¼Œæ€»è®¡100æ¡
"""

import json
import random
import argparse
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict

def sample_tatqa_eval_testset(
    input_file: str,
    output_file: str,
    total_samples: int = 100,
    seed: int = 42
) -> Dict[str, Any]:
    """
    ä»TatQAè¯„ä¼°æ•°æ®é›†ä¸­ç­‰é‡æŠ½å–æ ·æœ¬ç”Ÿæˆæµ‹è¯•é›†
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        total_samples: æ€»æ ·æœ¬æ•°
        seed: éšæœºç§å­
        
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    # è®¾ç½®éšæœºç§å­
    random.seed(seed)
    
    print(f"å¼€å§‹ä» {input_file} æŠ½å–æµ‹è¯•é›†...")
    print(f"ç›®æ ‡æ ·æœ¬æ•°: {total_samples}")
    print(f"éšæœºç§å­: {seed}")
    
    # è¯»å–åŸå§‹æ•°æ®
    data_by_type = defaultdict(list)
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if line.strip():
                    try:
                        item = json.loads(line)
                        answer_from = item.get('answer_from', 'unknown')
                        data_by_type[answer_from].append(item)
                    except json.JSONDecodeError as e:
                        print(f"è­¦å‘Š: ç¬¬{line_num}è¡ŒJSONè§£æå¤±è´¥: {e}")
                        continue
        
        print(f"åŸå§‹æ•°æ®ç»Ÿè®¡:")
        for data_type, items in data_by_type.items():
            print(f"  {data_type}: {len(items)} æ¡")
        
    except FileNotFoundError:
        print(f"é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return {}
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return {}
    
    # ç¡®å®šç›®æ ‡æ•°æ®ç±»å‹
    target_types = ['text', 'table', 'table+text']
    available_types = [t for t in target_types if t in data_by_type]
    
    if not available_types:
        print("é”™è¯¯: æœªæ‰¾åˆ°ç›®æ ‡æ•°æ®ç±»å‹")
        return {}
    
    print(f"\nç›®æ ‡æ•°æ®ç±»å‹: {available_types}")
    
    # è®¡ç®—æ¯ç»„æ ·æœ¬æ•°
    samples_per_type = total_samples // len(available_types)
    remainder = total_samples % len(available_types)
    
    print(f"æ¯ç»„æ ·æœ¬æ•°: {samples_per_type}")
    if remainder > 0:
        print(f"é¢å¤–åˆ†é…: {remainder} æ¡")
    
    # æŠ½å–æ ·æœ¬
    sampled_data = []
    stats = {}
    
    for i, data_type in enumerate(available_types):
        items = data_by_type[data_type]
        
        # è®¡ç®—å½“å‰ç±»å‹åº”æŠ½å–çš„æ ·æœ¬æ•°
        current_samples = samples_per_type
        if i < remainder:  # ä¼˜å…ˆåˆ†é…ç»™å‰é¢çš„ç±»å‹
            current_samples += 1
        
        # ç¡®ä¿ä¸è¶…è¿‡å¯ç”¨æ ·æœ¬æ•°
        current_samples = min(current_samples, len(items))
        
        # éšæœºæŠ½å–
        sampled_items = random.sample(items, current_samples)
        sampled_data.extend(sampled_items)
        
        stats[data_type] = {
            'available': len(items),
            'sampled': current_samples
        }
        
        print(f"  {data_type}: å¯ç”¨{len(items)}æ¡ â†’ æŠ½å–{current_samples}æ¡")
    
    # æ‰“ä¹±æ ·æœ¬é¡ºåº
    random.shuffle(sampled_data)
    
    # ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶
    try:
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            for item in sampled_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"\næµ‹è¯•é›†å·²ä¿å­˜åˆ°: {output_file}")
        print(f"æ€»æ ·æœ¬æ•°: {len(sampled_data)}")
        
    except Exception as e:
        print(f"é”™è¯¯: ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return {}
    
    # éªŒè¯è¾“å‡º
    print(f"\nè¾“å‡ºéªŒè¯:")
    output_stats = defaultdict(int)
    with open(output_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                item = json.loads(line)
                answer_from = item.get('answer_from', 'unknown')
                output_stats[answer_from] += 1
    
    for data_type, count in output_stats.items():
        print(f"  {data_type}: {count} æ¡")
    
    # è¿”å›ç»Ÿè®¡ä¿¡æ¯
    result_stats = {
        'input_file': input_file,
        'output_file': output_file,
        'total_samples': len(sampled_data),
        'target_samples': total_samples,
        'sampling_stats': stats,
        'output_stats': dict(output_stats)
    }
    
    return result_stats

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ä»TatQAè¯„ä¼°æ•°æ®é›†ä¸­ç­‰é‡æŠ½å–æ ·æœ¬ç”Ÿæˆæµ‹è¯•é›†")
    parser.add_argument('--input_file', type=str, 
                       default='evaluate_mrr/tatqa_eval_enhanced.jsonl',
                       help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_file', type=str, 
                       default='evaluate_mrr/tatqa_eval_test_100.jsonl',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--total_samples', type=int, default=100,
                       help='æ€»æ ·æœ¬æ•°')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    try:
        # æ‰§è¡ŒæŠ½æ ·
        stats = sample_tatqa_eval_testset(
            input_file=args.input_file,
            output_file=args.output_file,
            total_samples=args.total_samples,
            seed=args.seed
        )
        
        if stats:
            print(f"\nâœ… æµ‹è¯•é›†ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {stats['output_file']}")
            print(f"ğŸ“Š æ ·æœ¬æ€»æ•°: {stats['total_samples']}")
        else:
            print("âŒ æµ‹è¯•é›†ç”Ÿæˆå¤±è´¥!")
            return 1
        
        return 0
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit(main()) 