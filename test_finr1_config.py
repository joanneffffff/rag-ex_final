#!/usr/bin/env python3
"""
æµ‹è¯•Fin-R1é…ç½®æ˜¯å¦æ­£ç¡®
"""

import sys
from pathlib import Path

# Add parent directory to path
sys.path.append(str(Path(__file__).parent))

from config.parameters import Config
from xlm.components.generator.local_llm_generator import LocalLLMGenerator

def test_finr1_config():
    print("ğŸ”§ æµ‹è¯•Fin-R1é…ç½®...")
    
    # åŠ è½½é…ç½®
    config = Config()
    
    print(f"ğŸ“‹ æ¨¡å‹åç§°: {config.generator.model_name}")
    print(f"ğŸ“‹ è®¾å¤‡: {config.generator.device}")
    print(f"ğŸ“‹ é‡åŒ–: {config.generator.use_quantization} ({config.generator.quantization_type})")
    print(f"ğŸ“‹ max_new_tokens: {config.generator.max_new_tokens}")
    print(f"ğŸ“‹ do_sample: {config.generator.do_sample}")
    print(f"ğŸ“‹ repetition_penalty: {config.generator.repetition_penalty}")
    print(f"ğŸ“‹ eos_token_id: {config.generator.eos_token_id}")
    
    # æµ‹è¯•ç”Ÿæˆå™¨åˆå§‹åŒ–
    try:
        print("\nğŸ”§ åˆå§‹åŒ–ç”Ÿæˆå™¨...")
        generator = LocalLLMGenerator()
        
        print(f"âœ… ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"ğŸ“‹ æ¨¡å‹è®¾å¤‡: {next(generator.model.parameters()).device}")
        print(f"ğŸ“‹ æ¨¡å‹åç§°: {generator.model_name}")
        
        # æµ‹è¯•ç®€å•ç”Ÿæˆ
        test_prompt = "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"
        print(f"\nğŸ§ª æµ‹è¯•ç”Ÿæˆ: {test_prompt}")
        
        responses = generator.generate([test_prompt])
        print(f"âœ… ç”ŸæˆæˆåŠŸ: {responses[0][:100]}...")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_finr1_config() 