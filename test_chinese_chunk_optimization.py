#!/usr/bin/env python3
"""æµ‹è¯•ä¸­æ–‡chunkä¼˜åŒ–æ•ˆæœ"""

import json
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent))

def test_chinese_chunk_optimization():
    """æµ‹è¯•ä¸­æ–‡chunkä¼˜åŒ–æ•ˆæœ"""
    print("=== æµ‹è¯•ä¸­æ–‡chunkä¼˜åŒ–æ•ˆæœ ===")
    
    try:
        from xlm.utils.optimized_data_loader import OptimizedDataLoader
        
        print("1. åŠ è½½ä¼˜åŒ–åçš„ä¸­æ–‡æ•°æ®...")
        data_loader = OptimizedDataLoader(
            data_dir="data",
            max_samples=100,  # åªåŠ è½½100ä¸ªæ ·æœ¬
            chinese_document_level=True,
            english_chunk_level=True,
            include_eval_data=False  # ä¸åŒ…å«è¯„ä¼°æ•°æ®
        )
        
        chinese_chunks = data_loader.chinese_docs
        english_chunks = data_loader.english_docs
        
        print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ:")
        print(f"      ä¸­æ–‡chunks: {len(chinese_chunks)}")
        print(f"      è‹±æ–‡chunks: {len(english_chunks)}")
        
        # åˆ†æä¸­æ–‡chunké•¿åº¦åˆ†å¸ƒ
        chinese_lengths = [len(doc.content) for doc in chinese_chunks]
        english_lengths = [len(doc.content) for doc in english_chunks]
        
        print(f"\n2. ä¸­æ–‡chunké•¿åº¦åˆ†æ:")
        print(f"   å¹³å‡é•¿åº¦: {sum(chinese_lengths)/len(chinese_lengths):.0f} å­—ç¬¦")
        print(f"   æœ€å°é•¿åº¦: {min(chinese_lengths)} å­—ç¬¦")
        print(f"   æœ€å¤§é•¿åº¦: {max(chinese_lengths)} å­—ç¬¦")
        print(f"   é•¿åº¦åˆ†å¸ƒ:")
        print(f"     çŸ­æ–‡æ¡£ (â‰¤1000å­—ç¬¦): {len([l for l in chinese_lengths if l <= 1000])}")
        print(f"     ä¸­æ–‡æ¡£ (1000-5000å­—ç¬¦): {len([l for l in chinese_lengths if 1000 < l <= 5000])}")
        print(f"     é•¿æ–‡æ¡£ (>5000å­—ç¬¦): {len([l for l in chinese_lengths if l > 5000])}")
        
        print(f"\n3. è‹±æ–‡chunké•¿åº¦åˆ†æ:")
        print(f"   å¹³å‡é•¿åº¦: {sum(english_lengths)/len(english_lengths):.0f} å­—ç¬¦")
        print(f"   æœ€å°é•¿åº¦: {min(english_lengths)} å­—ç¬¦")
        print(f"   æœ€å¤§é•¿åº¦: {max(english_lengths)} å­—ç¬¦")
        
        # è®¡ç®—chunkæ¯”ä¾‹
        chinese_english_ratio = len(chinese_chunks) / len(english_chunks)
        print(f"\n4. Chunkæ¯”ä¾‹åˆ†æ:")
        print(f"   ä¸­æ–‡/è‹±æ–‡chunkæ¯”ä¾‹: {chinese_english_ratio:.2f}")
        
        if chinese_english_ratio > 5:
            print("   âš ï¸  ä¸­æ–‡chunkä»ç„¶è¿‡å¤šï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        elif chinese_english_ratio > 2:
            print("   âš ï¸  ä¸­æ–‡chunkè¾ƒå¤šï¼Œä½†å¯ä»¥æ¥å—")
        else:
            print("   âœ… ä¸­æ–‡chunkæ•°é‡åˆç†")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
        print(f"\n5. ä¸­æ–‡chunkç¤ºä¾‹:")
        if chinese_chunks:
            sample_doc = chinese_chunks[0]
            print(f"   æ¥æº: {sample_doc.metadata.source}")
            print(f"   é•¿åº¦: {len(sample_doc.content)} å­—ç¬¦")
            print(f"   å†…å®¹é¢„è§ˆ: {sample_doc.content[:200]}...")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«JSONæ ¼å¼
            if '{' in sample_doc.content and '}' in sample_doc.content:
                print("   âœ… ä¿æŒåŸå§‹JSONæ ¼å¼")
            else:
                print("   âš ï¸  å¯èƒ½è¢«è½¬æ¢äº†")
        
        # ä¼˜åŒ–å»ºè®®
        print(f"\n6. ä¼˜åŒ–å»ºè®®:")
        
        if chinese_english_ratio > 5:
            print("   ğŸ”§ å»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–:")
            print("      - å¢åŠ æ–‡æ¡£é•¿åº¦é˜ˆå€¼ï¼ˆå¦‚ä»8192å¢åŠ åˆ°16384ï¼‰")
            print("      - å‡å°‘æ–‡æ¡£åˆ†å‰²é¢‘ç‡")
            print("      - è€ƒè™‘ä½¿ç”¨æ›´å¤§çš„chunkå•ä½")
        else:
            print("   âœ… å½“å‰chunkç­–ç•¥åˆç†")
        
        # ä¸ä¹‹å‰ç»“æœå¯¹æ¯”
        print(f"\n7. ä¸ä¹‹å‰ç»“æœå¯¹æ¯”:")
        print(f"   ä¹‹å‰ä¸­æ–‡chunks: 6259ä¸ª")
        print(f"   ç°åœ¨ä¸­æ–‡chunks: {len(chinese_chunks)}ä¸ª")
        print(f"   æ”¹è¿›æ¯”ä¾‹: {(6259 - len(chinese_chunks)) / 6259 * 100:.1f}%")
        
        if len(chinese_chunks) < 6259:
            print("   ğŸ‰ æˆåŠŸå‡å°‘äº†ä¸­æ–‡chunkæ•°é‡ï¼")
        else:
            print("   âš ï¸  éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_chinese_chunk_optimization() 