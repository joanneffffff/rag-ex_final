#!/usr/bin/env python3
"""
æ·±å…¥åˆ†æcontextç±»å‹ä¸answer_fromç±»å‹ä¹‹é—´çš„æ˜ å°„å…³ç³»
"""

import json
import re
from collections import Counter, defaultdict
from pathlib import Path

def determine_context_type(context):
    """æ ¹æ®contextå†…å®¹åˆ¤æ–­ç»“æ„ç±»å‹"""
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«è¡¨æ ¼æ ‡è¯†
    has_table = "Table ID:" in context
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜æ˜¾çš„æ–‡æœ¬æ®µè½ï¼ˆéè¡¨æ ¼å†…å®¹ï¼‰
    lines = context.split('\n')
    table_lines = 0
    text_lines = 0
    
    for line in lines:
        line = line.strip()
        if line.startswith(('Table ID:', 'Headers:', 'Row', 'Category:')):
            table_lines += 1
        elif line and not line.startswith(('Table ID:', 'Headers:', 'Row', 'Category:')):
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹ï¼ˆä¸æ˜¯ç©ºè¡Œæˆ–çº¯æ•°å­—ï¼‰
            if len(line) > 10 and not re.match(r'^[\d\s\-\.,$%()]+$', line):
                text_lines += 1
    
    # åˆ¤æ–­ç±»å‹
    if has_table and text_lines > 2:
        return "table-text"
    elif has_table:
        return "table"
    else:
        return "text"

def analyze_mapping_relationship(file_path):
    """åˆ†æcontextç±»å‹ä¸answer_fromçš„æ˜ å°„å…³ç³»"""
    
    # ç»Ÿè®¡æ˜ å°„å…³ç³»
    mapping_stats = defaultdict(Counter)
    context_answer_examples = defaultdict(list)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            data = json.loads(line.strip())
            context = data.get('context', '')
            answer_from = data.get('answer_from', 'unknown')
            query = data.get('query', '')
            answer = data.get('answer', '')
            
            context_type = determine_context_type(context)
            
            # ç»Ÿè®¡æ˜ å°„å…³ç³»
            mapping_stats[context_type][answer_from] += 1
            
            # ä¿å­˜ç¤ºä¾‹ï¼ˆæ¯ä¸ªæ˜ å°„å…³ç³»ä¿å­˜å‰3ä¸ªç¤ºä¾‹ï¼‰
            if len(context_answer_examples[f"{context_type}->{answer_from}"]) < 3:
                example = {
                    "line": i + 1,
                    "query": query,
                    "answer": answer,
                    "context_preview": context[:300] + "..." if len(context) > 300 else context
                }
                context_answer_examples[f"{context_type}->{answer_from}"].append(example)
    
    return mapping_stats, context_answer_examples

def print_mapping_analysis(file_path, mapping_stats, context_answer_examples):
    """æ‰“å°æ˜ å°„åˆ†æç»“æœ"""
    
    print(f"\n=== {Path(file_path).name} Contextç±»å‹ -> Answer_from æ˜ å°„åˆ†æ ===")
    
    total_samples = sum(sum(counter.values()) for counter in mapping_stats.values())
    print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
    
    # åˆ†ææ¯ä¸ªcontextç±»å‹çš„æ˜ å°„
    for context_type in ["table", "text", "table-text"]:
        if context_type in mapping_stats:
            print(f"\nğŸ“Š Contextç±»å‹: '{context_type}'")
            total_for_type = sum(mapping_stats[context_type].values())
            
            for answer_from, count in mapping_stats[context_type].most_common():
                percentage = (count / total_for_type) * 100
                print(f"  -> answer_from='{answer_from}': {count} ({percentage:.1f}%)")
            
            # æ˜¾ç¤ºç¤ºä¾‹
            print(f"\n  ğŸ“ ç¤ºä¾‹:")
            for answer_from, count in mapping_stats[context_type].most_common():
                key = f"{context_type}->{answer_from}"
                if key in context_answer_examples:
                    for i, example in enumerate(context_answer_examples[key], 1):
                        print(f"    {i}. {context_type} -> {answer_from}:")
                        print(f"       é—®é¢˜: {example['query']}")
                        print(f"       ç­”æ¡ˆ: {example['answer']}")
                        print(f"       Contexté¢„è§ˆ: {example['context_preview'][:100]}...")
                        print()

def analyze_decision_rules(mapping_stats):
    """åˆ†æå†³ç­–è§„åˆ™"""
    
    print("\nğŸ¯ Contextç±»å‹ -> Answer_from å†³ç­–è§„åˆ™åˆ†æ")
    
    rules = {}
    
    for context_type in ["table", "text", "table-text"]:
        if context_type in mapping_stats:
            total = sum(mapping_stats[context_type].values())
            most_common = mapping_stats[context_type].most_common(1)[0]
            confidence = (most_common[1] / total) * 100
            
            rules[context_type] = {
                "most_likely": most_common[0],
                "confidence": confidence,
                "distribution": dict(mapping_stats[context_type])
            }
            
            print(f"\nğŸ“‹ Contextç±»å‹ '{context_type}':")
            print(f"  æœ€å¯èƒ½çš„answer_from: '{most_common[0]}' (ç½®ä¿¡åº¦: {confidence:.1f}%)")
            print(f"  å®Œæ•´åˆ†å¸ƒ: {dict(mapping_stats[context_type])}")
    
    return rules

def generate_decision_algorithm(rules):
    """ç”Ÿæˆå†³ç­–ç®—æ³•"""
    
    print("\nğŸš€ æ¨èçš„å†³ç­–ç®—æ³•:")
    
    algorithm = """
def predict_answer_from_by_context(context):
    \"\"\"
    æ ¹æ®contextå†…å®¹é¢„æµ‹answer_fromç±»å‹
    \"\"\"
    context_type = determine_context_type(context)
    
    # å†³ç­–è§„åˆ™ï¼ˆåŸºäºå®é™…æ•°æ®ç»Ÿè®¡ï¼‰
    if context_type == "text":
        return "text"  # ç½®ä¿¡åº¦: 100%
    elif context_type == "table":
        # éœ€è¦è¿›ä¸€æ­¥åˆ†æï¼Œå› ä¸ºtable contextå¯èƒ½å¯¹åº”tableæˆ–table-text
        return "table"  # ç½®ä¿¡åº¦: ~52%
    elif context_type == "table-text":
        # éœ€è¦è¿›ä¸€æ­¥åˆ†æï¼Œå› ä¸ºtable-text contextä¸»è¦å¯¹åº”table
        return "table"  # ç½®ä¿¡åº¦: ~53%
    else:
        return "unknown"
"""
    
    print(algorithm)
    
    # æä¾›æ›´ç²¾ç¡®çš„å†³ç­–é€»è¾‘
    print("\nğŸ” æ›´ç²¾ç¡®çš„å†³ç­–é€»è¾‘:")
    print("""
def predict_answer_from_precise(context):
    \"\"\"
    æ›´ç²¾ç¡®çš„answer_fromé¢„æµ‹ï¼ˆéœ€è¦é¢å¤–ç‰¹å¾ï¼‰
    \"\"\"
    context_type = determine_context_type(context)
    
    if context_type == "text":
        return "text"  # 100% ç¡®å®š
    
    elif context_type == "table":
        # åˆ†æè¡¨æ ¼æ˜¯å¦åŒ…å«éœ€è¦æ–‡æœ¬è§£é‡Šçš„å¤æ‚è®¡ç®—
        if has_complex_calculations(context):
            return "table-text"
        else:
            return "table"
    
    elif context_type == "table-text":
        # åˆ†ææ–‡æœ¬å†…å®¹çš„é‡è¦æ€§
        if text_content_is_critical(context):
            return "table-text"
        else:
            return "table"
    
    return "unknown"

def has_complex_calculations(context):
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤æ‚çš„è®¡ç®—è¯´æ˜
    calculation_keywords = ["calculate", "compute", "formula", "percentage", "ratio"]
    return any(keyword in context.lower() for keyword in calculation_keywords)

def text_content_is_critical(context):
    # æ£€æŸ¥æ–‡æœ¬å†…å®¹æ˜¯å¦å¯¹ç­”æ¡ˆè‡³å…³é‡è¦
    critical_keywords = ["note", "explanation", "definition", "assumption"]
    return any(keyword in context.lower() for keyword in critical_keywords)
""")

def main():
    """ä¸»å‡½æ•°"""
    files_to_analyze = [
        "evaluate_mrr/tatqa_train_qc_enhanced.jsonl",
        "evaluate_mrr/tatqa_eval_enhanced.jsonl"
    ]
    
    all_mapping_stats = defaultdict(Counter)
    
    for file_path in files_to_analyze:
        if Path(file_path).exists():
            mapping_stats, context_answer_examples = analyze_mapping_relationship(file_path)
            print_mapping_analysis(file_path, mapping_stats, context_answer_examples)
            
            # åˆå¹¶ç»Ÿè®¡
            for context_type, counter in mapping_stats.items():
                for answer_from, count in counter.items():
                    all_mapping_stats[context_type][answer_from] += count
        else:
            print(f"\næ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    # æ€»ä½“åˆ†æ
    if all_mapping_stats:
        print("\n" + "="*80)
        print("ğŸ“Š æ€»ä½“æ˜ å°„å…³ç³»åˆ†æ")
        print("="*80)
        
        total_samples = sum(sum(counter.values()) for counter in all_mapping_stats.values())
        print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
        
        for context_type in ["table", "text", "table-text"]:
            if context_type in all_mapping_stats:
                print(f"\nğŸ“‹ Contextç±»å‹ '{context_type}':")
                total_for_type = sum(all_mapping_stats[context_type].values())
                
                for answer_from, count in all_mapping_stats[context_type].most_common():
                    percentage = (count / total_for_type) * 100
                    print(f"  -> answer_from='{answer_from}': {count} ({percentage:.1f}%)")
        
        # ç”Ÿæˆå†³ç­–è§„åˆ™
        rules = analyze_decision_rules(all_mapping_stats)
        generate_decision_algorithm(rules)

if __name__ == "__main__":
    main() 