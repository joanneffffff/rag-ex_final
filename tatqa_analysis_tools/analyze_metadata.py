#!/usr/bin/env python3
"""
åˆ†ææ•°æ®ä¸­çš„å…ƒæ•°æ®æƒ…å†µ
"""

import json
import statistics
from pathlib import Path

def analyze_metadata(file_path: str):
    """åˆ†ææ–‡ä»¶ä¸­çš„å…ƒæ•°æ®æƒ…å†µ"""
    print(f"ğŸ” åˆ†ææ–‡ä»¶: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š æ€»è®°å½•æ•°: {len(data)}")
    print(f"ğŸ“‹ å­—æ®µåˆ—è¡¨: {list(data[0].keys())}")
    
    # å…ƒæ•°æ®å­—æ®µ
    metadata_fields = ['company_name', 'stock_code', 'report_date']
    
    # ç»Ÿè®¡ä¿¡æ¯
    metadata_stats = {field: {'non_empty': 0, 'non_none': 0, 'values': []} for field in metadata_fields}
    total_with_metadata = 0
    
    # é•¿åº¦ç»Ÿè®¡
    context_lengths = []
    answer_lengths = []
    question_lengths = []
    
    for record in data:
        has_any_metadata = False
        
        # åˆ†æå…ƒæ•°æ®
        for field in metadata_fields:
            if field in record:
                value = record[field]
                if value is not None:
                    metadata_stats[field]['non_none'] += 1
                    if str(value).strip() and str(value).lower() != 'none':
                        metadata_stats[field]['non_empty'] += 1
                        metadata_stats[field]['values'].append(str(value))
                        has_any_metadata = True
        
        if has_any_metadata:
            total_with_metadata += 1
        
        # åˆ†æé•¿åº¦
        context = record.get('original_context', record.get('context', ''))
        answer = record.get('original_answer', record.get('answer', ''))
        question = record.get('original_question', record.get('query', ''))
        
        context_lengths.append(len(context))
        answer_lengths.append(len(answer))
        question_lengths.append(len(question))
    
    # è¾“å‡ºå…ƒæ•°æ®ç»Ÿè®¡
    print(f"\nğŸ“‹ å…ƒæ•°æ®ç»Ÿè®¡:")
    print(f"æœ‰å…ƒæ•°æ®çš„è®°å½•: {total_with_metadata}/{len(data)} ({total_with_metadata/len(data)*100:.1f}%)")
    
    for field in metadata_fields:
        non_empty = metadata_stats[field]['non_empty']
        non_none = metadata_stats[field]['non_none']
        total = len(data)
        print(f"  {field}:")
        print(f"    éç©ºå€¼: {non_empty}/{total} ({non_empty/total*100:.1f}%)")
        print(f"    éNoneå€¼: {non_none}/{total} ({non_none/total*100:.1f}%)")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹å€¼
        if metadata_stats[field]['values']:
            unique_values = list(set(metadata_stats[field]['values'][:10]))
            print(f"    ç¤ºä¾‹å€¼: {unique_values}")
    
    # è¾“å‡ºé•¿åº¦ç»Ÿè®¡
    print(f"\nğŸ“ é•¿åº¦ç»Ÿè®¡:")
    print(f"Contextå¹³å‡é•¿åº¦: {statistics.mean(context_lengths):.1f} å­—ç¬¦")
    print(f"Answerå¹³å‡é•¿åº¦: {statistics.mean(answer_lengths):.1f} å­—ç¬¦")
    print(f"Questionå¹³å‡é•¿åº¦: {statistics.mean(question_lengths):.1f} å­—ç¬¦")
    print(f"Contexté•¿åº¦èŒƒå›´: {min(context_lengths)} - {max(context_lengths)} å­—ç¬¦")
    print(f"Answeré•¿åº¦èŒƒå›´: {min(answer_lengths)} - {max(answer_lengths)} å­—ç¬¦")
    print(f"Questioné•¿åº¦èŒƒå›´: {min(question_lengths)} - {max(question_lengths)} å­—ç¬¦")
    
    return {
        'total_records': len(data),
        'metadata_coverage': total_with_metadata/len(data)*100,
        'metadata_stats': metadata_stats,
        'avg_lengths': {
            'context': statistics.mean(context_lengths),
            'answer': statistics.mean(answer_lengths),
            'question': statistics.mean(question_lengths)
        }
    }

def analyze_tatqa_data(file_path: str):
    """åˆ†æTatQAæ•°æ®"""
    print(f"ğŸ” åˆ†æTatQAæ–‡ä»¶: {file_path}")
    
    data = []
    if file_path.endswith('.jsonl'):
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
    else:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    
    print(f"ğŸ“Š æ€»è®°å½•æ•°: {len(data)}")
    print(f"ğŸ“‹ å­—æ®µåˆ—è¡¨: {list(data[0].keys())}")
    
    # é•¿åº¦ç»Ÿè®¡
    context_lengths = []
    answer_lengths = []
    question_lengths = []
    
    for record in data:
        context = record.get('context', '')
        answer = record.get('answer', '')
        question = record.get('query', record.get('question', ''))
        
        context_lengths.append(len(context))
        answer_lengths.append(len(answer))
        question_lengths.append(len(question))
    
    print(f"\nğŸ“ TatQAé•¿åº¦ç»Ÿè®¡:")
    print(f"Contextå¹³å‡é•¿åº¦: {statistics.mean(context_lengths):.1f} å­—ç¬¦")
    print(f"Answerå¹³å‡é•¿åº¦: {statistics.mean(answer_lengths):.1f} å­—ç¬¦")
    print(f"Questionå¹³å‡é•¿åº¦: {statistics.mean(question_lengths):.1f} å­—ç¬¦")
    
    return {
        'total_records': len(data),
        'avg_lengths': {
            'context': statistics.mean(context_lengths),
            'answer': statistics.mean(answer_lengths),
            'question': statistics.mean(question_lengths)
        }
    }

def main():
    print("=== AlphaFinæ•°æ®å…ƒæ•°æ®åˆ†æ ===\n")
    
    # åˆ†æAlphaFinæ•°æ®
    alphafin_stats = analyze_metadata('data/alphafin/alphafin_merged_generated_qa_full_dedup.json')
    
    print("\n=== TatQAæ•°æ®åˆ†æ ===\n")
    
    # åˆ†æTatQAæ•°æ®
    tatqa_stats = analyze_tatqa_data('evaluate_mrr/tatqa_eval_enhanced.jsonl')
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n=== æ•°æ®æ¦‚å†µæ€»ç»“ ===\n")
    print("1.1 åŸå§‹æ•°æ®æ¦‚å†µ:")
    print(f"  ä¸­æ–‡æ•°æ® (AlphaFin): {alphafin_stats['total_records']} ä¸ªæ ·æœ¬")
    print(f"  è‹±æ–‡æ•°æ® (TatQA): {tatqa_stats['total_records']} ä¸ªæ ·æœ¬")
    
    print("\n1.2 LLMè‡ªåŠ¨åŒ–æ•°æ®å¤„ç†:")
    print(f"  å…ƒæ•°æ®è¦†ç›–ç‡: {alphafin_stats['metadata_coverage']:.1f}%")
    print("  æ ¸å¿ƒåŠŸèƒ½:")
    print("    - å…ƒæ•°æ®æå–å™¨: è‡ªåŠ¨æå–company_name, stock_code, report_date")
    print("    - é—®é¢˜ç”Ÿæˆå™¨: åŸºäºContextå’ŒAnswerç”ŸæˆQuestion")
    print("    - æ‘˜è¦ç”Ÿæˆå™¨: åŸºäºContextç”ŸæˆSummary")
    
    print("\n1.3 å¤„ç†åæ•°æ®ç»Ÿè®¡:")
    print("  ä¸­æ–‡ (QCA):")
    print(f"    æ ·æœ¬æ•°é‡: {alphafin_stats['total_records']}")
    print(f"    å¹³å‡Contexté•¿åº¦: {alphafin_stats['avg_lengths']['context']:.1f} å­—ç¬¦")
    print(f"    å¹³å‡Answeré•¿åº¦: {alphafin_stats['avg_lengths']['answer']:.1f} å­—ç¬¦")
    print(f"    å¹³å‡Questioné•¿åº¦: {alphafin_stats['avg_lengths']['question']:.1f} å­—ç¬¦")
    
    print("  è‹±æ–‡ (QCA):")
    print(f"    æ ·æœ¬æ•°é‡: {tatqa_stats['total_records']}")
    print(f"    å¹³å‡Contexté•¿åº¦: {tatqa_stats['avg_lengths']['context']:.1f} å­—ç¬¦")
    print(f"    å¹³å‡Answeré•¿åº¦: {tatqa_stats['avg_lengths']['answer']:.1f} å­—ç¬¦")
    print(f"    å¹³å‡Questioné•¿åº¦: {tatqa_stats['avg_lengths']['question']:.1f} å­—ç¬¦")

if __name__ == "__main__":
    main() 