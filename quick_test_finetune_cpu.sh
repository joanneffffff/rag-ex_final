#!/bin/bash

# CPUæ¨¡å¼å¿«é€Ÿæµ‹è¯•è„šæœ¬ - ä¸“é—¨ç”¨äºæ— GPUç¯å¢ƒ

echo "ğŸ§ª CPUæ¨¡å¼å¿«é€Ÿæµ‹è¯• - æ— GPUç¯å¢ƒ"
echo "æ—¶é—´: $(date)"
echo ""

# è®¾ç½®ç¯å¢ƒå˜é‡ - å¼ºåˆ¶ä½¿ç”¨CPU
export CUDA_VISIBLE_DEVICES=""
export TOKENIZERS_PARALLELISM=false
export CUDA_LAUNCH_BLOCKING=1

echo "ğŸ”§ ç¯å¢ƒé…ç½®:"
echo "  - CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES (å¼ºåˆ¶CPUæ¨¡å¼)"
echo "  - TOKENIZERS_PARALLELISM: $TOKENIZERS_PARALLELISM"
echo ""

# æµ‹è¯•é…ç½®ï¼ˆCPUä¼˜åŒ–ï¼‰
TEST_EPOCHS=1
TEST_MAX_SAMPLES=20  # CPUå¯ä»¥å¤„ç†æ›´å¤šæ ·æœ¬
TEST_EVAL_STEPS=10   # æ›´å¤šè¯„ä¼°æ­¥æ•°
TEST_BATCH_SIZE=4    # CPUæ‰¹æ¬¡å¤§å°

# æ•°æ®è·¯å¾„
TRAIN_DATA="evaluate_mrr/alphafin_train_qc.jsonl"
EVAL_DATA="evaluate_mrr/alphafin_eval.jsonl"
TEST_OUTPUT_DIR="./models/alphafin_encoder_test_cpu"

echo "ğŸ“Š æµ‹è¯•é…ç½®:"
echo "  - è®­ç»ƒæ•°æ®: $TRAIN_DATA"
echo "  - è¯„ä¼°æ•°æ®: $EVAL_DATA"
echo "  - è¾“å‡ºç›®å½•: $TEST_OUTPUT_DIR"
echo "  - æ ·æœ¬æ•°: $TEST_MAX_SAMPLES"
echo "  - è½®æ•°: $TEST_EPOCHS"
echo "  - æ‰¹æ¬¡å¤§å°: $TEST_BATCH_SIZE"
echo "  - è¯„ä¼°æ­¥æ•°: $TEST_EVAL_STEPS"
echo "  - è®¾å¤‡: CPU"
echo ""

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
echo "ğŸ“‹ æ£€æŸ¥æ•°æ®æ–‡ä»¶..."
if [ ! -f "$TRAIN_DATA" ]; then
    echo "âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: $TRAIN_DATA"
    exit 1
fi

if [ ! -f "$EVAL_DATA" ]; then
    echo "âŒ è¯„ä¼°æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: $EVAL_DATA"
    exit 1
fi

echo "âœ… æ•°æ®æ–‡ä»¶æ£€æŸ¥é€šè¿‡"
echo ""

# æ£€æŸ¥Pythonç¯å¢ƒ
echo "ğŸ æ£€æŸ¥Pythonç¯å¢ƒ..."
python --version
echo "  PyTorchç‰ˆæœ¬: $(python -c "import torch; print(torch.__version__)")"
echo "  CUDAå¯ç”¨: $(python -c "import torch; print(torch.cuda.is_available())")"
echo "  SentenceTransformersç‰ˆæœ¬: $(python -c "import sentence_transformers; print(sentence_transformers.__version__)")"
echo ""

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "$TEST_OUTPUT_DIR"

# å¼€å§‹æµ‹è¯•
echo "ğŸš€ å¼€å§‹CPUæ¨¡å¼æµ‹è¯•..."
echo "æ—¶é—´: $(date)"
echo ""

# è¿è¡Œæµ‹è¯•
python finetune_alphafin_encoder_enhanced.py \
    --model_name "Langboat/mengzi-bert-base-fin" \
    --train_jsonl "$TRAIN_DATA" \
    --eval_jsonl "$EVAL_DATA" \
    --output_dir "$TEST_OUTPUT_DIR" \
    --batch_size $TEST_BATCH_SIZE \
    --epochs $TEST_EPOCHS \
    --max_samples $TEST_MAX_SAMPLES \
    --eval_steps $TEST_EVAL_STEPS

# æ£€æŸ¥ç»“æœ
TEST_EXIT_CODE=$?

echo ""
echo "ğŸ“Š æµ‹è¯•ç»“æœåˆ†æ:"

if [ $TEST_EXIT_CODE -eq 0 ]; then
    echo "âœ… è„šæœ¬æ‰§è¡ŒæˆåŠŸ"
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if [ -f "$TEST_OUTPUT_DIR/model.safetensors" ] || [ -f "$TEST_OUTPUT_DIR/pytorch_model.bin" ]; then
        echo "âœ… æ¨¡å‹æ–‡ä»¶å·²ç”Ÿæˆ"
        MODEL_OK=true
    else
        echo "âŒ æ¨¡å‹æ–‡ä»¶æœªç”Ÿæˆ"
        MODEL_OK=false
    fi
    
    # æ£€æŸ¥è¯„ä¼°ç»“æœ
    if [ -f "$TEST_OUTPUT_DIR/eval/mrr_eval_mrr_evaluation_results.csv" ]; then
        echo "âœ… MRRè¯„ä¼°ç»“æœå·²ç”Ÿæˆ"
        echo "ğŸ“ˆ æŸ¥çœ‹ç»“æœ:"
        tail -3 "$TEST_OUTPUT_DIR/eval/mrr_eval_mrr_evaluation_results.csv"
        MRR_OK=true
    else
        echo "âŒ MRRè¯„ä¼°ç»“æœæœªç”Ÿæˆ"
        MRR_OK=false
    fi
    
    if [ "$MODEL_OK" = true ] && [ "$MRR_OK" = true ]; then
        echo ""
        echo "ğŸ‰ CPUæ¨¡å¼æµ‹è¯•å®Œå…¨æˆåŠŸï¼"
        echo "ğŸ’¡ ç°åœ¨å¯ä»¥è¿è¡Œå®Œæ•´CPUè®­ç»ƒäº†"
        echo ""
        echo "ğŸ“ å®Œæ•´CPUè®­ç»ƒå‘½ä»¤:"
        echo "export CUDA_VISIBLE_DEVICES=\"\""
        echo "python finetune_alphafin_encoder_enhanced.py \\"
        echo "    --model_name \"Langboat/mengzi-bert-base-fin\" \\"
        echo "    --train_jsonl \"$TRAIN_DATA\" \\"
        echo "    --eval_jsonl \"$EVAL_DATA\" \\"
        echo "    --output_dir \"./models/alphafin_encoder_finetuned_cpu\" \\"
        echo "    --batch_size 8 \\"
        echo "    --epochs 5 \\"
        echo "    --max_samples 20000 \\"
        echo "    --eval_steps 200"
        echo ""
        echo "â° é¢„è®¡å®Œæˆæ—¶é—´: 3-5å°æ—¶ (CPUæ¨¡å¼)"
    else
        echo ""
        echo "âš ï¸  æµ‹è¯•éƒ¨åˆ†æˆåŠŸï¼Œä½†æœ‰é—®é¢˜éœ€è¦è§£å†³"
    fi
    
else
    echo "âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥ (é€€å‡ºç : $TEST_EXIT_CODE)"
    echo ""
    echo "ğŸ” å¯èƒ½çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ:"
    echo ""
    echo "1. å†…å­˜ä¸è¶³:"
    echo "   - å‡å°‘æ‰¹æ¬¡å¤§å°: --batch_size 2"
    echo "   - å‡å°‘æ ·æœ¬æ•°: --max_samples 10"
    echo "   - å…³é—­å…¶ä»–ç¨‹åºé‡Šæ”¾å†…å­˜"
    echo ""
    echo "2. æ¨¡å‹ä¸‹è½½é—®é¢˜:"
    echo "   - æ£€æŸ¥ç½‘ç»œè¿æ¥"
    echo "   - æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°"
    echo ""
    echo "3. ä¾èµ–åŒ…é—®é¢˜:"
    echo "   - æ£€æŸ¥PyTorchç‰ˆæœ¬: pip list | grep torch"
    echo "   - æ£€æŸ¥sentence-transformersç‰ˆæœ¬: pip list | grep sentence"
    echo ""
    echo "ğŸ’¡ æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯:"
    echo "   python finetune_alphafin_encoder_enhanced.py --help"
fi

echo ""
echo "â° æµ‹è¯•å®Œæˆæ—¶é—´: $(date)" 