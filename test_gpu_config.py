#!/usr/bin/env python3
"""
æµ‹è¯•GPUé…ç½®è„šæœ¬
éªŒè¯æ¨¡å‹æ˜¯å¦æ­£ç¡®ä½¿ç”¨GPU
"""

import torch
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from xlm.components.generator.local_llm_generator import LocalLLMGenerator
from config.parameters import Config

def test_gpu_configuration():
    """æµ‹è¯•GPUé…ç½®"""
    print("=" * 60)
    print("ğŸ”§ GPUé…ç½®æµ‹è¯•")
    print("=" * 60)
    
    # 1. æ£€æŸ¥CUDAå¯ç”¨æ€§
    print("1. æ£€æŸ¥CUDAå¯ç”¨æ€§:")
    print(f"   - CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   - GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   - GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
    
    # 2. æ£€æŸ¥é…ç½®
    print("\n2. æ£€æŸ¥é…ç½®:")
    config = Config()
    print(f"   - ç”Ÿæˆå™¨è®¾å¤‡: {config.generator.device}")
    print(f"   - ä½¿ç”¨é‡åŒ–: {config.generator.use_quantization}")
    print(f"   - é‡åŒ–ç±»å‹: {config.generator.quantization_type}")
    print(f"   - æ¨¡å‹åç§°: {config.generator.model_name}")
    
    # 3. æµ‹è¯•æ¨¡å‹åŠ è½½
    print("\n3. æµ‹è¯•æ¨¡å‹åŠ è½½:")
    try:
        print("   - æ­£åœ¨åŠ è½½æ¨¡å‹...")
        generator = LocalLLMGenerator(device="cuda")
        
        print(f"   - æ¨¡å‹è®¾å¤‡: {generator.device}")
        print(f"   - æ¨¡å‹é‡åŒ–: {generator.use_quantization}")
        print(f"   - é‡åŒ–ç±»å‹: {generator.quantization_type}")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨GPUä¸Š
        model_device = next(generator.model.parameters()).device
        print(f"   - æ¨¡å‹å®é™…è®¾å¤‡: {model_device}")
        
        if model_device.type == 'cuda':
            print("   âœ… æ¨¡å‹æˆåŠŸåŠ è½½åˆ°GPU")
        else:
            print("   âŒ æ¨¡å‹æœªåŠ è½½åˆ°GPU")
            
    except Exception as e:
        print(f"   âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 4. æµ‹è¯•ç”Ÿæˆ
    print("\n4. æµ‹è¯•ç”Ÿæˆ:")
    try:
        test_prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½ã€‚"
        print(f"   - æµ‹è¯•æç¤º: {test_prompt}")
        
        response = generator.generate([test_prompt])
        print(f"   - ç”Ÿæˆå“åº”: {response[0][:100]}...")
        print("   âœ… ç”Ÿæˆæµ‹è¯•æˆåŠŸ")
        
    except Exception as e:
        print(f"   âŒ ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("\n" + "=" * 60)
    print("ğŸ‰ GPUé…ç½®æµ‹è¯•å®Œæˆ")
    print("=" * 60)
    return True

if __name__ == "__main__":
    success = test_gpu_configuration()
    sys.exit(0 if success else 1) 