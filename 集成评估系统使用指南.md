# 集成评估系统使用指南

## 🎯 系统概述

集成评估系统是一个统一的RAG系统评估平台，整合了所有检索和重排序模块，支持多种对比实验。**最新版本已升级为使用真实RAG系统组件，确保评估逻辑与生产系统完全一致。**

## 📋 核心功能

### 🔍 支持的评估方法

| 方法 | 描述 | 适用场景 |
|------|------|----------|
| `encoder_only` | 仅使用编码器检索 | 基础检索测试 |
| `encoder_faiss` | 编码器+FAISS加速 | 大规模检索 |
| `encoder_reranker` | 编码器+重排序 | 高精度检索 |
| `encoder_faiss_reranker` | 编码器+FAISS+重排序 | 完整流程 |

### 🏗️ 系统架构

```
集成评估系统 (真实RAG组件版)
├── 数据加载模块
│   ├── 评估数据加载
│   ├── 检索库构建 (DocumentWithMetadata)
│   └── 元数据提取
├── RAG系统管理器
│   ├── FinbertEncoder (双语言)
│   ├── BilingualRetriever
│   ├── QwenReranker
│   └── FAISS索引 (可选)
├── 检索引擎模块
│   ├── 语义检索 (BilingualRetriever)
│   ├── 重排序 (QwenReranker)
│   └── 语言检测
└── 评估分析模块
    ├── MRR计算
    ├── 性能统计
    └── 对比报告
```

### ✨ 特色功能

**✅ 元数据过滤**
- 支持AlphaFin公司名称、股票代码、报告日期过滤
- 提高检索精度和相关性

**✅ 真实RAG组件**
- 使用FinbertEncoder、BilingualRetriever、QwenReranker
- 与生产系统完全一致的评估逻辑

**✅ 多语言支持**
- 支持中英文混合检索和评估
- 自动语言检测和路由

**✅ 多种模型支持**
- 灵活的编码器和重排序模型配置
- 支持不同模型对比实验

**✅ 性能监控**
- 检索和重排序时间统计
- 详细的性能分析报告

**✅ 一键对比**
- 自动运行多种方法对比
- 生成详细的对比报告

## 🚀 快速开始

### 1. 基础使用

```bash
# 快速测试 (50个样本)
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --max_samples 50 \
    --method encoder_only
```

### 2. 完整对比实验

```bash
# 运行所有方法对比
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --max_samples 100 \
    --method all
```

### 3. 启用元数据过滤

```bash
# 使用元数据过滤提高精度
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --max_samples 500 \
    --method all \
    --use_metadata_filter
```

## 📊 参数说明

### 🔧 基础参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--eval_data` | str | `evaluate_mrr/alphafin_eval.jsonl` | 评估数据文件路径 |
| `--corpus_data` | str | `data/alphafin/alphafin_merged_generated_qa_full_dedup.json` | 检索库数据文件 |
| `--encoder_model` | str | `models/finetuned_finbert_tatqa` | 编码器模型名称 |
| `--reranker_model` | str | `Qwen/Qwen3-Reranker-0.6B` | 重排序模型名称 |
| `--method` | str | `all` | 评估方法选择 |

### 🎛️ 性能参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--top_k_retrieval` | int | 100 | 检索返回的top-k文档数 |
| `--top_k_rerank` | int | 10 | 重排序的top-k文档数 |
| `--max_samples` | int | 100 | 最大评估样本数 |
| `--batch_size` | int | 4 | 批次大小 |
| `--max_length` | int | 512 | 序列最大长度 |

### 🔍 高级参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--use_metadata_filter` | flag | False | 是否启用元数据过滤 |
| `--device` | str | `cuda` | 设备选择 (cuda/cpu) |
| `--num_gpus` | int | 2 | 使用的GPU数量 |

## 📈 使用场景

### 🧪 快速验证

**目标**: 验证系统是否正常工作
```bash
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --max_samples 50 \
    --method encoder_only \
    --batch_size 1
```

### 📊 性能对比

**目标**: 比较不同方法的性能
```bash
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --max_samples 500 \
    --method all \
    --use_metadata_filter
```

### 🎯 生产评估

**目标**: 全面评估系统性能
```bash
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --max_samples 1000 \
    --method encoder_faiss_reranker \
    --use_metadata_filter \
    --top_k_retrieval 200 \
    --top_k_rerank 20
```

## 📊 输出结果

### 📋 控制台输出

```
🚀 集成评估系统 - 使用真实RAG系统组件
📊 配置:
  - 评估数据: evaluate_mrr/alphafin_eval.jsonl
  - 检索库数据: data/alphafin/alphafin_merged_generated_qa_full_dedup.json
  - 编码器模型: models/finetuned_finbert_tatqa
  - 重排序模型: Qwen/Qwen3-Reranker-0.6B
  - 评估方法: all
  - 最大样本数: 100
  - 元数据过滤: 启用
  - GPU数量: 2

🔬 开始对比实验
============================================================

📊 测试方法: encoder_only
----------------------------------------
📈 结果:
  - 检索MRR @100: 0.2345
  - 重排序MRR @10: 0.0000
  - 平均检索时间: 0.045s
  - 平均重排序时间: 0.000s
  - 有效查询数: 95/100

📊 测试方法: encoder_faiss
----------------------------------------
📈 结果:
  - 检索MRR @100: 0.2345
  - 重排序MRR @10: 0.0000
  - 平均检索时间: 0.023s
  - 平均重排序时间: 0.000s
  - 有效查询数: 95/100

📊 测试方法: encoder_reranker
----------------------------------------
📈 结果:
  - 检索MRR @100: 0.2345
  - 重排序MRR @10: 0.3456
  - 平均检索时间: 0.045s
  - 平均重排序时间: 0.123s
  - 有效查询数: 95/100

📊 测试方法: encoder_faiss_reranker
----------------------------------------
📈 结果:
  - 检索MRR @100: 0.2345
  - 重排序MRR @10: 0.3456
  - 平均检索时间: 0.023s
  - 平均重排序时间: 0.123s
  - 有效查询数: 95/100

============================================================
📊 对比实验总结
============================================================
方法                     检索MRR    重排序MRR    检索时间    重排序时间
------------------------------------------------------------------------
encoder_faiss_reranker   0.2345     0.3456      0.023      0.123
encoder_reranker         0.2345     0.3456      0.045      0.123
encoder_faiss            0.2345     0.0000      0.023      0.000
encoder_only             0.2345     0.0000      0.045      0.000

🏆 最佳检索方法: encoder_faiss_reranker (MRR: 0.2345)
🏆 最佳重排序方法: encoder_faiss_reranker (MRR: 0.3456)

🎉 评估完成！
```

### 📄 详细报告

系统会自动生成详细的评估报告，包含：
- 每种方法的详细指标
- 性能对比分析
- 最佳方法推荐
- 错误分析

## 🔧 故障排除

### 🚨 常见问题

**1. GPU内存不足**
```bash
# 解决方案：使用CPU或减少批次大小
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --device cpu \
    --batch_size 1
```

**2. 模型加载失败**
```bash
# 解决方案：检查模型名称和网络连接
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --encoder_model "models/finetuned_finbert_tatqa" \
    --reranker_model "Qwen/Qwen3-Reranker-0.6B"
```

**3. 数据文件不存在**
```bash
# 解决方案：检查文件路径
ls -la evaluate_mrr/alphafin_eval.jsonl
ls -la data/alphafin/alphafin_merged_generated_qa_full_dedup.json
```

### 🔍 调试模式

```bash
# 启用详细日志
python encoder_finetune_evaluate/integrated_evaluation_system.py \
    --eval_data evaluate_mrr/alphafin_eval.jsonl \
    --max_samples 10 \
    --method encoder_only \
    --batch_size 1
```

## 📚 最佳实践

### 🎯 评估流程建议

1. **快速验证** (50个样本)
   - 验证系统配置正确
   - 检查数据加载正常
   - 确认RAG组件正常工作

2. **方法对比** (500个样本)
   - 比较不同方法性能
   - 确定最佳方法组合
   - 验证多语言支持

3. **生产评估** (1000+样本)
   - 全面评估系统性能
   - 生成最终报告
   - 与真实RAG系统性能对比

### ⚡ 性能优化

1. **批次大小调优**
   - 从batch_size=1开始
   - 逐步增加到最优值

2. **模型选择**
   - 根据数据特点选择合适模型
   - 平衡性能和速度
   - 优先使用微调后的Finbert模型

3. **参数调优**
   - 调整top_k_retrieval和top_k_rerank
   - 根据实际需求优化
   - 利用FAISS加速大规模检索

4. **多GPU优化**
   - 合理设置GPU数量
   - 监控GPU内存使用
   - 避免内存溢出

### 🔒 数据安全

1. **数据泄露检查**
   - 确保训练集和评估集分离
   - 避免数据污染
   - 验证DocumentWithMetadata结构正确

2. **结果验证**
   - 检查评估结果合理性
   - 验证指标计算正确
   - 确认与真实RAG系统结果一致

3. **组件验证**
   - 验证BilingualRetriever检索逻辑
   - 确认QwenReranker重排序效果
   - 检查多语言支持正常

## 📞 技术支持

如果遇到问题：
1. 检查参数配置
2. 查看错误日志
3. 尝试简化配置
4. 联系技术支持

## 🔄 版本更新说明

### v2.0 - 真实RAG组件集成 (最新)

**主要改进**:
- ✅ 使用FinbertEncoder、BilingualRetriever、QwenReranker真实组件
- ✅ 支持中英文混合检索和评估
- ✅ 自动语言检测和路由
- ✅ 多GPU并行处理支持
- ✅ 与生产系统完全一致的评估逻辑

**向后兼容性**: 保持原有API接口不变，内部实现完全升级

---

**注意**: 建议从最小配置开始测试，逐步增加复杂度，确保系统稳定运行。新版本使用真实RAG组件，评估结果更准确可靠。 