#!/usr/bin/env python3
"""
Promptæ‰°åŠ¨ vs Contextæ‰°åŠ¨å®éªŒ
å±•ç¤ºæ‰°åŠ¨åœ¨RAGç³»ç»Ÿä¸­çš„ä¸åŒä½ç½®å’Œæ•ˆæœ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from xlm.components.rag_system.rag_system import RagSystem
from xlm.components.retriever.enhanced_retriever import EnhancedRetriever
from xlm.components.generator.local_llm_generator import LocalLLMGenerator
from xlm.explainer.generic_retriever_explainer import GenericRetrieverExplainer
from xlm.explainer.generic_generator_explainer import GenericGeneratorExplainer
from xlm.modules.perturber.leave_one_out_perturber import LeaveOneOutPerturber
from xlm.modules.perturber.reorder_perturber import ReorderPerturber
from xlm.modules.perturber.trend_perturber import TrendPerturber
from xlm.modules.perturber.year_perturber import YearPerturber
from xlm.modules.perturber.term_perturber import TermPerturber
from xlm.modules.comparator.embedding_comparator import EmbeddingComparator
from xlm.modules.tokenizer.custom_tokenizer import CustomTokenizer
from xlm.dto.dto import ExplanationGranularity
from config.parameters import Config

class PromptVsContextPerturbation:
    """Promptæ‰°åŠ¨ vs Contextæ‰°åŠ¨å¯¹æ¯”å®éªŒ"""
    
    def __init__(self):
        """åˆå§‹åŒ–å®éªŒç¯å¢ƒ"""
        print("ğŸ”¬ åˆå§‹åŒ–Prompt vs Contextæ‰°åŠ¨å®éªŒ...")
        
        # åŠ è½½é…ç½®
        self.config = Config()
        
        # åˆå§‹åŒ–RAGç³»ç»Ÿç»„ä»¶
        self.generator = LocalLLMGenerator()
        self.retriever = EnhancedRetriever(config=self.config)
        
        # åˆå§‹åŒ–æ‰°åŠ¨ç³»ç»Ÿç»„ä»¶
        self.tokenizer = CustomTokenizer()
        from xlm.components.encoder.finbert import FinbertEncoder
        encoder = FinbertEncoder(model_name="ProsusAI/finbert")
        self.comparator = EmbeddingComparator(encoder=encoder)
        
        # åˆå§‹åŒ–æ‰°åŠ¨å™¨
        self.perturber = LeaveOneOutPerturber()
        
        print("âœ… å®éªŒç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
    
    def run_context_perturbation_experiment(self, question: str):
        """è¿è¡ŒContextæ‰°åŠ¨å®éªŒï¼ˆæ£€ç´¢é˜¶æ®µï¼‰"""
        print(f"\nğŸ” Contextæ‰°åŠ¨å®éªŒï¼ˆæ£€ç´¢é˜¶æ®µï¼‰")
        print(f"é—®é¢˜: {question}")
        print("=" * 60)
        
        try:
            # åˆ›å»ºæ£€ç´¢å™¨è§£é‡Šå™¨
            retriever_explainer = GenericRetrieverExplainer(
                perturber=self.perturber,
                comparator=self.comparator,
                retriever=self.retriever,
                tokenizer=self.tokenizer
            )
            
            # è·å–å‚è€ƒæ£€ç´¢ç»“æœ
            reference_doc, reference_score = retriever_explainer.get_reference(question)
            print(f"ğŸ“„ åŸå§‹æ–‡æ¡£: {reference_doc[:100]}...")
            print(f"ğŸ“Š åŸå§‹åˆ†æ•°: {reference_score:.4f}")
            
            # å¯¹æ–‡æ¡£å†…å®¹è¿›è¡Œåˆ†è¯
            features = self.tokenizer.tokenize(text=reference_doc, granularity=ExplanationGranularity.WORD_LEVEL)
            print(f"ğŸ”¤ æ–‡æ¡£ç‰¹å¾: {features[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
            
            # ç”Ÿæˆæ‰°åŠ¨æ–‡æ¡£
            perturbations = self.perturber.perturb(text=reference_doc, features=features)
            print(f"ğŸ”„ ç”Ÿæˆæ‰°åŠ¨æ–‡æ¡£æ•°é‡: {len(perturbations)}")
            
            # æ˜¾ç¤ºå‡ ä¸ªæ‰°åŠ¨ç¤ºä¾‹
            for i, perturbed in enumerate(perturbations[:3], 1):
                print(f"æ‰°åŠ¨{i}: {perturbed[:80]}...")
            
            # è¿›è¡Œæ‰°åŠ¨åˆ†æ
            explanation = retriever_explainer.explain(
                user_input=question,
                granularity=ExplanationGranularity.WORD_LEVEL,
                reference_text=reference_doc,
                reference_score=str(reference_score)
            )
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š Contextæ‰°åŠ¨åˆ†æç»“æœ:")
            print(f"åˆ†æçš„ç‰¹å¾æ•°é‡: {len(explanation.explanations)}")
            
            if explanation.explanations:
                print(f"\nğŸ† Top 5 é‡è¦æ–‡æ¡£ç‰¹å¾:")
                for i, feature in enumerate(explanation.explanations[:5], 1):
                    print(f"{i}. '{feature.feature}' - é‡è¦æ€§: {feature.score:.4f}")
            
            return explanation
            
        except Exception as e:
            print(f"âŒ Contextæ‰°åŠ¨å®éªŒå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def run_prompt_perturbation_experiment(self, question: str):
        """è¿è¡ŒPromptæ‰°åŠ¨å®éªŒï¼ˆç”Ÿæˆé˜¶æ®µï¼‰"""
        print(f"\nğŸ¤– Promptæ‰°åŠ¨å®éªŒï¼ˆç”Ÿæˆé˜¶æ®µï¼‰")
        print(f"é—®é¢˜: {question}")
        print("=" * 60)
        
        try:
            # å…ˆè·å–ä¸Šä¸‹æ–‡
            retrieved_docs, _ = self.retriever.retrieve(text=question, top_k=3, return_scores=True)
            context = "\n\n".join([doc.content for doc in retrieved_docs])
            
            # æ„å»ºå®Œæ•´prompt
            from xlm.components.rag_system.rag_system import PROMPT_TEMPLATE_ZH_CLEAN
            full_prompt = PROMPT_TEMPLATE_ZH_CLEAN.format(context=context, question=question)
            
            print(f"ğŸ“ å®Œæ•´Prompt: {full_prompt[:200]}...")
            
            # åˆ›å»ºç”Ÿæˆå™¨è§£é‡Šå™¨
            generator_explainer = GenericGeneratorExplainer(
                perturber=self.perturber,
                comparator=self.comparator,
                generator=self.generator,
                tokenizer=self.tokenizer
            )
            
            # è·å–å‚è€ƒç”Ÿæˆç»“æœ
            reference_response = generator_explainer.get_reference(full_prompt)
            print(f"ğŸ“„ åŸå§‹å›ç­”: {reference_response[:100]}...")
            
            # å¯¹promptè¿›è¡Œåˆ†è¯
            features = self.tokenizer.tokenize(text=full_prompt, granularity=ExplanationGranularity.WORD_LEVEL)
            print(f"ğŸ”¤ Promptç‰¹å¾: {features[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
            
            # ç”Ÿæˆæ‰°åŠ¨prompt
            perturbations = self.perturber.perturb(text=full_prompt, features=features)
            print(f"ğŸ”„ ç”Ÿæˆæ‰°åŠ¨Promptæ•°é‡: {len(perturbations)}")
            
            # æ˜¾ç¤ºå‡ ä¸ªæ‰°åŠ¨ç¤ºä¾‹
            for i, perturbed in enumerate(perturbations[:3], 1):
                print(f"æ‰°åŠ¨{i}: {perturbed[:80]}...")
            
            # è¿›è¡Œæ‰°åŠ¨åˆ†æ
            explanation = generator_explainer.explain(
                user_input=full_prompt,
                granularity=ExplanationGranularity.WORD_LEVEL,
                reference_text=reference_response,
                reference_score="1.0"
            )
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š Promptæ‰°åŠ¨åˆ†æç»“æœ:")
            print(f"åˆ†æçš„ç‰¹å¾æ•°é‡: {len(explanation.explanations)}")
            
            if explanation.explanations:
                print(f"\nğŸ† Top 5 é‡è¦Promptç‰¹å¾:")
                for i, feature in enumerate(explanation.explanations[:5], 1):
                    print(f"{i}. '{feature.feature}' - é‡è¦æ€§: {feature.score:.4f}")
            
            return explanation
            
        except Exception as e:
            print(f"âŒ Promptæ‰°åŠ¨å®éªŒå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def run_comparison_experiment(self, question: str):
        """è¿è¡Œå¯¹æ¯”å®éªŒ"""
        print(f"\nğŸš€ Prompt vs Contextæ‰°åŠ¨å¯¹æ¯”å®éªŒ")
        print(f"é—®é¢˜: {question}")
        print("=" * 60)
        
        # 1. è¿è¡Œæ ‡å‡†RAG
        try:
            rag_system = RagSystem(
                retriever=self.retriever,
                generator=self.generator,
                retriever_top_k=5
            )
            
            result = rag_system.run(question)
            print(f"âœ… æ ‡å‡†RAGè¿è¡ŒæˆåŠŸ")
            print(f"æ£€ç´¢æ–‡æ¡£æ•°: {len(result.retrieved_documents)}")
            print(f"ç”Ÿæˆå›ç­”: {result.generated_responses[0][:100]}...")
            
        except Exception as e:
            print(f"âŒ æ ‡å‡†RAGè¿è¡Œå¤±è´¥: {str(e)}")
        
        # 2. Contextæ‰°åŠ¨å®éªŒ
        context_explanation = self.run_context_perturbation_experiment(question)
        
        # 3. Promptæ‰°åŠ¨å®éªŒ
        prompt_explanation = self.run_prompt_perturbation_experiment(question)
        
        # 4. å¯¹æ¯”åˆ†æ
        print(f"\nğŸ“‹ å¯¹æ¯”åˆ†æ:")
        print(f"âœ… Contextæ‰°åŠ¨: {'æˆåŠŸ' if context_explanation else 'å¤±è´¥'}")
        print(f"âœ… Promptæ‰°åŠ¨: {'æˆåŠŸ' if prompt_explanation else 'å¤±è´¥'}")
        
        if context_explanation and prompt_explanation:
            print(f"\nğŸ” æ‰°åŠ¨ä½ç½®å¯¹æ¯”:")
            print(f"  - Contextæ‰°åŠ¨: åˆ†ææ–‡æ¡£å†…å®¹çš„é‡è¦æ€§")
            print(f"  - Promptæ‰°åŠ¨: åˆ†æå®Œæ•´promptçš„é‡è¦æ€§")
            print(f"  - ä¸¤è€…ç»“åˆ: å…¨é¢ç†è§£RAGç³»ç»Ÿçš„å…³é”®ç‰¹å¾")
        
        return {
            'context_explanation': context_explanation,
            'prompt_explanation': prompt_explanation
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Prompt vs Contextæ‰°åŠ¨å®éªŒ")
    print("=" * 60)
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = PromptVsContextPerturbation()
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "é¦–é’¢è‚¡ä»½åœ¨2023å¹´ä¸ŠåŠå¹´çš„ä¸šç»©è¡¨ç°å¦‚ä½•ï¼Ÿ",
        "ä¸­å›½å¹³å®‰çš„è´¢åŠ¡çŠ¶å†µæ€ä¹ˆæ ·ï¼Ÿ"
    ]
    
    # è¿è¡Œå®éªŒ
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*20} å®éªŒ {i} {'='*20}")
        results = experiment.run_comparison_experiment(question)
        
        if results:
            print(f"âœ… å®éªŒ {i} å®Œæˆ")
        else:
            print(f"âŒ å®éªŒ {i} å¤±è´¥")
    
    print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print("ğŸ“Š æ‰°åŠ¨ä½ç½®åˆ†æ:")
    print("  - Contextæ‰°åŠ¨: åˆ†ææ£€ç´¢é˜¶æ®µæ–‡æ¡£å†…å®¹çš„é‡è¦æ€§")
    print("  - Promptæ‰°åŠ¨: åˆ†æç”Ÿæˆé˜¶æ®µpromptå†…å®¹çš„é‡è¦æ€§")
    print("ğŸ”¬ å¯ä»¥å…¨é¢ç†è§£RAGç³»ç»Ÿçš„å¯è§£é‡Šæ€§")

if __name__ == "__main__":
    main() 