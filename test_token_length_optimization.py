#!/usr/bin/env python3
"""
Token é•¿åº¦ä¼˜åŒ–æµ‹è¯•
æµ‹è¯•ä¸åŒçš„ max_new_tokens è®¾ç½®å¯¹å“åº”è´¨é‡çš„å½±å“
"""

import sys
import os
from pathlib import Path

# Add parent directory to path
sys.path.append(str(Path(__file__).parent))

def test_token_length_settings():
    """æµ‹è¯•ä¸åŒçš„ token é•¿åº¦è®¾ç½®"""
    
    print("ğŸš€ Token é•¿åº¦ä¼˜åŒ–æµ‹è¯•")
    print("æµ‹è¯•ä¸åŒçš„ max_new_tokens è®¾ç½®å¯¹å“åº”è´¨é‡çš„å½±å“")
    print("=" * 60)
    
    try:
        from xlm.components.generator.local_llm_generator import LocalLLMGenerator
        
        # ç¡¬ç¼–ç æµ‹è¯• Prompt
        test_prompt = """===SYSTEM===
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

**è¦æ±‚ï¼š**
1. å›ç­”ç®€æ´ï¼Œæ§åˆ¶åœ¨2-3å¥è¯å†…
2. åªåŒ…å«æ ¸å¿ƒä¿¡æ¯
3. ç”¨ä¸­æ–‡å›ç­”
4. å¥å­è¦å®Œæ•´

===USER===
Apple Inc. reported Q3 2023 revenue of $81.8 billion, down 1.4% year-over-year. 
iPhone sales increased 2.8% to $39.7 billion. The company's services revenue 
grew 8.2% to $21.2 billion, while Mac and iPad sales declined.

é—®é¢˜ï¼šHow did Apple perform in Q3 2023?

å›ç­”ï¼š==="""
        
        # ä¸åŒçš„ token è®¾ç½®
        token_settings = [
            {"name": "å½“å‰è®¾ç½®", "max_new_tokens": 700, "max_total_tokens": 1000},
            {"name": "å¢åŠ è®¾ç½®", "max_new_tokens": 1000, "max_total_tokens": 1500},
            {"name": "ä¿å®ˆè®¾ç½®", "max_new_tokens": 500, "max_total_tokens": 800},
            {"name": "æ¿€è¿›è®¾ç½®", "max_new_tokens": 1500, "max_total_tokens": 2000},
        ]
        
        results = []
        
        for setting in token_settings:
            print(f"\n=== æµ‹è¯• {setting['name']} ===")
            print(f"max_new_tokens: {setting['max_new_tokens']}")
            print(f"max_total_tokens: {setting['max_total_tokens']}")
            
            try:
                # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹ï¼Œä¸´æ—¶ä¿®æ”¹é…ç½®
                generator = LocalLLMGenerator(device="cuda:1")
                
                # ä¸´æ—¶ä¿®æ”¹é…ç½®
                original_max_new_tokens = generator.max_new_tokens
                original_max_total_tokens = getattr(generator.config.generator, 'max_total_tokens', 1000)
                
                generator.max_new_tokens = setting['max_new_tokens']
                generator.config.generator.max_total_tokens = setting['max_total_tokens']
                
                print(f"âœ… ç”Ÿæˆå™¨é…ç½®æ›´æ–°æˆåŠŸ")
                print(f"   åŸå§‹ max_new_tokens: {original_max_new_tokens}")
                print(f"   å½“å‰ max_new_tokens: {generator.max_new_tokens}")
                
                # ç”Ÿæˆå“åº”
                print("ğŸš€ å¼€å§‹ç”Ÿæˆ...")
                responses = generator.generate([test_prompt])
                response = responses[0] if responses else "ç”Ÿæˆå¤±è´¥"
                
                print(f"å“åº”: {response}")
                
                # è¯„ä¼°å“åº”
                length = len(response.strip())
                has_chinese = any('\u4e00' <= char <= '\u9fff' for char in response)
                has_english = any(char.isalpha() and ord(char) < 128 for char in response)
                is_complete = response.strip().endswith(("ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"))
                
                # æ£€æŸ¥å…³é”®ä¿¡æ¯
                key_terms = ["Apple", "revenue", "billion", "iPhone", "sales", "Q3"]
                found_terms = [term for term in key_terms if term.lower() in response.lower()]
                
                # æ£€æŸ¥è¯­è¨€ä¸€è‡´æ€§ï¼ˆåŒºåˆ†å…¬å¸åç§°å’Œå›ç­”è¯­è¨€ï¼‰
                # å…¬å¸åç§°åº”è¯¥ä¿æŒåŸæ ·ï¼Œå›ç­”è¯­è¨€åº”è¯¥ä¸æŸ¥è¯¢è¯­è¨€ä¸€è‡´
                company_names = ["Apple", "iPhone", "Mac", "iPad"]  # è‹±æ–‡å…¬å¸/äº§å“åç§°
                chinese_company_names = ["å¾·èµ›ç”µæ± ", "ç”¨å‹ç½‘ç»œ", "é¦–é’¢è‚¡ä»½"]  # ä¸­æ–‡å…¬å¸åç§°
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡å…¬å¸åç§°ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰
                has_english_company = any(name in response for name in company_names)
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼ˆè¡¨ç¤ºå›ç­”ç”¨ä¸­æ–‡ï¼‰
                has_chinese_answer = has_chinese
                
                # è¯­è¨€ä¸€è‡´æ€§è¯„åˆ†ï¼šè‹±æ–‡æŸ¥è¯¢åº”è¯¥å¾—åˆ°ä¸­æ–‡å›ç­”ï¼Œä½†å¯ä»¥åŒ…å«è‹±æ–‡å…¬å¸åç§°
                language_consistent = has_chinese_answer  # åªè¦åŒ…å«ä¸­æ–‡å­—ç¬¦å°±ç®—è¯­è¨€ä¸€è‡´
                
                # è¯„åˆ†
                score = 0
                if 20 <= length <= 200: score += 25
                if language_consistent: score += 25  # ä¿®æ”¹ï¼šåªè¦åŒ…å«ä¸­æ–‡å›ç­”å°±ç®—ä¸€è‡´
                if len(found_terms) >= 3: score += 25
                if is_complete: score += 25
                
                results.append({
                    "name": setting['name'],
                    "max_new_tokens": setting['max_new_tokens'],
                    "max_total_tokens": setting['max_total_tokens'],
                    "response": response,
                    "length": length,
                    "language_consistent": language_consistent,
                    "is_complete": is_complete,
                    "key_terms_found": len(found_terms),
                    "score": score
                })
                
                print(f"è¯„åˆ†: {score}/100")
                print(f"é•¿åº¦: {length} å­—ç¬¦")
                print(f"åŒ…å«ä¸­æ–‡å­—ç¬¦: {'æ˜¯' if has_chinese else 'å¦'}")
                print(f"åŒ…å«è‹±æ–‡å­—ç¬¦: {'æ˜¯' if has_english else 'å¦'}")
                print(f"åŒ…å«è‹±æ–‡å…¬å¸åç§°: {'æ˜¯' if has_english_company else 'å¦'}")
                print(f"è¯­è¨€ä¸€è‡´: {'æ˜¯' if language_consistent else 'å¦'} (ä¸­æ–‡å›ç­”)")
                print(f"å¥å­å®Œæ•´: {'æ˜¯' if is_complete else 'å¦'}")
                print(f"å…³é”®ä¿¡æ¯: {found_terms}")
                
                # æ¢å¤åŸå§‹é…ç½®
                generator.max_new_tokens = original_max_new_tokens
                generator.config.generator.max_total_tokens = original_max_total_tokens
                
            except Exception as e:
                print(f"âŒ {setting['name']} æµ‹è¯•å¤±è´¥: {e}")
                results.append({
                    "name": setting['name'],
                    "max_new_tokens": setting['max_new_tokens'],
                    "max_total_tokens": setting['max_total_tokens'],
                    "response": "æµ‹è¯•å¤±è´¥",
                    "length": 0,
                    "language_consistent": False,
                    "is_complete": False,
                    "key_terms_found": 0,
                    "score": 0
                })
        
        # æ€»ç»“ç»“æœ
        print(f"\n=== æµ‹è¯•ç»“æœæ€»ç»“ ===")
        print("-" * 80)
        for result in results:
            status = "âœ…" if result["score"] >= 75 else "âš ï¸" if result["score"] >= 50 else "âŒ"
            print(f"{status} {result['name']}: {result['score']}/100")
            print(f"   max_new_tokens: {result['max_new_tokens']}, max_total_tokens: {result['max_total_tokens']}")
            print(f"   å“åº”é•¿åº¦: {result['length']} å­—ç¬¦")
            print(f"   è¯­è¨€ä¸€è‡´: {'æ˜¯' if result['language_consistent'] else 'å¦'}")
            print(f"   å¥å­å®Œæ•´: {'æ˜¯' if result['is_complete'] else 'å¦'}")
            print(f"   å…³é”®ä¿¡æ¯: {result['key_terms_found']} ä¸ª")
            print()
        
        # æ¨èæœ€ä½³è®¾ç½®
        best_result = max(results, key=lambda x: x['score'])
        print(f"ğŸ¯ æ¨èè®¾ç½®: {best_result['name']}")
        print(f"   max_new_tokens: {best_result['max_new_tokens']}")
        print(f"   max_total_tokens: {best_result['max_total_tokens']}")
        print(f"   è¯„åˆ†: {best_result['score']}/100")
        
        return True
        
    except Exception as e:
        print(f"âŒ Token é•¿åº¦æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_sentence_completion():
    """æµ‹è¯•å¥å­å®Œæ•´æ€§æ£€æµ‹æœºåˆ¶"""
    
    print("\n=== å¥å­å®Œæ•´æ€§æ£€æµ‹æµ‹è¯• ===")
    print("=" * 50)
    
    try:
        from xlm.components.generator.local_llm_generator import LocalLLMGenerator
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        generator = LocalLLMGenerator(device="cuda:1")
        
        # æµ‹è¯• Prompt
        test_prompt = """===SYSTEM===
ä½ æ˜¯ä¸€ä½é‡‘èåˆ†æå¸ˆã€‚è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

**è¦æ±‚ï¼š**
1. å›ç­”è¦å®Œæ•´ï¼Œå¥å­è¦ç»“æŸ
2. æ§åˆ¶åœ¨2å¥è¯å†…
3. ç”¨ä¸­æ–‡å›ç­”

===USER===
Apple Inc. reported Q3 2023 revenue of $81.8 billion.

é—®é¢˜ï¼šHow did Apple perform in Q3 2023?

å›ç­”ï¼š==="""
        
        print("1. å¯ç”¨å¥å­å®Œæ•´æ€§æ£€æµ‹...")
        generator.config.generator.enable_sentence_completion = True
        generator.config.generator.max_completion_attempts = 3
        generator.config.generator.token_increment = 100
        
        print("ğŸš€ å¼€å§‹ç”Ÿæˆ...")
        responses = generator.generate([test_prompt])
        response_with_completion = responses[0] if responses else "ç”Ÿæˆå¤±è´¥"
        
        print(f"å¯ç”¨å®Œæ•´æ€§æ£€æµ‹çš„å“åº”: {response_with_completion}")
        
        print("\n2. ç¦ç”¨å¥å­å®Œæ•´æ€§æ£€æµ‹...")
        generator.config.generator.enable_sentence_completion = False
        
        print("ğŸš€ å¼€å§‹ç”Ÿæˆ...")
        responses = generator.generate([test_prompt])
        response_without_completion = responses[0] if responses else "ç”Ÿæˆå¤±è´¥"
        
        print(f"ç¦ç”¨å®Œæ•´æ€§æ£€æµ‹çš„å“åº”: {response_without_completion}")
        
        # æ¯”è¾ƒç»“æœ
        print(f"\n3. ç»“æœæ¯”è¾ƒ:")
        print(f"å¯ç”¨å®Œæ•´æ€§æ£€æµ‹: {len(response_with_completion)} å­—ç¬¦")
        print(f"ç¦ç”¨å®Œæ•´æ€§æ£€æµ‹: {len(response_without_completion)} å­—ç¬¦")
        
        is_complete_with = response_with_completion.strip().endswith(("ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"))
        is_complete_without = response_without_completion.strip().endswith(("ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"))
        
        print(f"å¯ç”¨å®Œæ•´æ€§æ£€æµ‹ - å¥å­å®Œæ•´: {'æ˜¯' if is_complete_with else 'å¦'}")
        print(f"ç¦ç”¨å®Œæ•´æ€§æ£€æµ‹ - å¥å­å®Œæ•´: {'æ˜¯' if is_complete_without else 'å¦'}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¥å­å®Œæ•´æ€§æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    # æµ‹è¯•ä¸åŒçš„ token é•¿åº¦è®¾ç½®
    test_token_length_settings()
    
    # æµ‹è¯•å¥å­å®Œæ•´æ€§æ£€æµ‹
    test_sentence_completion()
    
    print("\nğŸ‰ Token é•¿åº¦ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main() 