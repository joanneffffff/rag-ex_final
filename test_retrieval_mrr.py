#!/usr/bin/env python3
"""
æµ‹è¯•æ£€ç´¢è´¨é‡ - MRRè¯„ä¼°
ä½¿ç”¨evaluate_mrr/alphafin_eval.jsonlå’Œtatqa_eval.jsonlä½œä¸ºæµ‹è¯•é›†
æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
1. è¯„ä¼°æ•°æ®contextåŠ å…¥çŸ¥è¯†åº“ - æµ‹è¯•çœŸå®æ£€ç´¢èƒ½åŠ›
2. è¯„ä¼°æ•°æ®contextä¸åŠ å…¥çŸ¥è¯†åº“ - é¿å…æ•°æ®æ³„éœ²
"""

import sys
import os
import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional
from tqdm import tqdm

sys.path.append(str(Path(__file__).parent))

# å¯¼å…¥å¿…è¦çš„ç±»å‹
from xlm.dto.dto import DocumentWithMetadata

def load_eval_data(eval_file: str) -> List[Dict[str, Any]]:
    """åŠ è½½è¯„ä¼°æ•°æ®"""
    data = []
    with open(eval_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data.append(json.loads(line))
    return data

def calculate_mrr(ranks: List[int]) -> float:
    """è®¡ç®—MRR (Mean Reciprocal Rank)"""
    if not ranks:
        return 0.0
    reciprocal_ranks = [1.0 / rank if rank > 0 else 0.0 for rank in ranks]
    return float(np.mean(reciprocal_ranks))

def calculate_hit_rate(ranks: List[int], k: int = 1) -> float:
    """è®¡ç®—Hit@k"""
    if not ranks:
        return 0.0
    hits = [1 if rank <= k and rank > 0 else 0 for rank in ranks]
    return float(np.mean(hits))

def test_retrieval_with_eval_context(include_eval_data: bool = True):
    """æµ‹è¯•æ£€ç´¢è´¨é‡ - å¯é€‰æ‹©æ˜¯å¦åŒ…å«è¯„ä¼°æ•°æ®åˆ°çŸ¥è¯†åº“"""
    mode = "åŒ…å«è¯„ä¼°æ•°æ®" if include_eval_data else "ä¸åŒ…å«è¯„ä¼°æ•°æ®"
    print("=" * 60)
    print(f"æµ‹è¯•æ£€ç´¢è´¨é‡ - MRRè¯„ä¼° ({mode})")
    print("=" * 60)
    
    try:
        from config.parameters import Config
        from xlm.components.retriever.bilingual_retriever import BilingualRetriever
        from xlm.components.encoder.finbert import FinbertEncoder
        from xlm.utils.optimized_data_loader import OptimizedDataLoader
        
        config = Config()
        
        print("1. åŠ è½½ç¼–ç å™¨...")
        encoder_ch = FinbertEncoder(
            model_name="models/finetuned_alphafin_zh",
            cache_dir=config.encoder.cache_dir,
        )
        encoder_en = FinbertEncoder(
            model_name="models/finetuned_finbert_tatqa",
            cache_dir=config.encoder.cache_dir,
        )
        print("   âœ… ç¼–ç å™¨åŠ è½½æˆåŠŸ")
        
        print(f"\n2. åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆçŸ¥è¯†åº“ï¼‰...")
        data_loader = OptimizedDataLoader(
            data_dir="data",
            max_samples=-1,  # åŠ è½½æ‰€æœ‰æ•°æ®
            chinese_document_level=True,
            english_chunk_level=True,
            include_eval_data=include_eval_data  # æ§åˆ¶æ˜¯å¦åŒ…å«è¯„ä¼°æ•°æ®
        )
        
        chinese_chunks = data_loader.chinese_docs
        english_chunks = data_loader.english_docs
        
        print(f"   âœ… è®­ç»ƒæ•°æ®åŠ è½½æˆåŠŸ:")
        print(f"      ä¸­æ–‡chunks: {len(chinese_chunks)}")
        print(f"      è‹±æ–‡chunks: {len(english_chunks)}")
        
        print("\n3. åŠ è½½è¯„ä¼°æ•°æ®...")
        alphafin_eval = load_eval_data("evaluate_mrr/alphafin_eval.jsonl")
        tatqa_eval = load_eval_data("evaluate_mrr/tatqa_eval.jsonl")
        
        print(f"   âœ… è¯„ä¼°æ•°æ®åŠ è½½æˆåŠŸ:")
        print(f"      AlphaFinè¯„ä¼°æ ·æœ¬: {len(alphafin_eval)}")
        print(f"      TatQAè¯„ä¼°æ ·æœ¬: {len(tatqa_eval)}")
        
        print("\n4. åˆ›å»ºæ£€ç´¢å™¨...")
        retriever = BilingualRetriever(
            encoder_en=encoder_en,
            encoder_ch=encoder_ch,
            corpus_documents_en=english_chunks,
            corpus_documents_ch=chinese_chunks,
            use_faiss=True,
            use_gpu=False,
            batch_size=8,
            cache_dir=config.encoder.cache_dir
        )
        print("   âœ… æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
        
        print("\n5. æµ‹è¯•ä¸­æ–‡æ£€ç´¢è´¨é‡ (AlphaFin)...")
        chinese_ranks = []
        chinese_queries = []
        
        for i, sample in enumerate(tqdm(alphafin_eval[:100], desc="æµ‹è¯•ä¸­æ–‡æ£€ç´¢")):  # æµ‹è¯•å‰100ä¸ªæ ·æœ¬
            query = sample.get('question', '')
            context = sample.get('context', '')
            
            if not query or not context:
                continue
                
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            retrieved_result = retriever.retrieve(
                text=query, 
                top_k=20, 
                return_scores=True, 
                language='zh'
            )
            
            # å¤„ç†è¿”å›å€¼ï¼šå¯èƒ½æ˜¯å…ƒç»„(documents, scores)æˆ–åªæ˜¯documents
            if isinstance(retrieved_result, tuple):
                retrieved_docs, scores = retrieved_result
            else:
                retrieved_docs = retrieved_result
                scores = []
            
            # æ£€æŸ¥æ­£ç¡®ç­”æ¡ˆæ˜¯å¦åœ¨æ£€ç´¢ç»“æœä¸­
            found_rank = 0
            for rank, doc in enumerate(retrieved_docs, 1):
                if context in doc.content or doc.content in context:
                    found_rank = rank
                    break
            
            chinese_ranks.append(found_rank)
            chinese_queries.append(query)
            
            if i < 5:  # æ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
                print(f"   æŸ¥è¯¢ {i+1}: {query[:50]}...")
                print(f"   æ‰¾åˆ°ä½ç½®: {found_rank}")
                if found_rank > 0:
                    print(f"   ç›¸å…³æ–‡æ¡£: {retrieved_docs[found_rank-1].content[:100]}...")
                print()
        
        print("\n6. æµ‹è¯•è‹±æ–‡æ£€ç´¢è´¨é‡ (TatQA)...")
        english_ranks = []
        english_queries = []
        
        for i, sample in enumerate(tqdm(tatqa_eval[:100], desc="æµ‹è¯•è‹±æ–‡æ£€ç´¢")):  # æµ‹è¯•å‰100ä¸ªæ ·æœ¬
            query = sample.get('question', '')
            context = sample.get('context', '')
            
            if not query or not context:
                continue
                
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            retrieved_result = retriever.retrieve(
                text=query, 
                top_k=20, 
                return_scores=True, 
                language='en'
            )
            
            # å¤„ç†è¿”å›å€¼ï¼šå¯èƒ½æ˜¯å…ƒç»„(documents, scores)æˆ–åªæ˜¯documents
            if isinstance(retrieved_result, tuple):
                retrieved_docs, scores = retrieved_result
            else:
                retrieved_docs = retrieved_result
                scores = []
            
            # æ£€æŸ¥æ­£ç¡®ç­”æ¡ˆæ˜¯å¦åœ¨æ£€ç´¢ç»“æœä¸­
            found_rank = 0
            for rank, doc in enumerate(retrieved_docs, 1):
                if context in doc.content or doc.content in context:
                    found_rank = rank
                    break
            
            english_ranks.append(found_rank)
            english_queries.append(query)
            
            if i < 5:  # æ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
                print(f"   Query {i+1}: {query[:50]}...")
                print(f"   Found at rank: {found_rank}")
                if found_rank > 0:
                    print(f"   Relevant doc: {retrieved_docs[found_rank-1].content[:100]}...")
                print()
        
        print("\n" + "=" * 60)
        print(f"æ£€ç´¢è´¨é‡è¯„ä¼°ç»“æœ ({mode})")
        print("=" * 60)
        
        # è®¡ç®—ä¸­æ–‡æ£€ç´¢æŒ‡æ ‡
        chinese_mrr = calculate_mrr(chinese_ranks)
        chinese_hit1 = calculate_hit_rate(chinese_ranks, k=1)
        chinese_hit5 = calculate_hit_rate(chinese_ranks, k=5)
        chinese_hit10 = calculate_hit_rate(chinese_ranks, k=10)
        
        print(f"ä¸­æ–‡æ£€ç´¢ (AlphaFin):")
        print(f"  æ ·æœ¬æ•°: {len(chinese_ranks)}")
        print(f"  MRR: {chinese_mrr:.4f}")
        print(f"  Hit@1: {chinese_hit1:.4f}")
        print(f"  Hit@5: {chinese_hit5:.4f}")
        print(f"  Hit@10: {chinese_hit10:.4f}")
        
        # è®¡ç®—è‹±æ–‡æ£€ç´¢æŒ‡æ ‡
        english_mrr = calculate_mrr(english_ranks)
        english_hit1 = calculate_hit_rate(english_ranks, k=1)
        english_hit5 = calculate_hit_rate(english_ranks, k=5)
        english_hit10 = calculate_hit_rate(english_ranks, k=10)
        
        print(f"\nè‹±æ–‡æ£€ç´¢ (TatQA):")
        print(f"  æ ·æœ¬æ•°: {len(english_ranks)}")
        print(f"  MRR: {english_mrr:.4f}")
        print(f"  Hit@1: {english_hit1:.4f}")
        print(f"  Hit@5: {english_hit5:.4f}")
        print(f"  Hit@10: {english_hit10:.4f}")
        
        # æ€»ä½“æŒ‡æ ‡
        all_ranks = chinese_ranks + english_ranks
        overall_mrr = calculate_mrr(all_ranks)
        overall_hit1 = calculate_hit_rate(all_ranks, k=1)
        overall_hit5 = calculate_hit_rate(all_ranks, k=5)
        overall_hit10 = calculate_hit_rate(all_ranks, k=10)
        
        print(f"\næ€»ä½“æ£€ç´¢:")
        print(f"  æ ·æœ¬æ•°: {len(all_ranks)}")
        print(f"  MRR: {overall_mrr:.4f}")
        print(f"  Hit@1: {overall_hit1:.4f}")
        print(f"  Hit@5: {overall_hit5:.4f}")
        print(f"  Hit@10: {overall_hit10:.4f}")
        
        # ä¿å­˜ç»“æœ
        suffix = "with_eval" if include_eval_data else "without_eval"
        results = {
            "mode": mode,
            "chinese": {
                "mrr": chinese_mrr,
                "hit1": chinese_hit1,
                "hit5": chinese_hit5,
                "hit10": chinese_hit10,
                "sample_count": len(chinese_ranks)
            },
            "english": {
                "mrr": english_mrr,
                "hit1": english_hit1,
                "hit5": english_hit5,
                "hit10": english_hit10,
                "sample_count": len(english_ranks)
            },
            "overall": {
                "mrr": overall_mrr,
                "hit1": overall_hit1,
                "hit5": overall_hit5,
                "hit10": overall_hit10,
                "sample_count": len(all_ranks)
            }
        }
        
        filename = f"retrieval_mrr_results_{suffix}.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
        return results
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def compare_retrieval_modes():
    """å¯¹æ¯”ä¸¤ç§æ£€ç´¢æ¨¡å¼çš„æ•ˆæœ"""
    print("=" * 80)
    print("å¯¹æ¯”æ£€ç´¢æ¨¡å¼ï¼šåŒ…å«è¯„ä¼°æ•°æ® vs ä¸åŒ…å«è¯„ä¼°æ•°æ®")
    print("=" * 80)
    
    # æµ‹è¯•åŒ…å«è¯„ä¼°æ•°æ®çš„æ¨¡å¼
    print("\nğŸ” æµ‹è¯•æ¨¡å¼1ï¼šåŒ…å«è¯„ä¼°æ•°æ®åˆ°çŸ¥è¯†åº“")
    results_with_eval = test_retrieval_with_eval_context(include_eval_data=True)
    
    print("\n" + "=" * 80)
    
    # æµ‹è¯•ä¸åŒ…å«è¯„ä¼°æ•°æ®çš„æ¨¡å¼
    print("\nğŸ” æµ‹è¯•æ¨¡å¼2ï¼šä¸åŒ…å«è¯„ä¼°æ•°æ®åˆ°çŸ¥è¯†åº“")
    results_without_eval = test_retrieval_with_eval_context(include_eval_data=False)
    
    # å¯¹æ¯”ç»“æœ
    if results_with_eval and results_without_eval:
        print("\n" + "=" * 80)
        print("æ¨¡å¼å¯¹æ¯”ç»“æœ")
        print("=" * 80)
        
        print(f"{'æŒ‡æ ‡':<15} {'åŒ…å«è¯„ä¼°æ•°æ®':<15} {'ä¸åŒ…å«è¯„ä¼°æ•°æ®':<15} {'å·®å¼‚':<10}")
        print("-" * 60)
        
        # ä¸­æ–‡å¯¹æ¯”
        ch_zh_mrr_diff = results_with_eval["chinese"]["mrr"] - results_without_eval["chinese"]["mrr"]
        ch_zh_hit1_diff = results_with_eval["chinese"]["hit1"] - results_without_eval["chinese"]["hit1"]
        
        print(f"{'ä¸­æ–‡MRR':<15} {results_with_eval['chinese']['mrr']:<15.4f} {results_without_eval['chinese']['mrr']:<15.4f} {ch_zh_mrr_diff:+.4f}")
        print(f"{'ä¸­æ–‡Hit@1':<15} {results_with_eval['chinese']['hit1']:<15.4f} {results_without_eval['chinese']['hit1']:<15.4f} {ch_zh_hit1_diff:+.4f}")
        
        # è‹±æ–‡å¯¹æ¯”
        ch_en_mrr_diff = results_with_eval["english"]["mrr"] - results_without_eval["english"]["mrr"]
        ch_en_hit1_diff = results_with_eval["english"]["hit1"] - results_without_eval["english"]["hit1"]
        
        print(f"{'è‹±æ–‡MRR':<15} {results_with_eval['english']['mrr']:<15.4f} {results_without_eval['english']['mrr']:<15.4f} {ch_en_mrr_diff:+.4f}")
        print(f"{'è‹±æ–‡Hit@1':<15} {results_with_eval['english']['hit1']:<15.4f} {results_without_eval['english']['hit1']:<15.4f} {ch_en_hit1_diff:+.4f}")
        
        # æ€»ä½“å¯¹æ¯”
        ch_overall_mrr_diff = results_with_eval["overall"]["mrr"] - results_without_eval["overall"]["mrr"]
        ch_overall_hit1_diff = results_with_eval["overall"]["hit1"] - results_without_eval["overall"]["hit1"]
        
        print(f"{'æ€»ä½“MRR':<15} {results_with_eval['overall']['mrr']:<15.4f} {results_without_eval['overall']['mrr']:<15.4f} {ch_overall_mrr_diff:+.4f}")
        print(f"{'æ€»ä½“Hit@1':<15} {results_with_eval['overall']['hit1']:<15.4f} {results_without_eval['overall']['hit1']:<15.4f} {ch_overall_hit1_diff:+.4f}")
        
        # ä¿å­˜å¯¹æ¯”ç»“æœ
        comparison_results = {
            "with_eval_data": results_with_eval,
            "without_eval_data": results_without_eval,
            "differences": {
                "chinese_mrr_diff": ch_zh_mrr_diff,
                "chinese_hit1_diff": ch_zh_hit1_diff,
                "english_mrr_diff": ch_en_mrr_diff,
                "english_hit1_diff": ch_en_hit1_diff,
                "overall_mrr_diff": ch_overall_mrr_diff,
                "overall_hit1_diff": ch_overall_hit1_diff
            }
        }
        
        with open("retrieval_comparison_results.json", "w", encoding="utf-8") as f:
            json.dump(comparison_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nå¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: retrieval_comparison_results.json")
        
        # åˆ†æå»ºè®®
        print(f"\nğŸ“Š åˆ†æå»ºè®®:")
        if ch_overall_mrr_diff > 0.1:
            print(f"   âœ… åŒ…å«è¯„ä¼°æ•°æ®æ˜¾è‘—æå‡äº†æ£€ç´¢è´¨é‡ (MRRæå‡ {ch_overall_mrr_diff:.4f})")
            print(f"   ğŸ’¡ å»ºè®®ï¼šè¯„ä¼°æ•°æ®çš„contextåº”è¯¥åŠ å…¥çŸ¥è¯†åº“ä»¥æµ‹è¯•çœŸå®æ£€ç´¢èƒ½åŠ›")
        elif ch_overall_mrr_diff < -0.1:
            print(f"   âš ï¸  åŒ…å«è¯„ä¼°æ•°æ®é™ä½äº†æ£€ç´¢è´¨é‡ (MRRä¸‹é™ {abs(ch_overall_mrr_diff):.4f})")
            print(f"   ğŸ’¡ å»ºè®®ï¼šå¯èƒ½å­˜åœ¨æ•°æ®æ³„éœ²é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ")
        else:
            print(f"   ğŸ” ä¸¤ç§æ¨¡å¼æ•ˆæœç›¸è¿‘ï¼Œå·®å¼‚ä¸å¤§")
            print(f"   ğŸ’¡ å»ºè®®ï¼šå¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚é€‰æ‹©æ¨¡å¼")

def test_retrieval_quality():
    """åŸå§‹æµ‹è¯•å‡½æ•° - ä¿æŒå‘åå…¼å®¹"""
    return test_retrieval_with_eval_context(include_eval_data=False)

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æµ‹è¯•æ£€ç´¢è´¨é‡ - MRRè¯„ä¼°")
    parser.add_argument("--mode", choices=["with_eval", "without_eval", "compare"], 
                       default="compare", help="æµ‹è¯•æ¨¡å¼")
    
    args = parser.parse_args()
    
    if args.mode == "with_eval":
        success = test_retrieval_with_eval_context(include_eval_data=True)
        if success:
            print("\nğŸ‰ åŒ…å«è¯„ä¼°æ•°æ®çš„æ£€ç´¢è´¨é‡æµ‹è¯•å®Œæˆï¼")
        else:
            print("\nâŒ åŒ…å«è¯„ä¼°æ•°æ®çš„æ£€ç´¢è´¨é‡æµ‹è¯•å¤±è´¥ï¼")
    elif args.mode == "without_eval":
        success = test_retrieval_with_eval_context(include_eval_data=False)
        if success:
            print("\nğŸ‰ ä¸åŒ…å«è¯„ä¼°æ•°æ®çš„æ£€ç´¢è´¨é‡æµ‹è¯•å®Œæˆï¼")
        else:
            print("\nâŒ ä¸åŒ…å«è¯„ä¼°æ•°æ®çš„æ£€ç´¢è´¨é‡æµ‹è¯•å¤±è´¥ï¼")
    else:  # compare
        compare_retrieval_modes()
        print("\nğŸ‰ æ£€ç´¢æ¨¡å¼å¯¹æ¯”æµ‹è¯•å®Œæˆï¼") 