#!/usr/bin/env python3
"""
å¿«é€Ÿ Prompt æµ‹è¯•è„šæœ¬
ç”¨äºå¿«é€Ÿæµ‹è¯•å•ä¸ª Prompt å˜ä½“çš„æ•ˆæœ
"""

import sys
import os
from pathlib import Path

# Add parent directory to path
sys.path.append(str(Path(__file__).parent))

def test_single_prompt():
    """æµ‹è¯•å•ä¸ª Prompt å˜ä½“"""
    
    print("=== å¿«é€Ÿ Prompt æµ‹è¯• ===")
    print("æµ‹è¯•é—®é¢˜ï¼šå¾·èµ›ç”µæ± ï¼ˆ000049ï¼‰2021å¹´åˆ©æ¶¦æŒç»­å¢é•¿çš„ä¸»è¦åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ")
    print("=" * 60)
    
    try:
        from xlm.components.generator.local_llm_generator import LocalLLMGenerator
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        print("1. åˆå§‹åŒ– LLM ç”Ÿæˆå™¨...")
        generator = LocalLLMGenerator()
        print(f"âœ… ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ: {generator.model_name}")
        
        # æµ‹è¯•æ•°æ®
        test_context = """
        å¾·èµ›ç”µæ± ï¼ˆ000049ï¼‰2021å¹´ä¸šç»©é¢„å‘Šæ˜¾ç¤ºï¼Œå…¬å¸é¢„è®¡å®ç°å½’å±äºä¸Šå¸‚å…¬å¸è‚¡ä¸œçš„å‡€åˆ©æ¶¦ä¸º6.5äº¿å…ƒè‡³7.5äº¿å…ƒï¼Œ
        åŒæ¯”å¢é•¿11.02%è‡³28.23%ã€‚ä¸šç»©å¢é•¿çš„ä¸»è¦åŸå› æ˜¯ï¼š
        1. iPhone 12 Pro Maxç­‰é«˜ç«¯äº§å“éœ€æ±‚å¼ºåŠ²ï¼Œå¸¦åŠ¨å…¬å¸ç”µæ± ä¸šåŠ¡å¢é•¿
        2. æ–°äº§å“ç›ˆåˆ©èƒ½åŠ›æå‡ï¼Œæ¯›åˆ©ç‡æ”¹å–„
        3. Aå®¢æˆ·ä¸šåŠ¡æŒç»­æˆé•¿ï¼Œéæ‰‹æœºä¸šåŠ¡ç¨³æ­¥å¢é•¿
        4. å¹¶è¡¨æ¯”ä¾‹å¢åŠ ï¼Œè´¡çŒ®ä¸šç»©å¢é‡
        """
        
        test_summary = "å¾·èµ›ç”µæ± 2021å¹´ä¸šç»©å¢é•¿ä¸»è¦å—ç›ŠäºiPhone 12 Pro Maxéœ€æ±‚å¼ºåŠ²å’Œæ–°å“ç›ˆåˆ©èƒ½åŠ›æå‡ã€‚"
        test_query = "å¾·èµ›ç”µæ± ï¼ˆ000049ï¼‰2021å¹´åˆ©æ¶¦æŒç»­å¢é•¿çš„ä¸»è¦åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ"
        
        # å½“å‰æµ‹è¯•çš„ Prompt å˜ä½“ï¼ˆå¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹æµ‹è¯•ä¸åŒçš„ç‰ˆæœ¬ï¼‰
        current_prompt = f"""ä½ æ˜¯ä¸€ä½é‡‘èåˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

æ‘˜è¦ï¼š{test_summary}

è¯¦ç»†å†…å®¹ï¼š{test_context}

é—®é¢˜ï¼š{test_query}

å›ç­”ï¼š"""
        
        print(f"\n2. å½“å‰æµ‹è¯•çš„ Prompt:")
        print("-" * 40)
        print(current_prompt)
        print("-" * 40)
        print(f"Prompt é•¿åº¦: {len(current_prompt)} å­—ç¬¦")
        
        # æµ‹è¯•å‚æ•°ï¼ˆå¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹ï¼‰
        test_params = {
            "temperature": 0.2,
            "top_p": 0.8,
            "max_new_tokens": 200
        }
        
        print(f"\n3. æµ‹è¯•å‚æ•°:")
        print(f"   Temperature: {test_params['temperature']}")
        print(f"   Top-p: {test_params['top_p']}")
        print(f"   Max tokens: {test_params['max_new_tokens']}")
        
        # ä¸´æ—¶ä¿®æ”¹å‚æ•°
        original_temp = generator.temperature
        original_top_p = generator.top_p
        original_max_tokens = generator.max_new_tokens
        
        try:
            generator.temperature = test_params["temperature"]
            generator.top_p = test_params["top_p"]
            generator.max_new_tokens = test_params["max_new_tokens"]
            
            # ç”Ÿæˆå“åº”
            print(f"\n4. ç”Ÿæˆå“åº”...")
            print("ğŸš€ å¼€å§‹ç”Ÿæˆï¼Œè¯·ç¨å€™...")
            
            responses = generator.generate([current_prompt])
            response = responses[0] if responses else "ç”Ÿæˆå¤±è´¥"
            
            print(f"\n5. ç”Ÿæˆç»“æœ:")
            print("=" * 60)
            print(f"é—®é¢˜: {test_query}")
            print(f"ç­”æ¡ˆ: {response}")
            print("=" * 60)
            
            # ç®€å•è¯„ä¼°
            print(f"\n6. ç®€å•è¯„ä¼°:")
            length = len(response.strip())
            print(f"   å“åº”é•¿åº¦: {length} å­—ç¬¦")
            print(f"   ç®€æ´æ€§: {'âœ…' if 50 <= length <= 200 else 'âŒ'} (ç†æƒ³: 50-200å­—ç¬¦)")
            
            key_terms = ["å¾·èµ›ç”µæ± ", "iPhone", "éœ€æ±‚", "å¢é•¿", "åˆ©æ¶¦", "ä¸šç»©"]
            found_terms = [term for term in key_terms if term in response]
            print(f"   å…³é”®ä¿¡æ¯: {found_terms}")
            print(f"   å‡†ç¡®æ€§: {'âœ…' if len(found_terms) >= 3 else 'âŒ'} (æ‰¾åˆ°{len(found_terms)}ä¸ªå…³é”®è¯)")
            
            unwanted_patterns = ["ã€", "ã€‘", "å›ç­”ï¼š", "Answer:", "---", "===", "___"]
            has_unwanted = any(pattern in response for pattern in unwanted_patterns)
            print(f"   çº¯ç²¹æ€§: {'âœ…' if not has_unwanted else 'âŒ'} (æ— æ ¼å¼æ ‡è®°)")
            
            is_complete = response.strip().endswith(("ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"))
            print(f"   å®Œæ•´æ€§: {'âœ…' if is_complete else 'âŒ'} (å¥å­å®Œæ•´)")
            
            # æ€»ä½“è¯„åˆ†
            score = 0
            if 50 <= length <= 200: score += 25
            if len(found_terms) >= 3: score += 25
            if not has_unwanted: score += 25
            if is_complete: score += 25
            
            print(f"\nğŸ¯ æ€»ä½“è¯„åˆ†: {score}/100 ({score}%)")
            
            if score >= 75:
                print("ğŸ‰ æ•ˆæœå¾ˆå¥½ï¼")
            elif score >= 50:
                print("âš ï¸ æ•ˆæœä¸€èˆ¬ï¼Œå¯ä»¥ç»§ç»­ä¼˜åŒ–")
            else:
                print("âŒ æ•ˆæœä¸ä½³ï¼Œéœ€è¦é‡æ–°è®¾è®¡")
            
        finally:
            # æ¢å¤åŸå§‹å‚æ•°
            generator.temperature = original_temp
            generator.top_p = original_top_p
            generator.max_new_tokens = original_max_tokens
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_single_prompt() 