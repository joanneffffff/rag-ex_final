#!/usr/bin/env python3
"""
å°†è¯„ä¼°æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›†å’Œè¯„ä¼°é›†
è¿™æ ·æˆ‘ä»¬å°±æœ‰åŒ…å«çœŸæ­£æ‘˜è¦çš„è®­ç»ƒæ•°æ®äº†
"""

import json
import random
from pathlib import Path

def split_eval_data(input_file, train_output, eval_output, train_ratio=0.8, seed=42):
    """
    å°†è¯„ä¼°æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›†å’Œè¯„ä¼°é›†
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        train_output: è®­ç»ƒæ•°æ®è¾“å‡ºæ–‡ä»¶
        eval_output: è¯„ä¼°æ•°æ®è¾“å‡ºæ–‡ä»¶
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        seed: éšæœºç§å­
    """
    print(f"åˆ†å‰²è¯„ä¼°æ•°æ®: {input_file}")
    
    # è¯»å–æ•°æ®
    data = []
    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data.append(json.loads(line))
    
    print(f"æ€»æ•°æ®é‡: {len(data)} æ¡")
    
    # éšæœºæ‰“ä¹±
    random.seed(seed)
    random.shuffle(data)
    
    # åˆ†å‰²
    n_train = int(len(data) * train_ratio)
    train_data = data[:n_train]
    eval_data = data[n_train:]
    
    print(f"åˆ†å‰²ç»“æœ:")
    print(f"  - è®­ç»ƒé›†: {len(train_data)} æ¡ ({train_ratio*100:.0f}%)")
    print(f"  - è¯„ä¼°é›†: {len(eval_data)} æ¡ ({(1-train_ratio)*100:.0f}%)")
    
    # ä¿å­˜è®­ç»ƒé›†ï¼ˆåªä¿ç•™è®­ç»ƒéœ€è¦çš„å­—æ®µï¼‰
    print(f"ä¿å­˜è®­ç»ƒé›†: {train_output}")
    with open(train_output, 'w', encoding='utf-8') as f:
        for item in train_data:
            train_item = {
                'generated_question': item['generated_question'],
                'summary': item['summary'],
                'doc_id': item['doc_id']
            }
            f.write(json.dumps(train_item, ensure_ascii=False) + '\n')
    
    # ä¿å­˜è¯„ä¼°é›†ï¼ˆä¿ç•™å®Œæ•´å­—æ®µï¼‰
    print(f"ä¿å­˜è¯„ä¼°é›†: {eval_output}")
    with open(eval_output, 'w', encoding='utf-8') as f:
        for item in eval_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print("âœ… åˆ†å‰²å®Œæˆï¼")
    
    return len(train_data), len(eval_data)

def main():
    input_file = "evaluate_mrr/alphafin_eval_summary.jsonl"
    train_output = "evaluate_mrr/alphafin_train_summary.jsonl"
    eval_output = "evaluate_mrr/alphafin_eval_summary_split.jsonl"
    
    if not Path(input_file).exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    train_count, eval_count = split_eval_data(
        input_file=input_file,
        train_output=train_output,
        eval_output=eval_output,
        train_ratio=0.8,
        seed=42
    )
    
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ:")
    print(f"  - è®­ç»ƒæ•°æ®: {train_count} æ¡ (åŒ…å«çœŸæ­£çš„æ‘˜è¦)")
    print(f"  - è¯„ä¼°æ•°æ®: {eval_count} æ¡")
    print(f"  - è®­ç»ƒæ–‡ä»¶: {train_output}")
    print(f"  - è¯„ä¼°æ–‡ä»¶: {eval_output}")

if __name__ == "__main__":
    main() 