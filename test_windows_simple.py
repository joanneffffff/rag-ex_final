#!/usr/bin/env python3
"""
ç®€åŒ–çš„Windowsç¯å¢ƒæµ‹è¯•è„šæœ¬
"""

import os
import sys
import traceback
from pathlib import Path

# Add current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def check_gpu():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print("=== GPUç¯å¢ƒæ£€æŸ¥ ===")
    
    try:
        import torch
        if torch.cuda.is_available():
            print("âœ… CUDAå¯ç”¨")
            print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"GPUåç§°: {torch.cuda.get_device_name()}")
            return "cuda"
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
            return "cpu"
    except ImportError:
        print("âš ï¸  PyTorchæœªå®‰è£…")
        return "cpu"
    except Exception as e:
        print(f"âš ï¸  GPUæ£€æŸ¥å¤±è´¥: {e}")
        return "cpu"

def check_models():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    print("\n=== æ¨¡å‹æ–‡ä»¶æ£€æŸ¥ ===")
    
    try:
        from config.parameters import Config
        config = Config()
        
        models = [
            ("ä¸­æ–‡ç¼–ç å™¨", config.encoder.chinese_model_path),
            ("è‹±æ–‡ç¼–ç å™¨", config.encoder.english_model_path),
            ("é‡æ’åºå™¨", config.reranker.model_name),
            ("ç”Ÿæˆå™¨", config.generator.model_name)
        ]
        
        for name, path in models:
            if os.path.exists(path):
                print(f"âœ… {name}: {path}")
            else:
                print(f"âŒ {name}: {path} (ä¸å­˜åœ¨)")
        
        return config
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return None

def check_data():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶"""
    print("\n=== æ•°æ®æ–‡ä»¶æ£€æŸ¥ ===")
    
    data_files = [
        ("ä¸­æ–‡æ•°æ®1", "data/alphafin/alphafin_rag_ready_generated_cleaned.json"),
        ("ä¸­æ–‡æ•°æ®2", "evaluate_mrr/alphafin_train_qc.jsonl"),
        ("è‹±æ–‡æ•°æ®1", "data/tatqa_dataset_raw/tatqa_dataset_train.json"),
        ("è‹±æ–‡æ•°æ®2", "evaluate_mrr/tatqa_train_qc.jsonl")
    ]
    
    available_data = {}
    
    for name, path in data_files:
        if os.path.exists(path):
            size = os.path.getsize(path) / (1024**2)  # MB
            print(f"âœ… {name}: {path} ({size:.1f} MB)")
            if "ä¸­æ–‡" in name:
                available_data["chinese"] = path
            elif "è‹±æ–‡" in name:
                available_data["english"] = path
        else:
            print(f"âŒ {name}: {path} (ä¸å­˜åœ¨)")
    
    return available_data

def test_basic_retrieval():
    """æµ‹è¯•åŸºæœ¬æ£€ç´¢åŠŸèƒ½"""
    print("\n=== åŸºæœ¬æ£€ç´¢æµ‹è¯• ===")
    
    try:
        from xlm.components.encoder.encoder import Encoder
        from xlm.components.retriever.sbert_retriever import SBERTRetriever
        from xlm.dto.dto import DocumentWithMetadata, DocumentMetadata
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        test_docs = [
            DocumentWithMetadata(
                content="è¿™æ˜¯ä¸€ä¸ªå…³äºå‡€åˆ©æ¶¦çš„æµ‹è¯•æ–‡æ¡£ã€‚å‡€åˆ©æ¶¦æ˜¯å…¬å¸æ”¶å…¥å‡å»æ‰€æœ‰è´¹ç”¨åçš„å‰©ä½™é‡‘é¢ã€‚",
                metadata=DocumentMetadata(
                    doc_id="test_1",
                    source="test",
                    language="chinese"
                )
            ),
            DocumentWithMetadata(
                content="This is a test document about net income. Net income is the remaining amount after subtracting all expenses from revenue.",
                metadata=DocumentMetadata(
                    doc_id="test_2",
                    source="test",
                    language="english"
                )
            )
        ]
        
        # åŠ è½½ç¼–ç å™¨
        print("åŠ è½½ç¼–ç å™¨...")
        encoder = Encoder(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            device="cpu"  # å…ˆç”¨CPUæµ‹è¯•
        )
        
        # åˆ›å»ºæ£€ç´¢å™¨
        print("åˆ›å»ºæ£€ç´¢å™¨...")
        retriever = SBERTRetriever(
            encoder=encoder,
            corpus_documents=test_docs,
            use_faiss=False  # å…ˆç”¨ç®€å•æ¨¡å¼
        )
        
        # æµ‹è¯•æ£€ç´¢
        test_queries = ["ä»€ä¹ˆæ˜¯å‡€åˆ©æ¶¦ï¼Ÿ", "What is net income?"]
        
        for query in test_queries:
            try:
                docs, scores = retriever.retrieve(query, top_k=2, return_scores=True)
                print(f"âœ… '{query}' -> æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
                if docs:
                    print(f"   æœ€é«˜åˆ†æ•°: {scores[0]:.4f}")
                    print(f"   æ–‡æ¡£å†…å®¹: {docs[0].content[:100]}...")
            except Exception as e:
                print(f"âŒ '{query}' -> æ£€ç´¢å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŸºæœ¬æ£€ç´¢æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_enhanced_system(config, data_files):
    """æµ‹è¯•å¢å¼ºç³»ç»Ÿ"""
    print("\n=== å¢å¼ºç³»ç»Ÿæµ‹è¯• ===")
    
    try:
        from xlm.registry.retriever import load_enhanced_retriever
        
        print("åŠ è½½å¢å¼ºæ£€ç´¢å™¨...")
        
        # å‡†å¤‡æ•°æ®è·¯å¾„
        chinese_path = data_files.get("chinese", "")
        english_path = data_files.get("english", "")
        
        if not chinese_path and not english_path:
            print("âš ï¸  æ²¡æœ‰å¯ç”¨çš„æ•°æ®æ–‡ä»¶ï¼Œè·³è¿‡å¢å¼ºç³»ç»Ÿæµ‹è¯•")
            return False
        
        # åŠ è½½å¢å¼ºæ£€ç´¢å™¨ - ä½¿ç”¨å­—ç¬¦ä¸²å‚æ•°é¿å…ç±»å‹é—®é¢˜
        retriever = load_enhanced_retriever(
            config=config,
            chinese_data_path=chinese_path if chinese_path else "",
            english_data_path=english_path if english_path else ""
        )
        
        print("âœ… å¢å¼ºæ£€ç´¢å™¨åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ä»€ä¹ˆæ˜¯å‡€åˆ©æ¶¦ï¼Ÿ",
            "What is net income?",
            "å…¬å¸çš„è¥ä¸šæ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ",
            "What is the company's revenue?"
        ]
        
        for query in test_queries:
            try:
                docs, scores = retriever.retrieve(query, top_k=3, return_scores=True)
                print(f"âœ… '{query}' -> æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
                if docs:
                    print(f"   æœ€é«˜åˆ†æ•°: {scores[0]:.4f}")
            except Exception as e:
                print(f"âŒ '{query}' -> æ£€ç´¢å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¢å¼ºç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_generator(config):
    """æµ‹è¯•ç”Ÿæˆå™¨"""
    print("\n=== ç”Ÿæˆå™¨æµ‹è¯• ===")
    
    try:
        from xlm.registry.generator import load_generator
        
        print("åŠ è½½ç”Ÿæˆå™¨...")
        generator = load_generator(
            generator_model_name=config.generator.model_name,
            use_local_llm=True
        )
        
        print("âœ… ç”Ÿæˆå™¨åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•ç”ŸæˆåŠŸèƒ½
        test_prompts = [
            "Context: è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ä¸Šä¸‹æ–‡ã€‚\nQuestion: è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é—®é¢˜å—ï¼Ÿ\nAnswer:",
            "Context: This is a test context.\nQuestion: Is this a test question?\nAnswer:"
        ]
        
        print("\næµ‹è¯•ç”ŸæˆåŠŸèƒ½:")
        for prompt in test_prompts:
            try:
                response = generator.generate([prompt])
                print(f"  âœ… ç”ŸæˆæˆåŠŸ: {response[:100]}...")
            except Exception as e:
                print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
        
        return generator
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return None

def test_unified_processor():
    """æµ‹è¯•ç»Ÿä¸€æ•°æ®å¤„ç†å™¨"""
    print("\n=== ç»Ÿä¸€æ•°æ®å¤„ç†å™¨æµ‹è¯• ===")
    
    try:
        from xlm.utils.unified_chunk_processor import process_unified_data, save_processed_chunks
        
        # æµ‹è¯•æ•°æ®è·¯å¾„
        tatqa_paths = ["data/tatqa_dataset_raw/tatqa_dataset_train.json"]
        alphafin_paths = ["data/alphafin/alphafin_rag_ready_generated_cleaned.json"]
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        available_tatqa = [p for p in tatqa_paths if os.path.exists(p)]
        available_alphafin = [p for p in alphafin_paths if os.path.exists(p)]
        
        if not available_tatqa and not available_alphafin:
            print("âš ï¸  æ²¡æœ‰å¯ç”¨çš„æ•°æ®æ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†å™¨æµ‹è¯•")
            return False
        
        print("å¤„ç†æ•°æ®...")
        chunks = process_unified_data(
            tatqa_paths=available_tatqa if available_tatqa else None,
            alphafin_paths=available_alphafin if available_alphafin else None
        )
        
        print(f"âœ… å¤„ç†å®Œæˆ:")
        print(f"  ä¸­æ–‡chunks: {len(chunks['chinese'])}")
        print(f"  è‹±æ–‡chunks: {len(chunks['english'])}")
        
        # ä¿å­˜ç»“æœ
        save_processed_chunks(chunks, "data/processed")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç»Ÿä¸€æ•°æ®å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Windowsç¯å¢ƒRAGç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # 1. æ£€æŸ¥GPU
    device = check_gpu()
    
    # 2. æ£€æŸ¥æ¨¡å‹
    config = check_models()
    if not config:
        print("âŒ é…ç½®åŠ è½½å¤±è´¥")
        return
    
    # 3. æ£€æŸ¥æ•°æ®
    data_files = check_data()
    
    # 4. åŸºæœ¬æ£€ç´¢æµ‹è¯•
    basic_ok = test_basic_retrieval()
    
    # 5. å¢å¼ºç³»ç»Ÿæµ‹è¯•
    enhanced_ok = test_enhanced_system(config, data_files)
    
    # 6. ç”Ÿæˆå™¨æµ‹è¯•
    generator = test_generator(config)
    
    # 7. ç»Ÿä¸€æ•°æ®å¤„ç†å™¨æµ‹è¯•
    processor_ok = test_unified_processor()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print(f"è®¾å¤‡: {device}")
    print(f"åŸºæœ¬æ£€ç´¢: {'âœ…' if basic_ok else 'âŒ'}")
    print(f"å¢å¼ºç³»ç»Ÿ: {'âœ…' if enhanced_ok else 'âŒ'}")
    print(f"ç”Ÿæˆå™¨: {'âœ…' if generator else 'âŒ'}")
    print(f"æ•°æ®å¤„ç†å™¨: {'âœ…' if processor_ok else 'âŒ'}")
    
    if basic_ok and enhanced_ok and generator:
        print("\nâœ… ç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œï¼")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œ: python run_enhanced_ui.py")
        print("  2. æˆ–è€…è¿è¡Œ: python test_dual_space_retriever.py")
        print("  3. æˆ–è€…è¿è¡Œ: python run_optimized_ui.py")
    else:
        print("\nâŒ ç³»ç»Ÿå­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 