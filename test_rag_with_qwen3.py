#!/usr/bin/env python3
"""
ä½¿ç”¨Qwen3-8Bä½œä¸ºç”Ÿæˆå™¨çš„RAGç³»ç»Ÿæµ‹è¯•
"""

import os
import sys
import torch
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.parameters import Config
from xlm.ui.optimized_rag_ui import OptimizedRagUI


def test_rag_with_qwen3():
    """æµ‹è¯•ä½¿ç”¨Qwen3-8Bçš„RAGç³»ç»Ÿ"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä½¿ç”¨Qwen3-8Bçš„RAGç³»ç»Ÿ...")
    
    # åŠ è½½é…ç½®
    config = Config()
    print(f"ğŸ“‹ å½“å‰é…ç½®:")
    print(f"   ç”Ÿæˆå™¨æ¨¡å‹: {config.generator.model_name}")
    print(f"   é‡åŒ–: {config.generator.use_quantization} ({config.generator.quantization_type})")
    print(f"   æœ€å¤§token: {config.generator.max_new_tokens}")
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "ä»€ä¹ˆæ˜¯è‚¡ç¥¨æŠ•èµ„ï¼Ÿ",
        "è¯·è§£é‡Šå€ºåˆ¸çš„åŸºæœ¬æ¦‚å¿µ",
        "åŸºé‡‘æŠ•èµ„ä¸è‚¡ç¥¨æŠ•èµ„æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯å¸‚ç›ˆç‡ï¼Ÿ",
        "è¯·è§£é‡Šä»€ä¹ˆæ˜¯ETFåŸºé‡‘"
    ]
    
    try:
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        print("\nğŸ”§ åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        rag_ui = OptimizedRagUI(
            encoder_model_name="paraphrase-multilingual-MiniLM-L12-v2",
            enable_reranker=True,
            use_existing_embedding_index=True,
            max_alphafin_chunks=10000  # é™åˆ¶æ•°æ®é‡ä»¥åŠ å¿«æµ‹è¯•
        )
        print("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ¯ä¸ªé—®é¢˜
        results = []
        for i, question in enumerate(test_questions):
            print(f"\nğŸ” æµ‹è¯•é—®é¢˜ {i+1}: {question}")
            
            try:
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                # ä½¿ç”¨RAGç³»ç»Ÿç”Ÿæˆå›ç­”
                result = rag_ui._process_question(
                    question=question,
                    datasource="Both",
                    reranker_checkbox=True
                )
                
                # è§£åŒ…ç»“æœ
                answer, contexts, _ = result
                
                # è®°å½•ç»“æŸæ—¶é—´
                end_time = time.time()
                generation_time = end_time - start_time
                
                # ç»Ÿè®¡tokenæ•°é‡
                answer_tokens = len(answer.split()) if answer else 0
                
                print(f"   âœ… ç”ŸæˆæˆåŠŸ")
                print(f"      å›ç­”: {answer[:100]}..." if answer else "      å›ç­”: æ— ")
                print(f"      é•¿åº¦: {answer_tokens} tokens")
                print(f"      æ—¶é—´: {generation_time:.2f}s")
                print(f"      æ£€ç´¢ä¸Šä¸‹æ–‡æ•°é‡: {len(contexts) if contexts is not None else 0}")
                
                results.append({
                    "question": question,
                    "answer": answer,
                    "tokens": answer_tokens,
                    "time": generation_time,
                    "contexts_count": len(contexts) if contexts is not None else 0,
                    "success": True
                })
                
            except Exception as e:
                print(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")
                results.append({
                    "question": question,
                    "answer": f"ç”Ÿæˆå¤±è´¥: {e}",
                    "tokens": 0,
                    "time": 0,
                    "contexts_count": 0,
                    "success": False
                })
        
        # è¾“å‡ºæ€»ç»“
        print(f"\nğŸ“Š RAGç³»ç»Ÿæµ‹è¯•æ€»ç»“:")
        print(f"=" * 50)
        
        successful_generations = [r for r in results if r["success"]]
        failed_generations = [r for r in results if not r["success"]]
        
        if successful_generations:
            avg_tokens = sum(r["tokens"] for r in successful_generations) / len(successful_generations)
            avg_time = sum(r["time"] for r in successful_generations) / len(successful_generations)
            avg_contexts = sum(r["contexts_count"] for r in successful_generations) / len(successful_generations)
            
            print(f"âœ… æˆåŠŸç”Ÿæˆ: {len(successful_generations)}/{len(results)}")
            print(f"   å¹³å‡tokenæ•°: {avg_tokens:.1f}")
            print(f"   å¹³å‡ç”Ÿæˆæ—¶é—´: {avg_time:.2f}s")
            print(f"   å¹³å‡æ£€ç´¢ä¸Šä¸‹æ–‡æ•°: {avg_contexts:.1f}")
        else:
            print(f"âŒ æˆåŠŸç”Ÿæˆ: 0/{len(results)}")
        
        if failed_generations:
            print(f"âŒ å¤±è´¥ç”Ÿæˆ: {len(failed_generations)}")
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated(device=1) / 1024**3
            print(f"\nğŸ’¾ GPUå†…å­˜ä½¿ç”¨: {gpu_memory:.2f}GB")
        
        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        print(f"\nğŸ“ è¯¦ç»†ç»“æœ:")
        for i, result in enumerate(results):
            print(f"\n   é—®é¢˜ {i+1}: {result['question']}")
            if result['success']:
                print(f"   å›ç­”: {result['answer'][:150]}...")
                print(f"   æ€§èƒ½: {result['tokens']} tokens, {result['time']:.2f}s, {result['contexts_count']} contexts")
            else:
                print(f"   é”™è¯¯: {result['answer']}")
        
        print(f"\nâœ… RAGç³»ç»Ÿæµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Qwen3-8B RAGç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨ï¼ŒGPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
    else:
        print("âŒ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    
    # è¿è¡Œæµ‹è¯•
    success = test_rag_with_qwen3()
    
    if success:
        print(f"\nğŸ‰ Qwen3-8B RAGç³»ç»Ÿæµ‹è¯•æˆåŠŸï¼")
        print(f"ğŸ’¡ å»ºè®®:")
        print(f"   - Qwen3-8Bä½œä¸ºç”Ÿæˆå™¨è¡¨ç°è‰¯å¥½")
        print(f"   - å¯ä»¥è€ƒè™‘åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨")
        print(f"   - ç›¸æ¯”Fin-R1ï¼Œå†…å­˜ä½¿ç”¨æ›´åˆç†")
    else:
        print(f"\nâŒ Qwen3-8B RAGç³»ç»Ÿæµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    main() 