#!/usr/bin/env python3
"""
ä½¿ç”¨å¢å¼ºæ£€ç´¢å™¨çš„UIç¤ºä¾‹
æ”¯æŒåŒç©ºé—´åŒç´¢å¼•å’ŒQwené‡æ’åºå™¨
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import gradio as gr
from typing import List, Optional

from config.parameters import Config
from xlm.registry.retriever import load_enhanced_retriever
from xlm.registry.generator import load_generator
from xlm.registry.rag_system import load_rag_system
from xlm.dto.dto import DocumentWithMetadata

class EnhancedRagUI:
    def __init__(
        self,
        chinese_data_path: str = "data/alphafin/alphafin_rag_ready_generated_cleaned.json",
        english_data_path: str = "data/tatqa_dataset_raw/tatqa_dataset_train.json",
        cache_dir: str = None,
        use_faiss: bool = True,
        enable_reranker: bool = True
    ):
        """
        åˆå§‹åŒ–å¢å¼ºRAG UI
        
        Args:
            chinese_data_path: ä¸­æ–‡æ•°æ®è·¯å¾„
            english_data_path: è‹±æ–‡æ•°æ®è·¯å¾„
            cache_dir: ç¼“å­˜ç›®å½•
            use_faiss: æ˜¯å¦ä½¿ç”¨FAISS
            enable_reranker: æ˜¯å¦å¯ç”¨é‡æ’åºå™¨
        """
        self.chinese_data_path = chinese_data_path
        self.english_data_path = english_data_path
        self.cache_dir = cache_dir
        self.use_faiss = use_faiss
        self.enable_reranker = enable_reranker
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        if cache_dir:
            os.environ['TRANSFORMERS_CACHE'] = os.path.join(cache_dir, 'transformers')
            os.environ['HF_HOME'] = cache_dir
            os.environ['HF_DATASETS_CACHE'] = os.path.join(cache_dir, 'datasets')
        
        # åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
        self._init_components()
        
        # åˆ›å»ºGradioç•Œé¢
        self.interface = self._create_interface()
    
    def _init_components(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        print("\n=== åˆå§‹åŒ–å¢å¼ºRAGç³»ç»Ÿ ===")
        
        # åˆ›å»ºé…ç½®
        self.config = Config()
        self.config.retriever.use_faiss = self.use_faiss
        self.config.reranker.enabled = self.enable_reranker
        
        if self.cache_dir:
            self.config.cache_dir = self.cache_dir
        
        print(f"é…ç½®ä¿¡æ¯:")
        print(f"- FAISS: {self.config.retriever.use_faiss}")
        print(f"- é‡æ’åºå™¨: {self.config.reranker.enabled}")
        print(f"- ä¸­æ–‡ç¼–ç å™¨: {self.config.encoder.chinese_model_path}")
        print(f"- è‹±æ–‡ç¼–ç å™¨: {self.config.encoder.english_model_path}")
        print(f"- é‡æ’åºå™¨: {self.config.reranker.model_name}")
        
        # åŠ è½½å¢å¼ºæ£€ç´¢å™¨
        print("\n1. åŠ è½½å¢å¼ºæ£€ç´¢å™¨...")
        self.retriever = load_enhanced_retriever(
            config=self.config,
            chinese_data_path=self.chinese_data_path,
            english_data_path=self.english_data_path
        )
        
        # åŠ è½½ç”Ÿæˆå™¨
        print("\n2. åŠ è½½ç”Ÿæˆå™¨...")
        self.generator = load_generator(
            generator_model_name=self.config.generator.model_name,
            use_local_llm=True
        )
        
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        print("\n3. åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        self.prompt_template = "Context: {context}\nQuestion: {question}\nAnswer:"
        self.rag_system = load_rag_system(
            retriever=self.retriever,
            generator=self.generator,
            prompt_template=self.prompt_template
        )
        
        print("=== ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ ===")
    
    def _create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        # ç¤ºä¾‹é—®é¢˜
        examples = [
            ["å®‰äº•é£Ÿå“ä¸»è¦ç”Ÿäº§ä»€ä¹ˆäº§å“ï¼Ÿ"],
            ["å®‰äº•é£Ÿå“2020å¹´è¥ä¸šæ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ"],
            ["What does Apple Inc. specialize in?"],
            ["What was Apple's total revenue in 2023?"],
            ["è¯·ä»‹ç»ä¸€ä¸‹å®‰äº•é£Ÿå“çš„ä¸šåŠ¡æƒ…å†µ"],
            ["Explain Apple's business model"]
        ]
        
        # åˆ›å»ºç•Œé¢
        with gr.Blocks(title="Enhanced RAG System - Dual Space Dual Index") as interface:
            gr.Markdown("# ğŸš€ Enhanced RAG System")
            gr.Markdown("### åŒç©ºé—´åŒç´¢å¼• + Qwené‡æ’åºå™¨")
            gr.Markdown("æ”¯æŒä¸­è‹±æ–‡æŸ¥è¯¢ï¼Œè‡ªåŠ¨é€‰æ‹©å¯¹åº”ç¼–ç å™¨å’Œç´¢å¼•ç©ºé—´")
            
            with gr.Row():
                with gr.Column(scale=2):
                    # è¾“å…¥åŒºåŸŸ
                    query_input = gr.Textbox(
                        label="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
                        placeholder="æ”¯æŒä¸­è‹±æ–‡æŸ¥è¯¢ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶é€‰æ‹©å¯¹åº”çš„ç¼–ç å™¨...",
                        lines=3
                    )
                    
                    with gr.Row():
                        submit_btn = gr.Button("ğŸ” æ£€ç´¢å¹¶ç”Ÿæˆ", variant="primary")
                        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º")
                    
                    # å‚æ•°è®¾ç½®
                    with gr.Accordion("âš™ï¸ å‚æ•°è®¾ç½®", open=False):
                        top_k = gr.Slider(
                            minimum=1, maximum=20, value=5, step=1,
                            label="æ£€ç´¢æ–‡æ¡£æ•°é‡ (Top-K)"
                        )
                        enable_rerank = gr.Checkbox(
                            value=self.enable_reranker,
                            label="å¯ç”¨é‡æ’åºå™¨"
                        )
                
                with gr.Column(scale=1):
                    # ç³»ç»Ÿä¿¡æ¯
                    gr.Markdown("### ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
                    info_text = gr.Textbox(
                        value=f"ä¸­æ–‡æ–‡æ¡£: {self.retriever.get_corpus_size()['chinese']}\nè‹±æ–‡æ–‡æ¡£: {self.retriever.get_corpus_size()['english']}\nFAISS: {'å¯ç”¨' if self.use_faiss else 'ç¦ç”¨'}\né‡æ’åºå™¨: {'å¯ç”¨' if self.enable_reranker else 'ç¦ç”¨'}",
                        label="ç³»ç»ŸçŠ¶æ€",
                        lines=5,
                        interactive=False
                    )
            
            with gr.Row():
                with gr.Column():
                    # æ£€ç´¢ç»“æœ
                    gr.Markdown("### ğŸ“„ æ£€ç´¢åˆ°çš„æ–‡æ¡£")
                    retrieved_docs = gr.Textbox(
                        label="æ£€ç´¢ç»“æœ",
                        lines=10,
                        interactive=False
                    )
                
                with gr.Column():
                    # ç”Ÿæˆç­”æ¡ˆ
                    gr.Markdown("### ğŸ’¡ ç”Ÿæˆçš„ç­”æ¡ˆ")
                    generated_answer = gr.Textbox(
                        label="ç­”æ¡ˆ",
                        lines=10,
                        interactive=False
                    )
            
            # ç¤ºä¾‹
            gr.Markdown("### ğŸ’¡ ç¤ºä¾‹é—®é¢˜")
            gr.Examples(
                examples=examples,
                inputs=query_input
            )
            
            # äº‹ä»¶å¤„ç†
            def process_query(query, top_k_val, enable_rerank_val):
                if not query.strip():
                    return "", "", ""
                
                try:
                    # æ›´æ–°é…ç½®
                    self.config.retriever.rerank_top_k = top_k_val
                    self.config.reranker.enabled = enable_rerank_val
                    
                    # æ‰§è¡Œæ£€ç´¢
                    print(f"\nå¤„ç†æŸ¥è¯¢: {query}")
                    print(f"å‚æ•°: top_k={top_k_val}, reranker={enable_rerank_val}")
                    
                    # æ£€ç´¢æ–‡æ¡£
                    retrieved_documents, retriever_scores = self.retriever.retrieve(
                        text=query,
                        top_k=top_k_val,
                        return_scores=True
                    )
                    
                    # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
                    docs_text = ""
                    for i, (doc, score) in enumerate(zip(retrieved_documents, retriever_scores)):
                        docs_text += f"æ–‡æ¡£ {i+1} (åˆ†æ•°: {score:.4f}):\n"
                        docs_text += f"{doc.content}\n"
                        docs_text += f"å…ƒæ•°æ®: {doc.metadata.doc_id}, {doc.metadata.language}\n"
                        docs_text += "-" * 50 + "\n"
                    
                    # ç”Ÿæˆç­”æ¡ˆ
                    if retrieved_documents:
                        rag_output = self.rag_system.run(query)
                        answer = rag_output.generated_responses[0] if rag_output.generated_responses else "æ— æ³•ç”Ÿæˆç­”æ¡ˆ"
                    else:
                        answer = "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆ"
                    
                    return docs_text, answer, ""
                    
                except Exception as e:
                    error_msg = f"å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                    print(error_msg)
                    return "", "", error_msg
            
            def clear_outputs():
                return "", "", ""
            
            # ç»‘å®šäº‹ä»¶
            submit_btn.click(
                fn=process_query,
                inputs=[query_input, top_k, enable_rerank],
                outputs=[retrieved_docs, generated_answer, info_text]
            )
            
            clear_btn.click(
                fn=clear_outputs,
                outputs=[query_input, retrieved_docs, generated_answer]
            )
            
            query_input.submit(
                fn=process_query,
                inputs=[query_input, top_k, enable_rerank],
                outputs=[retrieved_docs, generated_answer, info_text]
            )
        
        return interface
    
    def launch(self, **kwargs):
        """å¯åŠ¨UI"""
        return self.interface.launch(**kwargs)

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºUIå®ä¾‹
    ui = EnhancedRagUI(
        chinese_data_path="data/alphafin/alphafin_rag_ready_generated_cleaned.json",
        english_data_path="data/tatqa_dataset_raw/tatqa_dataset_train.json",
        cache_dir="M:/huggingface",
        use_faiss=True,
        enable_reranker=True
    )
    
    # å¯åŠ¨UI
    ui.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )

if __name__ == "__main__":
    main() 