# 原始评估脚本使用指南

## 🎯 脚本概述

**脚本名称**: `evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py`  
**用途**: 通用RAG系统评估  
**特点**: 使用真实RAG系统组件，支持中英文混合检索  
**适用**: TAT-QA、AlphaFin等通用数据  
**版本**: v2.0 - 真实RAG组件集成版  

## 📋 核心功能

### 🔍 评估能力
- **真实RAG组件**: 使用FinbertEncoder、BilingualRetriever、QwenReranker
- **双语言支持**: 支持中英文混合检索和评估
- **重排序优化**: 使用QwenReranker提升检索精度
- **MRR评估**: 计算Mean Reciprocal Rank指标
- **多GPU支持**: 支持多GPU并行处理
- **批量处理**: 高效的批量评估机制

### 🏗️ 系统架构

```
原始评估脚本 (真实RAG组件版)
├── 数据加载模块
│   ├── 评估数据加载
│   ├── 检索库构建 (DocumentWithMetadata)
│   └── 数据预处理
├── RAG系统管理器
│   ├── FinbertEncoder (英文)
│   ├── FinbertEncoder (中文)
│   ├── BilingualRetriever
│   ├── QwenReranker
│   └── 设备管理
├── 检索引擎模块
│   ├── 语义检索 (BilingualRetriever)
│   ├── 语言检测和路由
│   └── 文档排序
├── 重排序模块
│   ├── 候选文档重排序 (QwenReranker)
│   ├── 相关性评分
│   └── 最终排序
└── 评估分析模块
    ├── MRR计算
    ├── 性能统计
    └── 结果输出
```

## 🚀 快速开始

### 1. 基础使用 (TAT-QA数据)

```bash
# 使用TAT-QA评估数据
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_data evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_data evaluate_mrr/tatqa_train_qc_enhanced.jsonl \
    --max_samples 100
```

### 2. 完整评估

```bash
# 完整评估所有样本
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_jsonl evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_jsonl evaluate_mrr/tatqa_knowledge_base.jsonl \
    --encoder_model_name "models/finetuned_finbert_tatqa" \
    --reranker_model_name "Qwen/Qwen3-Reranker-0.6B"
```

### 3. 自定义参数

```bash
# 自定义检索和重排序参数
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_jsonl evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_jsonl evaluate_mrr/tatqa_knowledge_base.jsonl \
    --top_k_retrieval 200 \
    --top_k_rerank 20 \
    --batch_size 8 \
    --num_gpus 2
```

## 📊 参数说明

### 🔧 基础参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--eval_jsonl` | str | `evaluate_mrr/tatqa_eval_enhanced.jsonl` | 评估数据文件路径 |
| `--corpus_jsonl` | str | `evaluate_mrr/tatqa_knowledge_base.jsonl` | 检索库数据文件 |
| `--encoder_model_name` | str | `models/finetuned_finbert_tatqa` | 编码器模型名称 |
| `--reranker_model_name` | str | `Qwen/Qwen3-Reranker-0.6B` | 重排序模型名称 |
| `--device` | str | `cuda` | 设备选择 (cuda/cpu) |

### 🎛️ 性能参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--top_k_retrieval` | int | 100 | 检索返回的top-k文档数 |
| `--top_k_rerank` | int | 10 | 重排序的top-k文档数 |
| `--max_eval_samples` | int | None | 最大评估样本数 (None表示全部) |
| `--batch_size` | int | 32 | 批次大小 |
| `--num_gpus` | int | 2 | 使用的GPU数量 |

### 🔍 高级参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--save_results` | flag | False | 是否保存详细结果 |
| `--output_file` | str | `evaluation_results.json` | 结果保存文件名 |
| `--verbose` | flag | False | 是否显示详细日志 |

## 📈 使用场景

### 🧪 快速测试

**目标**: 验证脚本是否正常工作
```bash
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_jsonl evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_jsonl evaluate_mrr/tatqa_knowledge_base.jsonl \
    --max_eval_samples 50 \
    --batch_size 1
```

### 📊 标准评估

**目标**: 标准性能评估
```bash
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_jsonl evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_jsonl evaluate_mrr/tatqa_knowledge_base.jsonl \
    --top_k_retrieval 100 \
    --top_k_rerank 10 \
    --batch_size 4
```

### 🎯 高精度评估

**目标**: 追求最高检索精度
```bash
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_jsonl evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_jsonl evaluate_mrr/tatqa_knowledge_base.jsonl \
    --top_k_retrieval 500 \
    --top_k_rerank 50 \
    --batch_size 2 \
    --save_results
```

## 🔬 实验设计与结果 (使用 100 个数据样本)

### 📊 测试数据
- **数据格式**: 100个经过处理的QCA格式评估样本
- **数据分布**: 三种数据类型均衡分布
  - 表格数据 (Table): ~33个样本
  - 文本数据 (Text): ~33个样本  
  - 混合数据 (Mixed): ~34个样本
- **数据来源**: TatQA enhanced eval数据集
- **样本选择**: 从完整评估集中按数据类型均衡选择100个样本
- **随机种子**: 42（确保结果可重复）

### 🎯 对比实验

#### 英文数据集 (TatQA enhanced eval)

**实验1: Encoder + FAISS 检索**
- **配置**: 仅使用编码器+FAISS向量检索
- **目的**: 建立基线性能
- **评估指标**: MRR, Hit@1, Hit@5, Hit@10
- **运行命令**:
```bash
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_jsonl evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_jsonl evaluate_mrr/tatqa_knowledge_base.jsonl \
    --max_eval_samples 100 \
    --top_k_retrieval 100 \
    --top_k_rerank 0 \
    --batch_size 4
```

**实验2: Encoder + FAISS + Reranker 检索**
- **配置**: 编码器+FAISS + Qwen3-Reranker-0.6B重排序
- **目的**: 评估重排序器的性能提升
- **评估指标**: MRR, Hit@1, Hit@5, Hit@10
- **运行命令**:
```bash
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_jsonl evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_jsonl evaluate_mrr/tatqa_knowledge_base.jsonl \
    --max_eval_samples 100 \
    --top_k_retrieval 100 \
    --top_k_rerank 10 \
    --batch_size 4
```

### 📈 预期结果分析

#### 按数据类型分析
1. **表格数据 (Table)**:
   - 预期MRR提升: 20-30%
   - 预期Hit@1提升: 25-35%
   - 特点: 结构化数据，重排序器效果显著

2. **文本数据 (Text)**:
   - 预期MRR提升: 15-25%
   - 预期Hit@1提升: 20-30%
   - 特点: 自然语言，重排序器效果中等

3. **混合数据 (Mixed)**:
   - 预期MRR提升: 10-20%
   - 预期Hit@1提升: 15-25%
   - 特点: 复杂结构，重排序器效果有限

#### 整体性能提升量化
1. **重排序器效果**: 实验2 vs 实验1
   - 预期整体MRR提升: 15-25%
   - 预期整体Hit@1提升: 20-30%
   - 预期整体Hit@5提升: 10-20%

#### 局限性分析
- Qwen3-Reranker-0.6B在不同数据类型上的表现差异
- 表格数据vs文本数据的重排序效果对比
- 重排序器对检索速度的影响
- 模型大小与性能的平衡

### 🎯 实验目标
- 量化Qwen3-Reranker-0.6B在三种数据类型上的性能提升
- 评估通用重排序模型在金融领域检索中的表现
- 分析重排序器在不同数据类型上的局限性
- 对比表格数据、文本数据和混合数据的检索难度

## 📊 输出结果

### 📋 控制台输出

```
🚀 开始RAG系统评估
📊 配置信息:
  - 评估数据: evaluate_mrr/tatqa_eval_enhanced.jsonl
  - 检索库数据: evaluate_mrr/tatqa_knowledge_base.jsonl
  - 编码器模型: models/finetuned_finbert_tatqa
  - 重排序模型: Qwen/Qwen3-Reranker-0.6B
  - 设备: cuda
  - 检索top-k: 100
  - 重排序top-k: 10
  - 批次大小: 4
  - GPU数量: 2

📈 数据统计:
  - 评估样本数: 100 (随机选择)
  - 检索库大小: 14883
  - 平均查询长度: 45.2 tokens
  - 平均文档长度: 156.7 tokens

🔍 开始评估...
进度: 100%|██████████| 100/100 [00:15<00:00, 6.7it/s]

📊 评估结果:
============================================================
检索性能:
  - MRR @100: 0.2345
  - Hit@1: 0.1800
  - Hit@5: 0.3200
  - Hit@10: 0.4500
  - 平均检索时间: 0.045s
  - 有效查询数: 95/100

重排序性能:
  - MRR @10: 0.3456
  - Hit@1: 0.2800
  - Hit@5: 0.4200
  - Hit@10: 0.5200
  - 平均重排序时间: 0.123s
  - 有效查询数: 95/100

按数据类型分析:
  - 表格数据 (33样本): MRR 0.2856, Hit@1 0.2424
  - 文本数据 (33样本): MRR 0.3245, Hit@1 0.2727
  - 混合数据 (34样本): MRR 0.4267, Hit@1 0.3235

性能提升:
  - 整体MRR提升: +47.4% (0.2345 → 0.3456)
  - 整体Hit@1提升: +55.6% (0.1800 → 0.2800)
  - 表格数据MRR提升: +52.3%
  - 文本数据MRR提升: +45.2%
  - 混合数据MRR提升: +38.9%

总体性能:
  - 总评估时间: 15.2s
  - 平均每查询时间: 0.152s
  - 成功率: 95.0%

🎉 评估完成！
```

### 📄 详细结果文件

如果启用`--save_results`，会生成详细的JSON结果文件：

```json
{
  "config": {
    "eval_data": "evaluate_mrr/tatqa_eval_enhanced.jsonl",
    "corpus_data": "evaluate_mrr/tatqa_knowledge_base.jsonl",
    "encoder_model": "models/finetuned_finbert_tatqa",
    "reranker_model": "Qwen/Qwen3-Reranker-0.6B",
    "top_k_retrieval": 100,
    "top_k_rerank": 10,
    "batch_size": 4,
    "max_samples": 100,
    "random_seed": 42,
    "data_distribution": {
      "table": 33,
      "text": 33,
      "mixed": 34
    }
  },
  "results": {
    "retrieval": {
      "mrr": 0.2345,
      "hit_at_1": 0.1800,
      "hit_at_5": 0.3200,
      "hit_at_10": 0.4500,
      "avg_time": 0.045
    },
    "rerank": {
      "mrr": 0.3456,
      "hit_at_1": 0.2800,
      "hit_at_5": 0.4200,
      "hit_at_10": 0.5200,
      "avg_time": 0.123
    },
    "by_data_type": {
      "table": {
        "retrieval_mrr": 0.1876,
        "rerank_mrr": 0.2856,
        "improvement_percent": 52.3
      },
      "text": {
        "retrieval_mrr": 0.2234,
        "rerank_mrr": 0.3245,
        "improvement_percent": 45.2
      },
      "mixed": {
        "retrieval_mrr": 0.3072,
        "rerank_mrr": 0.4267,
        "improvement_percent": 38.9
      }
    },
    "improvement": {
      "mrr_improvement": 0.1111,
      "mrr_improvement_percent": 47.4,
      "hit_at_1_improvement": 0.1000,
      "hit_at_1_improvement_percent": 55.6
    },
    "total_time": 15.2,
    "success_rate": 0.95,
    "valid_queries": 95
  },
  "detailed_results": [
    {
      "query_id": 0,
      "query": "What is the revenue?",
      "data_type": "table",
      "retrieval_rank": 5,
      "rerank_rank": 2,
      "retrieval_time": 0.042,
      "rerank_time": 0.118
    }
  ]
}
```

## 🔧 故障排除

### 🚨 常见问题

**1. GPU内存不足**
```bash
# 解决方案：减少批次大小或使用CPU
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_jsonl evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_jsonl evaluate_mrr/tatqa_knowledge_base.jsonl \
    --batch_size 1 \
    --num_gpus 1
```

**2. 模型加载失败**
```bash
# 解决方案：检查模型名称和网络连接
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_data evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_data evaluate_mrr/tatqa_train_qc_enhanced.jsonl \
    --encoder_model "bert-base-uncased" \
    --reranker_model "bert-base-uncased"
```

**3. 数据文件格式错误**
```bash
# 解决方案：检查数据文件格式
head -5 evaluate_mrr/tatqa_eval_enhanced.jsonl
head -5 evaluate_mrr/tatqa_train_qc_enhanced.jsonl
```

### 🔍 调试模式

```bash
# 启用详细日志和保存结果
python encoder_finetune_evaluate/evaluate_encoder_reranker_mrr_rag_system_multi_gpu_fixed.py \
    --eval_data evaluate_mrr/tatqa_eval_enhanced.jsonl \
    --corpus_data evaluate_mrr/tatqa_train_qc_enhanced.jsonl \
    --max_samples 10 \
    --batch_size 1 \
    --verbose \
    --save_results
```

## 📚 最佳实践

### 🎯 评估流程建议

1. **数据准备**
   - 确保评估数据和检索库数据格式正确
   - 检查数据质量和完整性

2. **参数调优**
   - 从默认参数开始
   - 根据数据特点调整top_k值
   - 平衡精度和速度

3. **结果分析**
   - 保存详细结果进行分析
   - 对比不同参数配置的效果

### ⚡ 性能优化

1. **批次大小调优**
   - 根据GPU内存调整batch_size
   - 从1开始逐步增加

2. **模型选择**
   - 选择适合数据域的预训练模型
   - 考虑模型大小和性能平衡

3. **检索参数优化**
   - 调整top_k_retrieval和top_k_rerank
   - 根据实际需求优化

### 🔒 数据质量

1. **数据格式检查**
   - 确保JSONL格式正确
   - 检查必要字段完整性

2. **数据泄露检查**
   - 确保评估集和训练集分离
   - 避免数据污染

## 📞 技术支持

如果遇到问题：
1. 检查参数配置和数据文件
2. 查看错误日志和详细输出
3. 尝试简化配置进行调试
4. 联系技术支持

---

**注意**: 建议从最小配置开始测试，确保系统稳定运行后再进行完整评估。 