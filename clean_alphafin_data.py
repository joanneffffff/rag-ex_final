#!/usr/bin/env python3
"""
æ¸…ç†AlphaFinæ•°æ®ï¼Œå»é™¤æ¨¡æ¿åŒ–å†…å®¹
ä¿ç•™åŸå§‹è´¢åŠ¡æ•°æ®ï¼Œå»é™¤"ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ"ç­‰æ¨¡æ¿åŒ–å†…å®¹
"""

import json
import re
from pathlib import Path
from tqdm import tqdm

def clean_alphafin_context(context: str) -> str:
    """
    æ¸…ç†AlphaFinçš„contextï¼Œåªåˆ é™¤ç‰¹å®šçš„æ¨¡æ¿åŒ–è¯æ±‡
    ä¿ç•™å¤§éƒ¨åˆ†åŸå§‹å†…å®¹ï¼Œåªå»é™¤"ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ"ç­‰æ¨¡æ¿åŒ–å‰ç¼€
    
    Args:
        context: åŸå§‹contextå­—ç¬¦ä¸²
        
    Returns:
        æ¸…ç†åçš„contextå­—ç¬¦ä¸²
    """
    if not context or not isinstance(context, str):
        return context
    
    # åªåˆ é™¤ç‰¹å®šçš„æ¨¡æ¿åŒ–å‰ç¼€ï¼Œä¿ç•™æ•°æ®å†…å®¹
    patterns_to_remove = [
        # åˆ é™¤"ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ"å¼€å¤´çš„æ¨¡æ¿åŒ–å†…å®¹
        r"^ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ.*?å¦‚ä¸‹ï¼š\s*",
        r"^ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ.*?æ•°æ®å¦‚ä¸‹ï¼š\s*",
        # åˆ é™¤"ä»¥ä¸‹æ•°æ®æ˜¯...ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ"çš„æ¨¡æ¿åŒ–å‰ç¼€
        r"^ä»¥ä¸‹æ•°æ®æ˜¯.*?æ—¶é—´ä¸º.*?ï¼Œ\s*ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ.*?å¦‚ä¸‹ï¼š\s*",
        r"^ä»¥ä¸‹æ•°æ®æ˜¯.*?æ—¶é—´ä¸º.*?ï¼Œ\s*ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ.*?æ•°æ®å¦‚ä¸‹ï¼š\s*",
        # åˆ é™¤"ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆï¼Œæˆ‘å°†ç»™ä½ æä¾›ä¸€ä»½"çš„æ¨¡æ¿åŒ–å‰ç¼€
        r"^ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ.*?æˆ‘å°†ç»™ä½ æä¾›ä¸€ä»½.*?æ•°æ®ï¼Œå¦‚ä¸‹ï¼š\s*",
        # åˆ é™¤å¤æ‚çš„æ¨¡æ¿åŒ–å‰ç¼€ï¼ˆåŒ…å«é—®é¢˜éƒ¨åˆ†ï¼‰
        r"^ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æå¸ˆ.*?æˆ‘å°†ç»™ä½ æä¾›ä¸€ä»½.*?æ•°æ®è¡¨æ ¼ï¼Œè¿™æ˜¯ä¸€ä»½è‚¡ç¥¨åä¸º.*?ï¼Œè‚¡ç¥¨ä»£ç ä¸º.*?çš„æœ€æ–°æ—¶é—´ä¸º.*?çš„æ•°æ®ï¼Œã€é—®é¢˜ã€‘ï¼š.*?\s*æ•°æ®å¦‚ä¸‹ï¼š\s*",
    ]
    
    cleaned_context = context
    for pattern in patterns_to_remove:
        cleaned_context = re.sub(pattern, "", cleaned_context, flags=re.DOTALL)
    
    # åˆ é™¤ã€é—®é¢˜ã€‘å’Œã€ç­”æ¡ˆã€‘æ ‡è®°ï¼Œä½†ä¿ç•™å†…å®¹
    cleaned_context = re.sub(r"ã€é—®é¢˜ã€‘ï¼š", "", cleaned_context)
    cleaned_context = re.sub(r"ã€ç­”æ¡ˆã€‘ï¼š", "", cleaned_context)
    
    # å»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œï¼Œä½†ä¿ç•™åŸºæœ¬æ ¼å¼
    cleaned_context = re.sub(r'\s+', ' ', cleaned_context).strip()
    
    return cleaned_context

def clean_alphafin_data(input_path: str, output_path: str):
    """
    æ¸…ç†AlphaFinæ•°æ®æ–‡ä»¶
    
    Args:
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    print(f"ğŸ”„ æ¸…ç†AlphaFinæ•°æ®...")
    print(f"ğŸ“– è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_path}")
    
    # è¯»å–åŸå§‹æ•°æ®
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š åŸå§‹æ•°æ®æ ·æœ¬æ•°: {len(data)}")
    
    # æ¸…ç†æ•°æ®
    cleaned_data = []
    removed_count = 0
    
    for item in tqdm(data, desc="æ¸…ç†æ•°æ®"):
        # æ¸…ç†original_context
        original_context = item.get('original_context', '')
        cleaned_context = clean_alphafin_context(original_context)
        
        # å¦‚æœæ¸…ç†åå†…å®¹ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œè·³è¿‡
        if not cleaned_context or len(cleaned_context) < 10:
            removed_count += 1
            continue
        
        # åˆ›å»ºæ¸…ç†åçš„æ•°æ®é¡¹
        cleaned_item = item.copy()
        cleaned_item['original_context'] = cleaned_context
        
        # å¯é€‰ï¼šæ¸…ç†å…¶ä»–å­—æ®µ
        if 'summary' in cleaned_item:
            cleaned_item['summary'] = clean_alphafin_context(cleaned_item['summary'])
        
        cleaned_data.append(cleaned_item)
    
    print(f"âœ… æ¸…ç†å®Œæˆ:")
    print(f"   ğŸ“Š ä¿ç•™æ ·æœ¬æ•°: {len(cleaned_data)}")
    print(f"   ğŸ—‘ï¸ ç§»é™¤æ ·æœ¬æ•°: {removed_count}")
    print(f"   ğŸ“ˆ ä¿ç•™ç‡: {len(cleaned_data)/len(data)*100:.1f}%")
    
    # ä¿å­˜æ¸…ç†åçš„æ•°æ®
    output_path_obj = Path(output_path)
    output_path_obj.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path_obj, 'w', encoding='utf-8') as f:
        json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ¸…ç†åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
    print(f"\nğŸ“‹ æ¸…ç†ç¤ºä¾‹:")
    for i in range(min(3, len(cleaned_data))):
        item = cleaned_data[i]
        print(f"\nç¤ºä¾‹ {i+1}:")
        print(f"  å…¬å¸: {item.get('company_name', 'N/A')}")
        print(f"  è‚¡ç¥¨ä»£ç : {item.get('stock_code', 'N/A')}")
        print(f"  æ¸…ç†å‰é•¿åº¦: {len(item.get('original_context', ''))}")
        print(f"  æ¸…ç†åé•¿åº¦: {len(item['original_context'])}")
        print(f"  æ¸…ç†åå†…å®¹: {item['original_context'][:100]}...")

def main():
    """ä¸»å‡½æ•°"""
    # è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_file = "data/alphafin/alphafin_merged_generated_qa_full_dedup.json"
    output_file = "data/alphafin/alphafin_cleaned.json"
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(input_file).exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    # æ¸…ç†æ•°æ®
    clean_alphafin_data(input_file, output_file)
    
    print(f"\nğŸ‰ æ•°æ®æ¸…ç†å®Œæˆï¼")
    print(f"ğŸ“ å»ºè®®æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„ä¸­æ–‡æ•°æ®è·¯å¾„ä¸º: {output_file}")

if __name__ == "__main__":
    main() 