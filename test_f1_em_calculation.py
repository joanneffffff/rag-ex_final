#!/usr/bin/env python3
"""
æµ‹è¯•F1å’ŒEMè®¡ç®—æ˜¯å¦æ­£ç¡®
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from llm_comparison.chinese_llm_evaluation import (
    calculate_f1_score, 
    calculate_exact_match, 
    normalize_answer_chinese,
    get_tokens_chinese
)
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_f1_em_calculation():
    """æµ‹è¯•F1å’ŒEMè®¡ç®—"""
    
    logger.info("ðŸ§ª å¼€å§‹æµ‹è¯•F1å’ŒEMè®¡ç®—")
    
    # æµ‹è¯•æ¡ˆä¾‹
    test_cases = [
        {
            "name": "å®Œå…¨åŒ¹é…",
            "prediction": "è¯¥å…¬å¸åœ¨2012å¹´ç¬¬å››å­£åº¦çš„è´¢åŠ¡è´¹ç”¨æ˜¯3650812.88å…ƒ",
            "ground_truth": "è¯¥å…¬å¸åœ¨2012å¹´ç¬¬å››å­£åº¦çš„è´¢åŠ¡è´¹ç”¨æ˜¯3650812.88å…ƒ",
            "expected_f1": 1.0,
            "expected_em": 1.0
        },
        {
            "name": "éƒ¨åˆ†åŒ¹é…",
            "prediction": "è¯¥å…¬å¸åœ¨2012å¹´ç¬¬å››å­£åº¦çš„è´¢åŠ¡è´¹ç”¨æ˜¯3650812.88å…ƒ",
            "ground_truth": "è¯¥å…¬å¸åœ¨2012å¹´ç¬¬å››å­£åº¦çš„è´¢åŠ¡è´¹ç”¨æ˜¯3650812.88",
            "expected_f1": 0.9,  # åº”è¯¥å¾ˆé«˜
            "expected_em": 0.0    # ä¸å®Œå…¨åŒ¹é…
        },
        {
            "name": "æ— åŒ¹é…",
            "prediction": "æ ¹æ®çŽ°æœ‰ä¿¡æ¯ï¼Œæ— æ³•æä¾›æ­¤é¡¹ä¿¡æ¯",
            "ground_truth": "è¯¥å…¬å¸åœ¨2012å¹´ç¬¬å››å­£åº¦çš„è´¢åŠ¡è´¹ç”¨æ˜¯3650812.88å…ƒ",
            "expected_f1": 0.0,
            "expected_em": 0.0
        },
        {
            "name": "å®žé™…æ¡ˆä¾‹1",
            "prediction": "æ ¹æ®æä¾›çš„èµ„æ–™ï¼Œå®Œæ•´å…¬å¸è´¢åŠ¡æŠ¥å‘Šç‰‡æ®µä¸­å¹¶æœªåŒ…å«2008å¹´çš„æ•°æ®ï¼Œåªæœ‰2019å¹´è‡³2022Q1çš„ç›¸å…³ä¿¡æ¯ã€‚ å› æ­¤ï¼Œæ— æ³•ä»ŽçŽ°æœ‰ä¿¡æ¯ä¸­èŽ·å–ç‰‡ä»”ç™€å…¬å¸åœ¨2008å¹´ç¬¬ä¸€å­£åº¦çš„å‡€åˆ©æ¶¦ã€‚ ç­”æ¡ˆä¸ºï¼šæ ¹æ®çŽ°æœ‰ä¿¡æ¯ï¼Œæ— æ³•æä¾›æ­¤é¡¹ä¿¡æ¯ã€‚",
            "ground_truth": "è¯¥å…¬å¸åœ¨2008å¹´ç¬¬ä¸€å­£åº¦çš„å‡€åˆ©æ¶¦æ˜¯29694885.63ã€‚",
            "expected_f1": 0.0,  # åº”è¯¥å¾ˆä½Ž
            "expected_em": 0.0
        },
        {
            "name": "å®žé™…æ¡ˆä¾‹2",
            "prediction": "ç€šè“çŽ¯å¢ƒ2020å¹´åº¦è´¢æŠ¥çš„å…³é”®ä¸šç»©æŒ‡æ ‡åŒ…æ‹¬ï¼šå‡€åˆ©æ¶¦åŒæ¯”å¢žé•¿15.9%è‡³10.57äº¿å…ƒï¼› è¥ä¸šæ”¶å…¥è¾¾74.81äº¿å…ƒï¼ŒåŒæ¯”å¢žé•¿21.45%ï¼› ç»è¥æ´»åŠ¨çŽ°é‡‘æµå¢žé•¿47.68%è‡³19.56äº¿å…ƒï¼›ã€‚",
            "ground_truth": "è¿™ä¸ªè‚¡ç¥¨çš„ä¸‹æœˆæœ€ç»ˆæ”¶ç›Šç»“æžœæ˜¯ï¼šè·Œï¼Œä¸‹è·Œæ¦‚çŽ‡ï¼šè¾ƒå¤§",
            "expected_f1": 0.0,  # åº”è¯¥å¾ˆä½Ž
            "expected_em": 0.0
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        logger.info(f"\nðŸ“Š æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['name']}")
        
        # è®¡ç®—F1å’ŒEM
        f1_score = calculate_f1_score(test_case['prediction'], test_case['ground_truth'])
        em_score = calculate_exact_match(test_case['prediction'], test_case['ground_truth'])
        
        # æ˜¾ç¤ºå½’ä¸€åŒ–ç»“æžœ
        normalized_pred = normalize_answer_chinese(test_case['prediction'])
        normalized_truth = normalize_answer_chinese(test_case['ground_truth'])
        
        logger.info(f"   é¢„æµ‹ç­”æ¡ˆ: {test_case['prediction'][:50]}...")
        logger.info(f"   æœŸæœ›ç­”æ¡ˆ: {test_case['ground_truth'][:50]}...")
        logger.info(f"   å½’ä¸€åŒ–é¢„æµ‹: {normalized_pred[:50]}...")
        logger.info(f"   å½’ä¸€åŒ–æœŸæœ›: {normalized_truth[:50]}...")
        logger.info(f"   F1åˆ†æ•°: {f1_score:.4f} (æœŸæœ›: {test_case['expected_f1']:.4f})")
        logger.info(f"   EMåˆ†æ•°: {em_score:.4f} (æœŸæœ›: {test_case['expected_em']:.4f})")
        
        # æ£€æŸ¥åˆ†è¯ç»“æžœ
        pred_tokens = get_tokens_chinese(test_case['prediction'])
        truth_tokens = get_tokens_chinese(test_case['ground_truth'])
        
        logger.info(f"   é¢„æµ‹åˆ†è¯: {pred_tokens[:10]}...")
        logger.info(f"   æœŸæœ›åˆ†è¯: {truth_tokens[:10]}...")
        
        # éªŒè¯ç»“æžœæ˜¯å¦åˆç†
        if f1_score >= 0 and f1_score <= 1:
            logger.info(f"   âœ… F1åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…")
        else:
            logger.error(f"   âŒ F1åˆ†æ•°è¶…å‡ºèŒƒå›´: {f1_score}")
            
        if em_score >= 0 and em_score <= 1:
            logger.info(f"   âœ… EMåˆ†æ•°åœ¨åˆç†èŒƒå›´å†…")
        else:
            logger.error(f"   âŒ EMåˆ†æ•°è¶…å‡ºèŒƒå›´: {em_score}")
    
    logger.info("\nðŸŽ‰ F1å’ŒEMè®¡ç®—æµ‹è¯•å®Œæˆï¼")

def test_normalization():
    """æµ‹è¯•å½’ä¸€åŒ–å‡½æ•°"""
    
    logger.info("\nðŸ§ª æµ‹è¯•å½’ä¸€åŒ–å‡½æ•°")
    
    test_texts = [
        "è¯¥å…¬å¸åœ¨2012å¹´ç¬¬å››å­£åº¦çš„è´¢åŠ¡è´¹ç”¨æ˜¯3,650,812.88ã€‚",
        "è¯¥å…¬å¸åœ¨2012å¹´ç¬¬å››å­£åº¦çš„è´¢åŠ¡è´¹ç”¨æ˜¯3650812.88å…ƒ",
        "æ ¹æ®çŽ°æœ‰ä¿¡æ¯ï¼Œæ— æ³•æä¾›æ­¤é¡¹ä¿¡æ¯ã€‚",
        "ç€šè“çŽ¯å¢ƒ2020å¹´åº¦è´¢æŠ¥çš„å…³é”®ä¸šç»©æŒ‡æ ‡åŒ…æ‹¬ï¼šå‡€åˆ©æ¶¦åŒæ¯”å¢žé•¿15.9%è‡³10.57äº¿å…ƒï¼›"
    ]
    
    for i, text in enumerate(test_texts, 1):
        normalized = normalize_answer_chinese(text)
        tokens = get_tokens_chinese(text)
        
        logger.info(f"   åŽŸæ–‡ {i}: {text}")
        logger.info(f"   å½’ä¸€åŒ–: {normalized}")
        logger.info(f"   åˆ†è¯: {tokens}")
        logger.info("")

if __name__ == "__main__":
    test_f1_em_calculation()
    test_normalization() 