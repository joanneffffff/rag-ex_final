#!/usr/bin/env python3
"""
æµ‹è¯•F1å’ŒEMè®¡ç®—é€»è¾‘
"""

import json
import re
from typing import List

def normalize_answer_chinese(s: str) -> str:
    """
    æ ‡å‡†åŒ–ä¸­æ–‡ç­”æ¡ˆ
    """
    if not s:
        return ""
    
    # ç§»é™¤"è§£æ"åŠå…¶åçš„å†…å®¹
    if "è§£æ" in s:
        s = s.split("è§£æ")[0]
    
    # ç§»é™¤"ã€è§£é‡Šã€‘"åŠå…¶åçš„å†…å®¹
    if "ã€è§£é‡Šã€‘" in s:
        s = s.split("ã€è§£é‡Šã€‘")[0]
    
    # ç§»é™¤"è§£é‡Š"åŠå…¶åçš„å†…å®¹
    if "è§£é‡Š" in s:
        s = s.split("è§£é‡Š")[0]
    
    # æ¸…ç†ç©ºç™½å­—ç¬¦
    s = re.sub(r'\s+', ' ', s.strip())
    
    return s

def get_tokens_chinese(s: str) -> List[str]:
    """
    ä¸­æ–‡åˆ†è¯
    """
    if not s:
        return []
    return list(s)

def calculate_f1_score(prediction: str, ground_truth: str, language: str = "chinese") -> float:
    """
    è®¡ç®—F1åˆ†æ•°
    """
    if language == "chinese":
        pred_tokens = get_tokens_chinese(prediction)
        truth_tokens = get_tokens_chinese(ground_truth)
    else:
        pred_tokens = prediction.lower().split()
        truth_tokens = ground_truth.lower().split()
    
    if not pred_tokens or not truth_tokens:
        return 0.0
    
    # è®¡ç®—äº¤é›†
    common = set(pred_tokens) & set(truth_tokens)
    
    if not common:
        return 0.0
    
    precision = len(common) / len(pred_tokens)
    recall = len(common) / len(truth_tokens)
    
    if precision + recall == 0:
        return 0.0
    
    return 2 * precision * recall / (precision + recall)

def calculate_exact_match(prediction: str, ground_truth: str, language: str = "chinese") -> float:
    """
    è®¡ç®—ç²¾ç¡®åŒ¹é…åˆ†æ•°
    """
    if language == "chinese":
        pred_normalized = normalize_answer_chinese(prediction)
        truth_normalized = normalize_answer_chinese(ground_truth)
    else:
        pred_normalized = prediction.lower().strip()
        truth_normalized = ground_truth.lower().strip()
    
    return 1.0 if pred_normalized == truth_normalized else 0.0

def process_answer(answer: str) -> str:
    """
    ç§»é™¤ç­”æ¡ˆä¸­çš„[Reranker: Enabled]æ–‡æœ¬
    """
    if not answer:
        return answer
    
    # ç§»é™¤[Reranker: Enabled]å‰ç¼€
    answer = re.sub(r'^\[Reranker: Enabled\]\s*', '', answer)
    
    return answer.strip()

def test_sample_calculation():
    """
    æµ‹è¯•å•ä¸ªæ ·æœ¬çš„è®¡ç®—
    """
    print("ğŸ§ª æµ‹è¯•F1å’ŒEMè®¡ç®—é€»è¾‘...")
    
    # ä»åŸå§‹æ•°æ®ä¸­å–ä¸€ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    sample_data = {
        "answer": "[Reranker: Enabled] ä¸­å›½ä¸­å†¶601618.SHåœ¨2017å¹´6æœˆ30æ—¥çš„èµ„äº§è´Ÿå€ºè¡¨æ˜¾ç¤ºå…¶å‡€èµ„äº§ä¸º76,421,499,000.0å…ƒã€‚ æ­¤ä¿¡æ¯ç›´æ¥æ¥æºäºæ‘˜è¦éƒ¨åˆ†çš„ç¬¬ä¸€æ¡è®°å½•ï¼Œå¹¶å¾—åˆ°äº†è¯¦ç»†å†…å®¹çš„æ”¯æŒï¼Œå…¶ä¸­\"è‚¡ä¸œæƒç›Šåˆè®¡\"çš„å…·ä½“æ•°å€¼ä¸º76,421,499,000.0å…ƒï¼Œä¸”\"è´Ÿå€ºåŠè‚¡ä¸œæƒç›Šæ€»è®¡\"ä¸º40,269,525,600.0å…ƒï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å‡€èµ„äº§çš„æ­£ç¡®æ€§ã€‚ æ— é¡»é¢å¤–è®¡ç®—ï¼Œå› ä¸ºå‡€èµ„äº§å·²ç›´æ¥ç»™å‡ºã€‚",
        "expected_answer": "æ ¹æ®èµ„äº§è´Ÿå€ºè¡¨æ•°æ®ï¼Œè¯¥å…¬å¸çš„å‡€èµ„äº§ä¸º76,421,499,000.0å…ƒã€‚"
    }
    
    original_answer = sample_data["answer"]
    expected_answer = sample_data["expected_answer"]
    
    print(f"ğŸ“ åŸå§‹ç­”æ¡ˆ: {original_answer[:100]}...")
    print(f"ğŸ“ æœŸæœ›ç­”æ¡ˆ: {expected_answer}")
    
    # ç§»é™¤[Reranker: Enabled]
    cleaned_answer = process_answer(original_answer)
    print(f"ğŸ§¹ æ¸…ç†åç­”æ¡ˆ: {cleaned_answer[:100]}...")
    
    # è®¡ç®—F1
    f1_score = calculate_f1_score(cleaned_answer, expected_answer, "chinese")
    print(f"ğŸ¯ F1åˆ†æ•°: {f1_score:.4f}")
    
    # è®¡ç®—EM
    em_score = calculate_exact_match(cleaned_answer, expected_answer, "chinese")
    print(f"ğŸ¯ EMåˆ†æ•°: {em_score:.4f}")
    
    # æµ‹è¯•æ ‡å‡†åŒ–
    pred_normalized = normalize_answer_chinese(cleaned_answer)
    truth_normalized = normalize_answer_chinese(expected_answer)
    print(f"ğŸ“Š æ ‡å‡†åŒ–é¢„æµ‹: {pred_normalized[:100]}...")
    print(f"ğŸ“Š æ ‡å‡†åŒ–æœŸæœ›: {truth_normalized}")
    
    return f1_score, em_score

def test_multiple_samples():
    """
    æµ‹è¯•å¤šä¸ªæ ·æœ¬
    """
    print("\nğŸ” æµ‹è¯•å¤šä¸ªæ ·æœ¬...")
    
    # åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡æ–‡ä»¶è¿›è¡Œæµ‹è¯•
    import os
    batch_files = [f for f in os.listdir("raw_data_alphafin_eval_samples_updated") 
                   if f.startswith('batch_') and f.endswith('.json')]
    
    if batch_files:
        test_file = os.path.join("raw_data_alphafin_eval_samples_updated", batch_files[0])
        
        with open(test_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        total_f1 = 0.0
        total_em = 0.0
        sample_count = 0
        
        for sample in data["data"][:5]:  # åªæµ‹è¯•å‰5ä¸ªæ ·æœ¬
            original_answer = sample.get("answer", "")
            expected_answer = sample.get("expected_answer", "")
            
            cleaned_answer = process_answer(original_answer)
            f1_score = calculate_f1_score(cleaned_answer, expected_answer, "chinese")
            em_score = calculate_exact_match(cleaned_answer, expected_answer, "chinese")
            
            print(f"æ ·æœ¬ {sample_count + 1}: F1={f1_score:.4f}, EM={em_score:.4f}")
            
            total_f1 += f1_score
            total_em += em_score
            sample_count += 1
        
        avg_f1 = total_f1 / sample_count if sample_count > 0 else 0.0
        avg_em = total_em / sample_count if sample_count > 0 else 0.0
        
        print(f"\nğŸ“Š å‰5ä¸ªæ ·æœ¬å¹³å‡: F1={avg_f1:.4f}, EM={avg_em:.4f}")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸ”§ å¼€å§‹æµ‹è¯•F1å’ŒEMè®¡ç®—é€»è¾‘...")
    print("=" * 60)
    
    # æµ‹è¯•å•ä¸ªæ ·æœ¬
    f1, em = test_sample_calculation()
    
    # æµ‹è¯•å¤šä¸ªæ ·æœ¬
    test_multiple_samples()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•å®Œæˆ")
    print("ğŸ’¡ å¦‚æœç»“æœä¸åŸå§‹ç»“æœå·®å¼‚å¾ˆå¤§ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´è®¡ç®—é€»è¾‘")

if __name__ == "__main__":
    main() 