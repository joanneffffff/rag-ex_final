#!/usr/bin/env python3
"""
æµ‹è¯•MRRè®¡ç®—æ˜¯å¦æ­£ç¡®
"""

import json
import numpy as np
import torch
from sentence_transformers import SentenceTransformer

def test_mrr_calculation():
    """æµ‹è¯•MRRè®¡ç®—é€»è¾‘"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•MRRè®¡ç®—...")
    
    # åŠ è½½ä¸€äº›è¯„ä¼°æ•°æ®
    eval_data = []
    with open("evaluate_mrr/alphafin_eval.jsonl", 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= 5:  # åªå–å‰5ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
                break
            item = json.loads(line)
            eval_data.append({
                'query': item.get('generated_question', ''),
                'context': item.get('summary', ''),
                'doc_id': item.get('doc_id', '')
            })
    
    print(f"ğŸ“Š åŠ è½½äº† {len(eval_data)} ä¸ªæµ‹è¯•æ ·æœ¬")
    
    # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬çš„ä¿¡æ¯
    for i, item in enumerate(eval_data[:3]):
        print(f"\næ ·æœ¬ {i+1}:")
        print(f"  doc_id: {item['doc_id']}")
        print(f"  query: {item['query'][:100]}...")
        print(f"  context: {item['context'][:100]}...")
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ¤– åŠ è½½æ¨¡å‹...")
    model = SentenceTransformer("Langboat/mengzi-bert-base-fin")
    
    # ç¼–ç æ‰€æœ‰ä¸Šä¸‹æ–‡
    contexts = [item['context'] for item in eval_data]
    print(f"ç¼–ç  {len(contexts)} ä¸ªä¸Šä¸‹æ–‡...")
    context_embeddings = model.encode(contexts, convert_to_tensor=True)
    
    # æµ‹è¯•æ¯ä¸ªæŸ¥è¯¢
    mrrs = []
    for i, item in enumerate(eval_data):
        print(f"\n--- æµ‹è¯•æŸ¥è¯¢ {i+1} ---")
        print(f"doc_id: {item['doc_id']}")
        print(f"query: {item['query'][:80]}...")
        
        # ç¼–ç æŸ¥è¯¢
        query_emb = model.encode(item['query'], convert_to_tensor=True)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        scores = torch.cosine_similarity(query_emb.unsqueeze(0), context_embeddings)[0].cpu().numpy()
        
        # æ‰¾åˆ°ç›®æ ‡ä¸Šä¸‹æ–‡çš„ç´¢å¼•ï¼ˆåº”è¯¥æ˜¯iï¼Œå› ä¸ºæ•°æ®æ˜¯æŒ‰é¡ºåºæ’åˆ—çš„ï¼‰
        target_context_idx = i
        
        # æ’åº
        sorted_indices = np.argsort(scores)[::-1]
        print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {scores}")
        print(f"æ’åºåçš„ç´¢å¼•: {sorted_indices}")
        print(f"ç›®æ ‡ç´¢å¼•: {target_context_idx}")
        
        # æ‰¾åˆ°æ’å
        rank = -1
        for r, idx in enumerate(sorted_indices):
            if idx == target_context_idx:
                rank = r + 1
                break
        
        print(f"ç›®æ ‡æ’å: {rank}")
        
        if rank != -1:
            mrr_score = 1.0 / rank
            mrrs.append(mrr_score)
            print(f"MRRåˆ†æ•°: {mrr_score:.4f}")
        else:
            mrrs.append(0.0)
            print(f"MRRåˆ†æ•°: 0.0000 (æœªæ‰¾åˆ°)")
    
    # è®¡ç®—å¹³å‡MRR
    avg_mrr = float(np.mean(mrrs)) if mrrs else 0.0
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"  å„æ ·æœ¬MRR: {[f'{mrr:.4f}' for mrr in mrrs]}")
    print(f"  å¹³å‡MRR: {avg_mrr:.4f}")
    
    # åˆ†æç»“æœ
    if avg_mrr > 0.5:
        print("âœ… MRRè®¡ç®—æ­£ç¡®ï¼Œæ¨¡å‹èƒ½å¤Ÿæ­£ç¡®åŒ¹é…æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡")
    elif avg_mrr > 0.1:
        print("âš ï¸  MRRè¾ƒä½ï¼Œä½†è®¡ç®—é€»è¾‘æ­£ç¡®ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒ")
    else:
        print("âŒ MRRæä½ï¼Œå¯èƒ½å­˜åœ¨ä»¥ä¸‹é—®é¢˜:")
        print("   1. å­—æ®µæ˜ å°„é”™è¯¯")
        print("   2. æ•°æ®è´¨é‡é—®é¢˜")
        print("   3. æ¨¡å‹éœ€è¦æ›´å¤šè®­ç»ƒ")
    
    return avg_mrr

if __name__ == "__main__":
    test_mrr_calculation() 