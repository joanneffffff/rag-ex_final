import json
import random
from pathlib import Path

def split_alphafin_json(
    input_json,
    train_jsonl,
    eval_jsonl,
    train_ratio=0.8,
    seed=42
):
    """åˆ†å‰²AlphaFinæ•°æ®ä¸ºè®­ç»ƒé›†å’Œè¯„ä¼°é›†"""
    print(f"ğŸ“– åŠ è½½åŸå§‹æ•°æ®: {input_json}")
    
    with open(input_json, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    print(f"âœ… åŠ è½½äº† {len(data)} ä¸ªæ ·æœ¬")
    
    # éšæœºæ‰“ä¹±æ•°æ®
    random.seed(seed)
    random.shuffle(data)
    
    # è®¡ç®—åˆ†å‰²ç‚¹
    n_train = int(len(data) * train_ratio)
    train_data = data[:n_train]
    eval_data = data[n_train:]
    
    print(f"ğŸ“Š åˆ†å‰²ç»“æœ:")
    print(f"  - è®­ç»ƒé›†: {len(train_data)} ä¸ªæ ·æœ¬ ({train_ratio*100:.0f}%)")
    print(f"  - è¯„ä¼°é›†: {len(eval_data)} ä¸ªæ ·æœ¬ ({(1-train_ratio)*100:.0f}%)")
    
    # ä¿å­˜è®­ç»ƒé›†ï¼ˆä¿ç•™generated_questionã€summaryå’Œdoc_idï¼‰
    print(f"ğŸ’¾ ä¿å­˜è®­ç»ƒé›†: {train_jsonl}")
    with open(train_jsonl, "w", encoding="utf-8") as f:
        for item in train_data:
            train_item = {
                "generated_question": item.get("generated_question", item.get("question", "")),
                "summary": item.get("summary", ""),
                "doc_id": item.get("doc_id", "")
            }
            f.write(json.dumps(train_item, ensure_ascii=False) + "\n")
    
    # ä¿å­˜è¯„ä¼°é›†ï¼ˆä¿ç•™å®Œæ•´Q-C-Aï¼‰
    print(f"ğŸ’¾ ä¿å­˜è¯„ä¼°é›†: {eval_jsonl}")
    with open(eval_jsonl, "w", encoding="utf-8") as f:
        for item in eval_data:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
    
    print(f"âœ… åˆ†å‰²å®Œæˆï¼")
    print(f"  - è®­ç»ƒé›†: {train_jsonl} ({len(train_data)}æ¡)")
    print(f"  - è¯„ä¼°é›†: {eval_jsonl} ({len(eval_data)}æ¡)")

def analyze_data_distribution(train_jsonl, eval_jsonl):
    """åˆ†æè®­ç»ƒé›†å’Œè¯„ä¼°é›†çš„æ•°æ®åˆ†å¸ƒ"""
    print(f"\nğŸ“Š æ•°æ®åˆ†å¸ƒåˆ†æ:")
    
    # åˆ†æè®­ç»ƒé›†
    train_samples = []
    with open(train_jsonl, "r", encoding="utf-8") as f:
        for line in f:
            train_samples.append(json.loads(line))
    
    # åˆ†æè¯„ä¼°é›†
    eval_samples = []
    with open(eval_jsonl, "r", encoding="utf-8") as f:
        for line in f:
            eval_samples.append(json.loads(line))
    
    print(f"è®­ç»ƒé›†ç»Ÿè®¡:")
    print(f"  - æ ·æœ¬æ•°: {len(train_samples)}")
    print(f"  - å¹³å‡é—®é¢˜é•¿åº¦: {sum(len(s['generated_question']) for s in train_samples)/len(train_samples):.1f} å­—ç¬¦")
    print(f"  - å¹³å‡æ‘˜è¦é•¿åº¦: {sum(len(s['summary']) for s in train_samples)/len(train_samples):.1f} å­—ç¬¦")
    
    print(f"è¯„ä¼°é›†ç»Ÿè®¡:")
    print(f"  - æ ·æœ¬æ•°: {len(eval_samples)}")
    print(f"  - å¹³å‡é—®é¢˜é•¿åº¦: {sum(len(s['question']) for s in eval_samples)/len(eval_samples):.1f} å­—ç¬¦")
    print(f"  - å¹³å‡ä¸Šä¸‹æ–‡é•¿åº¦: {sum(len(s['context']) for s in eval_samples)/len(eval_samples):.1f} å­—ç¬¦")
    print(f"  - å¹³å‡ç­”æ¡ˆé•¿åº¦: {sum(len(s['answer']) for s in eval_samples)/len(eval_samples):.1f} å­—ç¬¦")

if __name__ == "__main__":
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path("evaluate_mrr").mkdir(exist_ok=True)
    
    # åˆ†å‰²AlphaFinæ•°æ®
    split_alphafin_json(
        input_json="data/alphafin/alphafin_final_clean.json",      # AlphaFinçš„æ¸…ç†åæ•°æ®
        train_jsonl="evaluate_mrr/alphafin_train_qc.jsonl",     # è¾“å‡ºAlphaFinè®­ç»ƒé›†Q-C
        eval_jsonl="evaluate_mrr/alphafin_eval.jsonl",           # è¾“å‡ºAlphaFinè¯„ä¼°é›†Q-C-A
        train_ratio=0.9,  # æ”¹ä¸º9/1åˆ†å‰²
        seed=42
    )
    
    # åˆ†ææ•°æ®åˆ†å¸ƒ
    analyze_data_distribution(
        "evaluate_mrr/alphafin_train_qc.jsonl",
        "evaluate_mrr/alphafin_eval.jsonl"
    ) 