# -*- coding: utf-8 -*-
"""alphafin_data_clean

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ICvdPqMJ81vpAkyGtQyOwVbxCLF5ik25
"""

from google.colab import drive
drive.mount('/content/drive')

# prompt: 把rag-ex作为当前目录

import os
os.chdir('/content/drive/MyDrive/rag-ex')

import json
import re
from pathlib import Path
from tqdm import tqdm # 用于显示处理进度

# --- 辅助函数：确保目录存在 ---
def ensure_directory_exists(file_path):
    """确保给定文件路径的父目录存在"""
    Path(file_path).parent.mkdir(parents=True, exist_ok=True)

# --- 清洗规则字典 (直接嵌入 Python 代码) ---
CLEANING_RULES_DICT = {
  "financial_keywords": [
    "金融", "银行", "央行", "证券", "股票", "股市", "交易所", "期货", "期权", "基金", "债券",
    "投资", "融资", "贷款", "存款", "利率", "汇率", "货币", "经济", "通胀", "通缩", "GDP",
    "CPI", "PPI", "财政", "税收", "预算", "赤字", "债务", "财报", "盈利", "亏损", "营收",
    "成本", "利润", "收入", "支出", "资产", "负债", "权益", "市值", "估值", "交易", "市场",
    "分析师", "评级", "研究报告", "监管", "合规", "风控", "并购", "重组", "IPO", "退市",
    "股息", "分红", "配股", "增发", "回购", "做多", "做空", "牛市", "熊市", "震荡", "波动",
    "指数", "板块", "概念股", "蓝筹股", "成长股", "价值股", "小盘股", "大盘股", "创业板",
    "科创板", "主板", "新三板", "开盘", "收盘", "涨停", "跌停", "交易量", "成交额", "换手率",
    "K线图", "均线", "技术指标", "基本面", "宏观经济", "行业分析", "公司研究", "风险管理",
    "资产配置", "投资组合", "对冲", "套利", "杠杆", "保证金", "爆仓", "流动性", "信用风险",
    "市场风险", "操作风险", "政策风险", "流动性风险", "系统性风险", "非系统性风险", "金融危机",
    "货币政策", "财政政策", "产业政策", "贸易政策", "国际贸易", "进出口", "外汇储备", "国际收支",
    "资本流动", "直接投资", "证券投资", "衍生品", "金融创新", "金融科技", "数字货币", "区块链",
    "P2P", "众筹", "互联网金融", "普惠金融", "绿色金融", "可持续金融", "社会责任投资", "ESG",
    "央行", "银保监会", "证监会", "外管局", "金融机构", "商业银行", "投资银行", "证券公司",
    "基金公司", "保险公司", "信托公司", "资产管理公司", "评级机构", "交易所", "清算所",
    "楼市", "房价", "房地产", "房贷", "公积金", "土地", "开发商", "物业"
  ],
  "negative_keywords": [
    "电影", "影片", "体育", "游戏", "音乐", "艺术", "食谱", "烹饪",
    "旅行", "度假", "天气", "时尚", "名人", "八卦",
    "健康小贴士", "锻炼", "政治", "选举", "犯罪", "小说",
    "故事", "诗歌", "历史", "地理", "科学项目",
    "教育", "学生", "老师", "学校", "大学", "娱乐", "新闻",
    "游乐场", "儿童", "小孩", "受伤", "事故", "报警", "医院", "治疗",
    "乐吧车", "安全带", "法律责任", "律师", "监护人", "消费者权益", "消费者",
    "摔伤", "坠落", "新闻报道", "记者", "受害者", "伤势", "投诉", "维权", "曝光",
    "娱乐中心", "公园", "摩天轮", "游乐设施"
  ],
  "patterns_to_exclude": [
    "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+",
    "\\b(足球|篮球|棒球|网球|排球)\\b",
    "\\b(导演|演员|制片人)\\b",
    "\\b(菜谱|配料|厨具)\\b",
    "\\b(章节|页|段落)\\b",
    "\\b(习近平|特朗普|拜登|普京|默克尔|马克龙)\\b",
    "\\b(海都网|福州新闻|新华社|中新社|人民日报|每日经济新闻|证券时报|XX日报|XX晚报|XX新闻网)\\b",
    "\\b(记者|报道|通讯员|特约评论员)\\b",
    "\\b(原标题|来源|责任编辑)\\b"
  ],
  "min_length_chars": 100,
  "min_financial_keyword_count": 5
}

# --- 加载清洗规则 (直接从字典加载) ---
def load_cleaning_rules():
    """直接从 CLEANING_RULES_DICT 加载清洗规则并编译正则表达式"""
    rules = CLEANING_RULES_DICT.copy() # 使用副本，避免修改原始字典

    # 编译正则表达式，忽略大小写
    compiled_patterns = []
    if "patterns_to_exclude" in rules:
        for pattern_str in rules["patterns_to_exclude"]:
            compiled_patterns.append(re.compile(pattern_str, re.IGNORECASE))
    rules["compiled_patterns"] = compiled_patterns
    return rules

# --- 检查文本是否包含任何金融相关关键词 ---
def contains_financial_keywords(text, keywords):
    """
    检查文本是否包含任何金融相关关键词 (大小写不敏感)。
    text: 待检查文本 (str)
    keywords: 金融关键词列表 (list of str)
    """
    if not isinstance(text, str) or not text.strip():
        return False
    text_lower = text.lower() # 将文本转换为小写以进行不区分大小写的匹配
    for keyword in keywords:
        if keyword.lower() in text_lower: # 将关键词也转换为小写
            return True
    return False

# --- 数据清洗主函数 ---
def clean_json_data(input_json_path: str, output_json_path: str):
    """
    加载 JSON 数据，根据清洗规则进行过滤，并将结果保存到新的 JSON 文件。
    input_json_path: 原始 JSON 文件路径
    output_json_path: 清洗后 JSON 文件保存路径
    """
    ensure_directory_exists(output_json_path) # 确保输出目录存在

    try:
        # 加载清洗规则 (直接从内联字典加载)
        rules = load_cleaning_rules()
        financial_keywords = [k.lower() for k in rules.get("financial_keywords", [])]
        negative_keywords = [k.lower() for k in rules.get("negative_keywords", [])]
        compiled_patterns = rules.get("compiled_patterns", [])
        min_length_chars = rules.get("min_length_chars", 100)
        min_financial_keyword_count = rules.get("min_financial_keyword_count", 5)

        print(f"加载原始数据: {input_json_path}")
        with open(input_json_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)

        print(f"原始记录数量: {len(raw_data)}")

        filtered_data = []
        # 使用 tqdm 显示处理进度
        for record in tqdm(raw_data, desc="清洗数据"):
            # 假设每条记录的文本内容在 'input' 字段中
            # 如果你的JSON结构不同，请根据实际情况修改 'input' 键
            content = record.get('input', '') # 获取文本内容，如果不存在则为空字符串

            if not isinstance(content, str) or not content.strip():
                continue # 跳过非字符串或空内容

            content_lower = content.lower()

            # 1. 检查文档长度
            if len(content) < min_length_chars:
                continue

            # 2. 检查是否包含负面关键词或匹配排除模式 (高优先级过滤)
            if any(neg_kw in content_lower for neg_kw in negative_keywords):
                continue
            if any(pattern.search(content) for pattern in compiled_patterns):
                continue

            # 3. 检查是否包含足够的金融关键词
            financial_keyword_hits = sum(1 for kw in financial_keywords if kw in content_lower)
            if financial_keyword_hits < min_financial_keyword_count:
                continue

            # 如果通过所有规则，则保留记录
            filtered_data.append(record)

        print(f"清洗后记录数量: {len(filtered_data)}")

        # 保存过滤后的数据
        print(f"保存清洗后的数据到: {output_json_path}")
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(filtered_data, f, ensure_ascii=False, indent=4)

        print("\n清洗完成。前5条过滤后的记录示例:")
        for i in range(min(5, len(filtered_data))):
            record_summary = {k: filtered_data[i][k] for k in filtered_data[i] if k in ['input', 'output']}
            print(record_summary)

    except FileNotFoundError as e:
        print(f"错误: {e}")
    except json.JSONDecodeError:
        print(f"错误: 无法解析 JSON 文件 {input_json_path}。请检查文件内容是否为有效的 JSON 格式。")
    except Exception as e:
        print(f"发生未知错误: {e}")
        import traceback
        traceback.print_exc() # 打印详细错误信息

# --- 主执行部分 ---
if __name__ == "__main__":
    # 配置输入和输出文件路径
    # 请根据你的实际文件位置修改这些路径
    input_file = '/content/drive/MyDrive/rag-ex/data/alphafin/data.json'
    output_file = '/content/drive/MyDrive/rag-ex/data/alphafin/cleaned_financial_data.json'

    clean_json_data(input_file, output_file)