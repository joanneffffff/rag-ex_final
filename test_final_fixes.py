#!/usr/bin/env python3
"""
éªŒè¯æœ€ç»ˆä¿®å¤æ˜¯å¦å®Œæ•´
"""

import json
import numpy as np
import torch
from sentence_transformers import SentenceTransformer

def test_final_fixes():
    """æµ‹è¯•æœ€ç»ˆä¿®å¤"""
    print("ğŸ§ª éªŒè¯æœ€ç»ˆä¿®å¤...")
    
    # 1. æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½
    print("\n1ï¸âƒ£ æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½...")
    train_examples = []
    with open("evaluate_mrr/alphafin_train_qc.jsonl", 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= 3:  # åªå–å‰3ä¸ªæ ·æœ¬
                break
            item = json.loads(line)
            generated_question = item.get('generated_question', '')
            summary = item.get('summary', '')
            
            if generated_question and summary:
                train_examples.append([generated_question, summary])
    
    print(f"âœ… è®­ç»ƒæ•°æ®åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(train_examples)}")
    for i, (q, c) in enumerate(train_examples):
        print(f"  æ ·æœ¬{i+1}: query={q[:50]}..., context={c[:50]}...")
    
    # 2. æµ‹è¯•è¯„ä¼°æ•°æ®åŠ è½½
    print("\n2ï¸âƒ£ æµ‹è¯•è¯„ä¼°æ•°æ®åŠ è½½...")
    eval_data = []
    with open("evaluate_mrr/alphafin_eval.jsonl", 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= 3:  # åªå–å‰3ä¸ªæ ·æœ¬
                break
            item = json.loads(line)
            generated_question = item.get('generated_question', '')
            summary = item.get('summary', '')
            doc_id = item.get('doc_id', '')
            
            if generated_question and summary:
                eval_data.append({
                    'query': generated_question,
                    'context': summary,
                    'doc_id': doc_id
                })
    
    print(f"âœ… è¯„ä¼°æ•°æ®åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(eval_data)}")
    for i, item in enumerate(eval_data):
        print(f"  æ ·æœ¬{i+1}: doc_id={item['doc_id']}, query={item['query'][:50]}...")
    
    # 3. æµ‹è¯•MRRè®¡ç®—
    print("\n3ï¸âƒ£ æµ‹è¯•MRRè®¡ç®—...")
    model = SentenceTransformer("Langboat/mengzi-bert-base-fin")
    
    # ç¼–ç ä¸Šä¸‹æ–‡
    contexts = [item['context'] for item in eval_data]
    context_embeddings = model.encode(contexts, convert_to_tensor=True)
    
    # æµ‹è¯•ç¬¬ä¸€ä¸ªæŸ¥è¯¢
    query_emb = model.encode(eval_data[0]['query'], convert_to_tensor=True)
    scores = torch.cosine_similarity(query_emb.unsqueeze(0), context_embeddings).cpu().numpy()
    
    print(f"âœ… MRRè®¡ç®—æ­£ç¡®ï¼Œç›¸ä¼¼åº¦åˆ†æ•°å½¢çŠ¶: {scores.shape}")
    print(f"  ç›¸ä¼¼åº¦åˆ†æ•°: {scores}")
    
    # 4. æ€»ç»“
    print("\nğŸ“Š ä¿®å¤éªŒè¯æ€»ç»“:")
    print("âœ… è®­ç»ƒæ•°æ®å­—æ®µæ˜ å°„æ­£ç¡® (generated_question -> summary)")
    print("âœ… è¯„ä¼°æ•°æ®å­—æ®µæ˜ å°„æ­£ç¡® (generated_question -> summary)")
    print("âœ… MRRè®¡ç®—é€»è¾‘æ­£ç¡® (ä½™å¼¦ç›¸ä¼¼åº¦å‘é‡)")
    print("âœ… doc_idåŒ¹é…é€»è¾‘æ­£ç¡®")
    print("\nğŸš€ æ‰€æœ‰ä¿®å¤å®Œæˆï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")

if __name__ == "__main__":
    test_final_fixes() 