#!/usr/bin/env python3
"""
åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶å¹¶è®¡ç®—æ•´ä½“çš„F1å’ŒEMåˆ†æ•°
ä½¿ç”¨ä¸­æ–‡LLMè¯„ä¼°æ–‡ä»¶ä¸­çš„è®¡ç®—é€»è¾‘
"""

import json
import os
import re
import jieba
from pathlib import Path
from typing import Dict, List, Any
from collections import Counter

NOT_FOUND_REPLY_ENGLISH = "I cannot find the answer in the provided context."

def normalize_answer_chinese(s: str) -> str:
    """
    é’ˆå¯¹ä¸­æ–‡è¿›è¡Œç­”æ¡ˆå½’ä¸€åŒ–ï¼šç§»é™¤æ ‡ç‚¹ã€è½¬æ¢å…¨è§’å­—ç¬¦ä¸ºåŠè§’ã€å»é™¤å¤šä½™ç©ºæ ¼ã€åˆ†è¯å¹¶å°å†™ã€‚
    ä¸llm_comparison/chinese_llm_evaluation.pyä¿æŒå®Œå…¨ä¸€è‡´ã€‚
    """
    if not s:
        return ""

    s = s.strip().lower()
    s = s.replace('ï¼Œ', ',').replace('ã€‚', '.').replace('ï¼', '!').replace('ï¼Ÿ', '?').replace('ï¼›', ';')
    s = s.replace('ï¼ˆ', '(').replace('ï¼‰', ')')

    punctuation_pattern = r'[!"#$%&\'()*+,-./:;<=>?@[\]^_`{|}~â€œâ€â€˜â€™ã€ã€‘ã€ã€ã€Šã€‹â€”â€¦Â·ï½ã€Œã€ï½ï¿¥%#@ï¼&ï¼ˆï¼‰ã€Šã€‹]'
    s = re.sub(punctuation_pattern, '', s)

    import jieba
    tokens = list(jieba.cut(s))
    normalized_tokens = [token for token in tokens if token.strip()]
    return " ".join(normalized_tokens)

def get_tokens_chinese(s: str) -> List[str]:
    """ä½¿ç”¨jiebaåˆ†è¯è·å–ä¸­æ–‡tokenåˆ—è¡¨"""
    return list(jieba.cut(s))

def _shared_text_standardizer_english(text: str) -> str:
    """
    Helper function to standardize English text for both answer extraction and F1 score calculation.
    Strictly follows the rules from the English Prompt Template.
    """
    text = text.strip()
    
    # Lowercase all text
    text = text.lower()

    # é€’å½’æ›¿æ¢æ‰€æœ‰ \text{...} ä¸º ...ï¼ˆä¿ç•™å†…å®¹ï¼‰
    while True:
        new_text = re.sub(r'\\text\{([^}]*)\}', r'\1', text, flags=re.DOTALL)
        if new_text == text:
            break
        text = new_text
    # å…¶ä½™ LaTeX æ ¼å¼ç›´æ¥å»æ‰
    text = re.sub(r'\\[a-zA-Z]+\{[^}]*\}', '', text)
    text = re.sub(r'\\[a-zA-Z]+', '', text)
    
    # Remove currency symbols and common unit words based on prompt rule
    text = re.sub(r'\b(million|billion|thousand|trillion|usd|eur|gbp|m|b)\b', '', text, flags=re.IGNORECASE).strip()
    text = re.sub(r'[\$Â£â‚¬]', '', text).strip()

    # Remove commas from numbers
    text = text.replace(',', '')

    # Handle negative numbers in parentheses (e.g., "(33)" -> "-33")
    if text.startswith('(') and text.endswith(')'):
        text = '-' + text[1:-1]
    
    # Normalize percentages
    text = text.replace(' percent', '%').replace('pct', '%')
    text = re.sub(r'(\d+\.?\d*)\s*%', r'\1%', text)
    
    # Remove common introductory phrases
    text = re.sub(r'^(the\s*answer\s*is|it\s*was|the\s*value\s*is|resulting\s*in|this\s*represents|the\s*effect\s*is|therefore|so|thus|in\s*conclusion|final\s*answer\s*is|final\s*number\s*is)\s*', '', text, flags=re.IGNORECASE).strip()
    
    # Remove trailing punctuation
    if text.endswith('%'):
        text = re.sub(r'[\.,;]$', '', text).strip()
    else:
        text = re.sub(r'[\.,;%]$', '', text).strip() 
    
    # Final cleanup of whitespace
    text = ' '.join(text.split()).strip()

    return text

def calculate_f1_score_chinese(prediction: str, ground_truth: str) -> float:
    """è®¡ç®—F1-scoreï¼Œæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡"""
    pred_tokens = set(get_tokens_chinese(normalize_answer_chinese(prediction)))
    gt_tokens = set(get_tokens_chinese(normalize_answer_chinese(ground_truth)))
    
    if not gt_tokens:
        return 1.0 if not pred_tokens else 0.0
    
    intersection = pred_tokens & gt_tokens
    precision = len(intersection) / len(pred_tokens) if pred_tokens else 0.0
    recall = len(intersection) / len(gt_tokens)
    
    if precision + recall == 0:
        return 0.0
    
    return 2 * precision * recall / (precision + recall)

def calculate_exact_match_chinese(prediction: str, ground_truth: str) -> float:
    """è®¡ç®—Exact Matchï¼Œæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡"""
    pred_normalized = normalize_answer_chinese(prediction)
    gt_normalized = normalize_answer_chinese(ground_truth)
    
    return 1.0 if pred_normalized == gt_normalized else 0.0

def calculate_f1_score_english(prediction: str, ground_truth: str) -> float:
    """Calculates F1-score based on token overlap for English."""
    
    normalized_prediction = _shared_text_standardizer_english(prediction).lower()
    normalized_ground_truth = _shared_text_standardizer_english(ground_truth).lower()

    # Handle cases where the model explicitly states "I cannot find the answer..."
    if normalized_prediction == NOT_FOUND_REPLY_ENGLISH.lower():
        return 1.0 if normalized_ground_truth == NOT_FOUND_REPLY_ENGLISH.lower() else 0.0
    
    # Handle cases where the ground truth is "I cannot find the answer...", but the model gave a factual answer (which is an error)
    if normalized_ground_truth == NOT_FOUND_REPLY_ENGLISH.lower():
        return 0.0

    prediction_tokens = normalized_prediction.split()
    ground_truth_tokens = normalized_ground_truth.split()

    if not ground_truth_tokens: 
        return 1.0 if not prediction_tokens else 0.0
    if not prediction_tokens: 
        return 0.0

    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)
    num_same = sum(common.values())
    if num_same == 0: 
        return 0.0

    precision = 1.0 * num_same / len(prediction_tokens)
    recall = 1.0 * num_same / len(ground_truth_tokens)
    f1 = (2 * precision * recall) / (precision + recall)
    return f1

def calculate_exact_match_english(prediction: str, ground_truth: str) -> float:
    """Calculates Exact Match score for English."""
    return 1.0 if _shared_text_standardizer_english(prediction).lower() == _shared_text_standardizer_english(ground_truth).lower() else 0.0

def calculate_f1_score(prediction: str, ground_truth: str, language: str = "chinese") -> float:
    """ç»Ÿä¸€çš„F1åˆ†æ•°è®¡ç®—å‡½æ•°ï¼Œæ ¹æ®è¯­è¨€é€‰æ‹©ä¸åŒçš„è®¡ç®—æ–¹æ³•"""
    if language == "chinese":
        return calculate_f1_score_chinese(prediction, ground_truth)
    else:
        return calculate_f1_score_english(prediction, ground_truth)

def calculate_exact_match(prediction: str, ground_truth: str, language: str = "chinese") -> float:
    """ç»Ÿä¸€çš„ç²¾ç¡®åŒ¹é…è®¡ç®—å‡½æ•°ï¼Œæ ¹æ®è¯­è¨€é€‰æ‹©ä¸åŒçš„è®¡ç®—æ–¹æ³•"""
    if language == "chinese":
        return calculate_exact_match_chinese(prediction, ground_truth)
    else:
        return calculate_exact_match_english(prediction, ground_truth)

def process_answer(answer: str) -> str:
    """
    ç§»é™¤ç­”æ¡ˆä¸­çš„[Reranker: Enabled]å‰ç¼€ã€"è§£æ"åŠå…¶åé¢çš„å†…å®¹ï¼Œä»¥åŠ"ã€è§£é‡Šã€‘"åŠå…¶åé¢çš„å†…å®¹
    """
    if not answer:
        return answer
    
    # ç§»é™¤[Reranker: Enabled]å‰ç¼€
    answer = re.sub(r'^\[Reranker: Enabled\]\s*', '', answer)
    
    # ç§»é™¤"è§£æ"åŠå…¶åé¢çš„æ‰€æœ‰å†…å®¹
    parse_index = answer.find("è§£æ")
    if parse_index != -1:
        answer = answer[:parse_index]
    
    # ç§»é™¤"ã€è§£é‡Šã€‘"åŠå…¶åé¢çš„æ‰€æœ‰å†…å®¹
    explanation_index = answer.find("ã€è§£é‡Šã€‘")
    if explanation_index != -1:
        answer = answer[:explanation_index]
    
    return answer.strip()

def detect_language(text: str) -> str:
    """
    æ£€æµ‹æ–‡æœ¬è¯­è¨€ï¼Œç®€å•çš„ä¸­è‹±æ–‡æ£€æµ‹
    """
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
    chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
    total_chars = len([char for char in text if char.isalpha() or '\u4e00' <= char <= '\u9fff'])
    
    if total_chars > 0 and chinese_chars / total_chars > 0.3:  # å¦‚æœè¶…è¿‡30%æ˜¯ä¸­æ–‡å­—ç¬¦ï¼Œè®¤ä¸ºæ˜¯ä¸­æ–‡
        return "chinese"
    else:
        return "english"

def load_and_process_batch(file_path: str) -> List[Dict[str, Any]]:
    """
    åŠ è½½å¹¶å¤„ç†å•ä¸ªæ‰¹æ¬¡æ–‡ä»¶
    """
    print(f"ğŸ“ åŠ è½½æ–‡ä»¶: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    processed_samples = []
    
    for sample in data["data"]:
        original_answer = sample.get("answer", "")
        expected_answer = sample.get("expected_answer", "")
        
        # æ£€æµ‹è¯­è¨€
        language = sample.get("language", "chinese")  # é»˜è®¤ä½¿ç”¨ä¸­æ–‡
        if language == "auto":
            # å¦‚æœè¯­è¨€æ˜¯autoï¼Œåˆ™è‡ªåŠ¨æ£€æµ‹
            query = sample.get("query", "")
            language = detect_language(query)
        
        # ç§»é™¤[Reranker: Enabled]æ–‡æœ¬
        cleaned_answer = process_answer(original_answer)
        
        # é‡æ–°è®¡ç®—F1å’ŒEMåˆ†æ•° - æ ¹æ®è¯­è¨€é€‰æ‹©è®¡ç®—æ–¹æ³•
        f1_score = calculate_f1_score(cleaned_answer, expected_answer, language)
        exact_match = calculate_exact_match(cleaned_answer, expected_answer, language)
        
        # åˆ›å»ºå¤„ç†åçš„æ ·æœ¬
        processed_sample = {
            "sample_id": sample.get("sample_id", 0),
            "query": sample.get("query", ""),
            "summary_context": sample.get("summary_context", ""),
            "answer": cleaned_answer,
            "expected_answer": expected_answer,
            "f1": f1_score,
            "em": exact_match,
            "processing_time": sample.get("processing_time", 0.0),
            "generation_time": sample.get("generation_time", 0.0),
            "token_count": sample.get("token_count", 0),
            "success": sample.get("success", True),
            "language": language,
            "auto_stock_prediction": sample.get("auto_stock_prediction", False)
        }
        
        processed_samples.append(processed_sample)
    
    print(f"âœ… å¤„ç†å®Œæˆ: {len(processed_samples)} ä¸ªæ ·æœ¬")
    return processed_samples

def combine_all_batches(data_dir: str) -> Dict[str, Any]:
    """
    åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶
    """
    print(f"ğŸš€ å¼€å§‹åˆå¹¶ç›®å½•: {data_dir}")
    
    if not os.path.exists(data_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return {}
    
    # è·å–æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶
    batch_files = []
    for file in os.listdir(data_dir):
        if file.startswith('batch_') and file.endswith('.json'):
            batch_files.append(os.path.join(data_dir, file))
    
    batch_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(batch_files)} ä¸ªæ‰¹æ¬¡æ–‡ä»¶")
    
    # åˆå¹¶æ‰€æœ‰æ ·æœ¬
    all_samples = []
    total_processing_time = 0.0
    total_generation_time = 0.0
    total_token_count = 0
    successful_samples = 0
    failed_samples = 0
    stock_prediction_samples = 0
    
    for file_path in batch_files:
        samples = load_and_process_batch(file_path)
        all_samples.extend(samples)
        
        # ç´¯è®¡ç»Ÿè®¡
        for sample in samples:
            total_processing_time += sample.get("processing_time", 0.0)
            total_generation_time += sample.get("generation_time", 0.0)
            total_token_count += sample.get("token_count", 0)
            
            if sample.get("success", True):
                successful_samples += 1
            else:
                failed_samples += 1
            
            if sample.get("auto_stock_prediction", False):
                stock_prediction_samples += 1
    
    # è®¡ç®—æ•´ä½“æŒ‡æ ‡
    if all_samples:
        # æŒ‰è¯­è¨€åˆ†ç»„è®¡ç®—
        chinese_samples = [s for s in all_samples if s.get("language") == "chinese"]
        english_samples = [s for s in all_samples if s.get("language") == "english"]
        
        # æ€»ä½“æŒ‡æ ‡
        overall_f1 = sum(s.get("f1", 0.0) for s in all_samples) / len(all_samples)
        overall_em = sum(s.get("em", 0.0) for s in all_samples) / len(all_samples)
        
        # ä¸­æ–‡æ ·æœ¬æŒ‡æ ‡
        chinese_f1 = 0.0
        chinese_em = 0.0
        if chinese_samples:
            chinese_f1 = sum(s.get("f1", 0.0) for s in chinese_samples) / len(chinese_samples)
            chinese_em = sum(s.get("em", 0.0) for s in chinese_samples) / len(chinese_samples)
        
        # è‹±æ–‡æ ·æœ¬æŒ‡æ ‡
        english_f1 = 0.0
        english_em = 0.0
        if english_samples:
            english_f1 = sum(s.get("f1", 0.0) for s in english_samples) / len(english_samples)
            english_em = sum(s.get("em", 0.0) for s in english_samples) / len(english_samples)
        
        result = {
            "timestamp": "2025-07-14 00:00:00",  # ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
            "total_samples": len(all_samples),
            "successful_samples": successful_samples,
            "failed_samples": failed_samples,
            "stock_prediction_samples": stock_prediction_samples,
            "overall_metrics": {
                "f1_score": overall_f1,
                "exact_match": overall_em
            },
            "chinese_metrics": {
                "sample_count": len(chinese_samples),
                "f1_score": chinese_f1,
                "exact_match": chinese_em
            },
            "english_metrics": {
                "sample_count": len(english_samples),
                "f1_score": english_f1,
                "exact_match": english_em
            },
            "performance_metrics": {
                "total_processing_time": total_processing_time,
                "total_generation_time": total_generation_time,
                "total_token_count": total_token_count,
                "avg_processing_time": total_processing_time / len(all_samples) if all_samples else 0.0,
                "avg_generation_time": total_generation_time / len(all_samples) if all_samples else 0.0,
                "avg_token_count": total_token_count / len(all_samples) if all_samples else 0.0
            },
            "data": all_samples
        }
    else:
        result = {
            "timestamp": "",
            "total_samples": 0,
            "successful_samples": 0,
            "failed_samples": 0,
            "stock_prediction_samples": 0,
            "overall_metrics": {
                "f1_score": 0.0,
                "exact_match": 0.0
            },
            "chinese_metrics": {
                "sample_count": 0,
                "f1_score": 0.0,
                "exact_match": 0.0
            },
            "english_metrics": {
                "sample_count": 0,
                "f1_score": 0.0,
                "exact_match": 0.0
            },
            "performance_metrics": {
                "total_processing_time": 0.0,
                "total_generation_time": 0.0,
                "total_token_count": 0,
                "avg_processing_time": 0.0,
                "avg_generation_time": 0.0,
                "avg_token_count": 0.0
            },
            "data": []
        }
    
    return result

def save_combined_result(result: Dict[str, Any], output_file: str):
    """ä¿å­˜åˆå¹¶ç»“æœåˆ°æ–‡ä»¶"""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def print_summary(result: Dict[str, Any]):
    """æ‰“å°ç»“æœæ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“Š è¯„ä¼°ç»“æœæ‘˜è¦")
    print("="*60)
    
    print(f"ğŸ“ˆ æ€»ä½“æŒ‡æ ‡:")
    print(f"   æ€»æ ·æœ¬æ•°: {result['total_samples']}")
    print(f"   æˆåŠŸæ ·æœ¬: {result['successful_samples']}")
    print(f"   å¤±è´¥æ ·æœ¬: {result['failed_samples']}")
    print(f"   è‚¡ç¥¨é¢„æµ‹æ ·æœ¬: {result['stock_prediction_samples']}")
    
    print(f"\nğŸ¯ æ•´ä½“æ€§èƒ½:")
    print(f"   F1åˆ†æ•°: {result['overall_metrics']['f1_score']:.4f}")
    print(f"   ç²¾ç¡®åŒ¹é…: {result['overall_metrics']['exact_match']:.4f}")
    
    print(f"\nğŸ‡¨ğŸ‡³ ä¸­æ–‡æ ·æœ¬ ({result['chinese_metrics']['sample_count']} ä¸ª):")
    print(f"   F1åˆ†æ•°: {result['chinese_metrics']['f1_score']:.4f}")
    print(f"   ç²¾ç¡®åŒ¹é…: {result['chinese_metrics']['exact_match']:.4f}")
    
    print(f"\nğŸ‡ºğŸ‡¸ è‹±æ–‡æ ·æœ¬ ({result['english_metrics']['sample_count']} ä¸ª):")
    print(f"   F1åˆ†æ•°: {result['english_metrics']['f1_score']:.4f}")
    print(f"   ç²¾ç¡®åŒ¹é…: {result['english_metrics']['exact_match']:.4f}")
    
    print(f"\nâ±ï¸ æ€§èƒ½æŒ‡æ ‡:")
    print(f"   æ€»å¤„ç†æ—¶é—´: {result['performance_metrics']['total_processing_time']:.2f}ç§’")
    print(f"   æ€»ç”Ÿæˆæ—¶é—´: {result['performance_metrics']['total_generation_time']:.2f}ç§’")
    print(f"   æ€»Tokenæ•°: {result['performance_metrics']['total_token_count']}")
    print(f"   å¹³å‡å¤„ç†æ—¶é—´: {result['performance_metrics']['avg_processing_time']:.2f}ç§’")
    print(f"   å¹³å‡ç”Ÿæˆæ—¶é—´: {result['performance_metrics']['avg_generation_time']:.2f}ç§’")
    print(f"   å¹³å‡Tokenæ•°: {result['performance_metrics']['avg_token_count']:.1f}")
    
    print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ•°æ®ç›®å½•
    data_dir = "comprehensive_evaluation_results/raw_data_alphafin_eval_samples_updated"
    
    print("ğŸš€ å¼€å§‹é‡æ–°è®¡ç®—F1å’ŒEMæŒ‡æ ‡...")
    print(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
    
    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
    result = combine_all_batches(data_dir)
    
    if result:
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = result.get("timestamp", "").replace(" ", "_").replace(":", "-")
        output_file = f"comprehensive_evaluation_results/combined_results_recalculated_{timestamp}.json"
        
        # ä¿å­˜ç»“æœ
        save_combined_result(result, output_file)
        
        # æ‰“å°æ‘˜è¦
        print_summary(result)
        
        print(f"\nâœ… é‡æ–°è®¡ç®—å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    else:
        print("âŒ å¤„ç†å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆç»“æœ")

if __name__ == "__main__":
    main() 