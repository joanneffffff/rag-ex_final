#!/usr/bin/env python3
"""
åˆ†æå‡çº§åçš„TatQAæ•°æ®
æ‰¾å‡ºæ¥è‡ªåŒä¸€æ®µè½/è¡¨æ ¼çš„é—®é¢˜ç¤ºä¾‹
"""

import json
from collections import defaultdict
from pathlib import Path

def analyze_upgraded_data():
    """åˆ†æå‡çº§åçš„æ•°æ®ï¼Œæ‰¾å‡ºç›¸å…³ç¤ºä¾‹"""
    print("=== åˆ†æå‡çº§åçš„TatQAæ•°æ® ===")
    
    # åŠ è½½å‡çº§åçš„æ•°æ®
    upgraded_eval_path = "evaluate_mrr/tatqa_eval_upgraded.jsonl"
    
    if not Path(upgraded_eval_path).exists():
        print(f"âŒ å‡çº§åçš„è¯„ä¼°æ•°æ®ä¸å­˜åœ¨: {upgraded_eval_path}")
        return
    
    # åŠ è½½æ•°æ®
    data = []
    with open(upgraded_eval_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data.append(json.loads(line))
    
    print(f"âœ… åŠ è½½äº† {len(data)} ä¸ªè¯„ä¼°æ ·æœ¬")
    
    # æŒ‰doc_idåˆ†ç»„
    doc_groups = defaultdict(list)
    for item in data:
        relevant_doc_ids = item.get('relevant_doc_ids', [])
        if relevant_doc_ids:
            # æå–åŸºç¡€doc_idï¼ˆå»æ‰chunk_idéƒ¨åˆ†ï¼‰
            base_doc_id = relevant_doc_ids[0].rsplit('_', 1)[0] if '_' in relevant_doc_ids[0] else relevant_doc_ids[0]
            doc_groups[base_doc_id].append(item)
    
    print(f"ğŸ“Š æŒ‰æ–‡æ¡£åˆ†ç»„ç»Ÿè®¡:")
    print(f"  æ€»æ–‡æ¡£æ•°: {len(doc_groups)}")
    
    # æ‰¾å‡ºåŒ…å«å¤šä¸ªé—®é¢˜çš„æ–‡æ¡£
    multi_question_docs = {doc_id: items for doc_id, items in doc_groups.items() if len(items) > 1}
    print(f"  åŒ…å«å¤šä¸ªé—®é¢˜çš„æ–‡æ¡£æ•°: {len(multi_question_docs)}")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªå¤šé—®é¢˜æ–‡æ¡£çš„ç¤ºä¾‹
    print(f"\n=== æ¥è‡ªåŒä¸€æ–‡æ¡£çš„å¤šä¸ªé—®é¢˜ç¤ºä¾‹ ===")
    
    for i, (doc_id, items) in enumerate(list(multi_question_docs.items())[:5]):
        print(f"\nğŸ“„ æ–‡æ¡£ {i+1}: {doc_id}")
        print(f"   åŒ…å« {len(items)} ä¸ªé—®é¢˜")
        
        # æŒ‰chunk_idåˆ†ç»„
        chunk_groups = defaultdict(list)
        for item in items:
            relevant_doc_ids = item.get('relevant_doc_ids', [])
            if relevant_doc_ids:
                chunk_id = relevant_doc_ids[0].rsplit('_', 1)[1] if '_' in relevant_doc_ids[0] else 'unknown'
                chunk_groups[chunk_id].append(item)
        
        # æ˜¾ç¤ºæ¯ä¸ªchunkçš„é—®é¢˜
        for chunk_id, chunk_items in chunk_groups.items():
            print(f"\n   ğŸ“ Chunk: {chunk_id}")
            print(f"   åŒ…å« {len(chunk_items)} ä¸ªé—®é¢˜:")
            
            for j, item in enumerate(chunk_items[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                print(f"     {j+1}. é—®é¢˜: {item['query'][:80]}...")
                print(f"        ç­”æ¡ˆ: {item['answer'][:50]}...")
                print(f"        ç›¸å…³æ–‡æ¡£ID: {item['relevant_doc_ids']}")
                print()
            
            if len(chunk_items) > 3:
                print(f"     ... è¿˜æœ‰ {len(chunk_items) - 3} ä¸ªé—®é¢˜")
    
    # æ‰¾å‡ºæ¥è‡ªåŒä¸€æ®µè½çš„é—®é¢˜ç¤ºä¾‹
    print(f"\n=== æ¥è‡ªåŒä¸€æ®µè½çš„é—®é¢˜ç¤ºä¾‹ ===")
    
    para_groups = defaultdict(list)
    for item in data:
        relevant_doc_ids = item.get('relevant_doc_ids', [])
        if relevant_doc_ids and 'para_' in relevant_doc_ids[0]:
            para_groups[relevant_doc_ids[0]].append(item)
    
    # æ˜¾ç¤ºåŒ…å«å¤šä¸ªé—®é¢˜çš„æ®µè½
    multi_para_questions = {para_id: items for para_id, items in para_groups.items() if len(items) > 1}
    
    for i, (para_id, items) in enumerate(list(multi_para_questions.items())[:3]):
        print(f"\nğŸ“ æ®µè½ {i+1}: {para_id}")
        print(f"   åŒ…å« {len(items)} ä¸ªé—®é¢˜:")
        
        for j, item in enumerate(items):
            print(f"     {j+1}. é—®é¢˜: {item['query'][:80]}...")
            print(f"        ç­”æ¡ˆ: {item['answer'][:50]}...")
            print(f"        ä¸Šä¸‹æ–‡: {item['context'][:100]}...")
            print()
    
    # æ‰¾å‡ºæ¥è‡ªåŒä¸€è¡¨æ ¼çš„é—®é¢˜ç¤ºä¾‹
    print(f"\n=== æ¥è‡ªåŒä¸€è¡¨æ ¼çš„é—®é¢˜ç¤ºä¾‹ ===")
    
    table_groups = defaultdict(list)
    for item in data:
        relevant_doc_ids = item.get('relevant_doc_ids', [])
        if relevant_doc_ids and 'table_' in relevant_doc_ids[0]:
            table_groups[relevant_doc_ids[0]].append(item)
    
    # æ˜¾ç¤ºåŒ…å«å¤šä¸ªé—®é¢˜çš„è¡¨æ ¼
    multi_table_questions = {table_id: items for table_id, items in table_groups.items() if len(items) > 1}
    
    for i, (table_id, items) in enumerate(list(multi_table_questions.items())[:3]):
        print(f"\nğŸ“Š è¡¨æ ¼ {i+1}: {table_id}")
        print(f"   åŒ…å« {len(items)} ä¸ªé—®é¢˜:")
        
        for j, item in enumerate(items):
            print(f"     {j+1}. é—®é¢˜: {item['query'][:80]}...")
            print(f"        ç­”æ¡ˆ: {item['answer'][:50]}...")
            print(f"        ä¸Šä¸‹æ–‡: {item['context'][:100]}...")
            print()
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\n=== æ•°æ®ç»Ÿè®¡ ===")
    print(f"æ€»æ ·æœ¬æ•°: {len(data)}")
    print(f"åŒ…å«relevant_doc_idsçš„æ ·æœ¬æ•°: {sum(1 for item in data if item.get('relevant_doc_ids'))}")
    print(f"æ®µè½é—®é¢˜æ•°: {sum(1 for item in data if item.get('relevant_doc_ids') and 'para_' in item['relevant_doc_ids'][0])}")
    print(f"è¡¨æ ¼é—®é¢˜æ•°: {sum(1 for item in data if item.get('relevant_doc_ids') and 'table_' in item['relevant_doc_ids'][0])}")
    print(f"åŒ…å«å¤šä¸ªé—®é¢˜çš„æ®µè½æ•°: {len(multi_para_questions)}")
    print(f"åŒ…å«å¤šä¸ªé—®é¢˜çš„è¡¨æ ¼æ•°: {len(multi_table_questions)}")

def show_specific_examples():
    """æ˜¾ç¤ºç‰¹å®šçš„ç¤ºä¾‹æ•°æ®"""
    print(f"\n=== ç‰¹å®šç¤ºä¾‹æ•°æ® ===")
    
    # åŠ è½½æ•°æ®
    upgraded_eval_path = "evaluate_mrr/tatqa_eval_upgraded.jsonl"
    data = []
    with open(upgraded_eval_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data.append(json.loads(line))
    
    # æ‰¾å‡ºä¸€ä¸ªåŒ…å«å¤šä¸ªé—®é¢˜çš„æ®µè½ç¤ºä¾‹
    para_groups = defaultdict(list)
    for item in data:
        relevant_doc_ids = item.get('relevant_doc_ids', [])
        if relevant_doc_ids and 'para_' in relevant_doc_ids[0]:
            para_groups[relevant_doc_ids[0]].append(item)
    
    # æ‰¾å‡ºåŒ…å«æœ€å¤šé—®é¢˜çš„æ®µè½
    max_para = max(para_groups.items(), key=lambda x: len(x[1])) if para_groups else None
    
    if max_para:
        para_id, items = max_para
        print(f"\nğŸ¯ åŒ…å«æœ€å¤šé—®é¢˜çš„æ®µè½: {para_id}")
        print(f"   åŒ…å« {len(items)} ä¸ªé—®é¢˜")
        print(f"   ä¸Šä¸‹æ–‡: {items[0]['context'][:200]}...")
        print()
        
        for i, item in enumerate(items):
            print(f"   é—®é¢˜ {i+1}:")
            print(f"     æŸ¥è¯¢: {item['query']}")
            print(f"     ç­”æ¡ˆ: {item['answer']}")
            print(f"     ç›¸å…³æ–‡æ¡£ID: {item['relevant_doc_ids']}")
            print()
    
    # æ‰¾å‡ºä¸€ä¸ªåŒ…å«å¤šä¸ªé—®é¢˜çš„è¡¨æ ¼ç¤ºä¾‹
    table_groups = defaultdict(list)
    for item in data:
        relevant_doc_ids = item.get('relevant_doc_ids', [])
        if relevant_doc_ids and 'table_' in relevant_doc_ids[0]:
            table_groups[relevant_doc_ids[0]].append(item)
    
    # æ‰¾å‡ºåŒ…å«æœ€å¤šé—®é¢˜çš„è¡¨æ ¼
    max_table = max(table_groups.items(), key=lambda x: len(x[1])) if table_groups else None
    
    if max_table:
        table_id, items = max_table
        print(f"\nğŸ¯ åŒ…å«æœ€å¤šé—®é¢˜çš„è¡¨æ ¼: {table_id}")
        print(f"   åŒ…å« {len(items)} ä¸ªé—®é¢˜")
        print(f"   ä¸Šä¸‹æ–‡: {items[0]['context'][:200]}...")
        print()
        
        for i, item in enumerate(items):
            print(f"   é—®é¢˜ {i+1}:")
            print(f"     æŸ¥è¯¢: {item['query']}")
            print(f"     ç­”æ¡ˆ: {item['answer']}")
            print(f"     ç›¸å…³æ–‡æ¡£ID: {item['relevant_doc_ids']}")
            print()

def main():
    """ä¸»å‡½æ•°"""
    print("=== TatQAå‡çº§æ•°æ®åˆ†æå·¥å…· ===")
    print("åˆ†ææ¥è‡ªåŒä¸€æ®µè½/è¡¨æ ¼çš„é—®é¢˜ç¤ºä¾‹")
    print()
    
    # 1. åˆ†æå‡çº§åçš„æ•°æ®
    analyze_upgraded_data()
    
    # 2. æ˜¾ç¤ºç‰¹å®šç¤ºä¾‹
    show_specific_examples()
    
    print(f"\n" + "="*50)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("\næ€»ç»“ï¼š")
    print("1. å‡çº§åçš„æ•°æ®æˆåŠŸæ·»åŠ äº†relevant_doc_idså­—æ®µ")
    print("2. å¯ä»¥æ¸…æ¥šåœ°è¯†åˆ«æ¥è‡ªåŒä¸€æ®µè½æˆ–è¡¨æ ¼çš„å¤šä¸ªé—®é¢˜")
    print("3. è¿™ç¡®ä¿äº†è¯„ä¼°æ—¶èƒ½å¤Ÿè¿›è¡Œä¸¥æ ¼çš„doc_idåŒ¹é…")
    print("4. é¿å…äº†å› æ¨¡ç³ŠåŒ¹é…å¯¼è‡´çš„é«˜ä¼°é—®é¢˜")

if __name__ == "__main__":
    main() 