#!/usr/bin/env python3
"""
ç­›é€‰è¯„ä¼°æ ·æœ¬è„šæœ¬ V2
åˆ é™¤æ‰€æœ‰ä»¥"è¿™ä¸ªè‚¡ç¥¨çš„ä¸‹æœˆæœ€ç»ˆæ”¶ç›Šç»“æœæ˜¯"å¼€å¤´çš„ç­”æ¡ˆ
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Any

def filter_eval_samples_v2(input_file: str, output_file: str, target_samples: int = 100):
    """
    ç­›é€‰è¯„ä¼°æ ·æœ¬ V2
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        target_samples: ç›®æ ‡æ ·æœ¬æ•°é‡
    """
    filtered_samples = []
    excluded_count = 0
    
    # å®šä¹‰è¦æ’é™¤çš„æ¨¡å¼
    exclude_pattern = r"^è¿™ä¸ªè‚¡ç¥¨çš„ä¸‹æœˆæœ€ç»ˆæ”¶ç›Šç»“æœæ˜¯"
    
    print(f"ğŸ” å¼€å§‹ç­›é€‰æ ·æœ¬...")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"ğŸ¯ ç­›é€‰æ¡ä»¶: æ’é™¤ä»¥'è¿™ä¸ªè‚¡ç¥¨çš„ä¸‹æœˆæœ€ç»ˆæ”¶ç›Šç»“æœæ˜¯'å¼€å¤´çš„ç­”æ¡ˆ")
    print(f"ğŸ“Š ç›®æ ‡æ ·æœ¬æ•°: {target_samples}")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                sample = json.loads(line.strip())
                answer = sample.get("answer", "").strip()
                
                # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦åŒ…å«æŒ‡å®šæ¨¡å¼
                if "è¿™ä¸ªè‚¡ç¥¨çš„ä¸‹æœˆæœ€ç»ˆæ”¶ç›Šç»“æœæ˜¯" in answer:
                    excluded_count += 1
                    if excluded_count <= 10:  # åªæ˜¾ç¤ºå‰10ä¸ªè¢«æ’é™¤çš„æ ·æœ¬
                        print(f"âŒ æ’é™¤æ ·æœ¬ {line_num}: {answer[:50]}...")
                    elif excluded_count == 11:
                        print(f"âŒ ... (è¿˜æœ‰æ›´å¤šè¢«æ’é™¤çš„æ ·æœ¬)")
                    continue
                
                # ä¿ç•™ç¬¦åˆæ¡ä»¶çš„æ ·æœ¬
                filtered_samples.append(sample)
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡æ•°é‡
                if len(filtered_samples) >= target_samples:
                    break
                    
            except json.JSONDecodeError as e:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆJSONè¡Œ {line_num}: {e}")
                continue
            except Exception as e:
                print(f"âš ï¸ å¤„ç†è¡Œ {line_num} æ—¶å‡ºé”™: {e}")
                continue
    
    # ä¿å­˜ç­›é€‰åçš„æ ·æœ¬
    with open(output_file, 'w', encoding='utf-8') as f:
        for sample in filtered_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    print(f"\nğŸ“Š ç­›é€‰ç»“æœ:")
    print(f"âœ… ä¿ç•™æ ·æœ¬æ•°: {len(filtered_samples)}")
    print(f"âŒ æ’é™¤æ ·æœ¬æ•°: {excluded_count}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    if filtered_samples:
        print(f"\nğŸ“ˆ æ ·æœ¬ç»Ÿè®¡:")
        print(f"   - æ— instructionæ ·æœ¬: {sum(1 for s in filtered_samples if not s.get('instruction', '').strip())}")
        print(f"   - æœ‰instructionæ ·æœ¬: {sum(1 for s in filtered_samples if s.get('instruction', '').strip())}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªæ ·æœ¬çš„ç­”æ¡ˆå¼€å¤´
        print(f"\nğŸ” å‰5ä¸ªæ ·æœ¬çš„ç­”æ¡ˆå¼€å¤´:")
        for i, sample in enumerate(filtered_samples[:5]):
            answer = sample.get("answer", "")[:100]
            print(f"   {i+1}. {answer}...")
    
    if len(filtered_samples) < target_samples:
        print(f"âš ï¸ è­¦å‘Š: åªæ‰¾åˆ° {len(filtered_samples)} ä¸ªç¬¦åˆæ¡ä»¶çš„æ ·æœ¬ï¼Œå°‘äºç›®æ ‡æ•°é‡ {target_samples}")

if __name__ == "__main__":
    input_file = "evaluate_mrr/alphafin_eval.jsonl"
    output_file = "data/alphafin/alphafin_eval_clean.jsonl"
    target_samples = 100
    
    print("ğŸš€ å¼€å§‹åˆ›å»ºæ–°çš„è¯„ä¼°æ•°æ®é›†...")
    filter_eval_samples_v2(input_file, output_file, target_samples)
    print("âœ… æ–°è¯„ä¼°æ•°æ®é›†åˆ›å»ºå®Œæˆï¼") 