#!/usr/bin/env python3
"""
æµ‹è¯•è‹±æ–‡æŸ¥è¯¢å¾—åˆ°ä¸­æ–‡å“åº”çš„é—®é¢˜
"""

import sys
import os
from pathlib import Path

# Add parent directory to path
sys.path.append(str(Path(__file__).parent))

def test_english_prompt_issue():
    """æµ‹è¯•è‹±æ–‡ Prompt é—®é¢˜"""
    
    print("=== è‹±æ–‡æŸ¥è¯¢å“åº”è¯­è¨€é—®é¢˜æµ‹è¯• ===")
    print("=" * 60)
    
    try:
        from xlm.components.generator.local_llm_generator import LocalLLMGenerator
        from xlm.components.prompt_templates.template_loader import template_loader
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        print("1. åˆå§‹åŒ– LLM ç”Ÿæˆå™¨...")
        generator = LocalLLMGenerator()
        print(f"âœ… ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ: {generator.model_name}")
        
        # æµ‹è¯•æ•°æ®
        test_context = """
        Apple Inc. reported Q3 2023 revenue of $81.8 billion, down 1.4% year-over-year. 
        iPhone sales increased 2.8% to $39.7 billion. The company's services revenue 
        grew 8.2% to $21.2 billion, while Mac and iPad sales declined.
        """
        
        test_query = "How did Apple perform in Q3 2023?"
        
        # æµ‹è¯•ä¸åŒçš„ Prompt æ¨¡æ¿
        prompt_templates = {
            "è‹±æ–‡æ¨¡æ¿": "rag_english_template",
            "å¤šé˜¶æ®µè‹±æ–‡æ¨¡æ¿": "multi_stage_english_template"
        }
        
        for template_name, template_key in prompt_templates.items():
            print(f"\n2. æµ‹è¯• {template_name}...")
            
            # ç”Ÿæˆ Prompt
            if template_key == "rag_english_template":
                prompt = template_loader.format_template(
                    template_key,
                    context=test_context,
                    question=test_query
                )
            else:
                prompt = template_loader.format_template(
                    template_key,
                    context=test_context,
                    query=test_query
                )
            
            if prompt is None:
                print(f"âŒ {template_name} æ¨¡æ¿åŠ è½½å¤±è´¥")
                continue
                
            print(f"âœ… Prompt ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(prompt)} å­—ç¬¦")
            print(f"âœ… Prompt é¢„è§ˆ:\n{prompt[:300]}...")
            
            # æ£€æŸ¥æ ¼å¼è½¬æ¢
            print(f"\n3. æ£€æŸ¥æ ¼å¼è½¬æ¢...")
            if "Fin-R1" in generator.model_name:
                print("ğŸ” æ£€æµ‹åˆ° Fin-R1 æ¨¡å‹ï¼Œæ£€æŸ¥æ ¼å¼è½¬æ¢...")
                
                # æ£€æŸ¥æ˜¯å¦ä¼šè¿›è¡Œæ ¼å¼è½¬æ¢
                json_chat = generator.convert_to_json_chat_format(prompt)
                print(f"JSON æ ¼å¼è½¬æ¢ç»“æœ: {'ä¼šè½¬æ¢' if json_chat != prompt else 'ä¸ä¼šè½¬æ¢'}")
                
                if json_chat != prompt:
                    print(f"è½¬æ¢åçš„ JSON æ ¼å¼: {json_chat[:200]}...")
                    
                    # è½¬æ¢ä¸º Fin-R1 æ ¼å¼
                    fin_r1_format = generator.convert_json_to_fin_r1_format(json_chat)
                    print(f"Fin-R1 æ ¼å¼é¢„è§ˆ: {fin_r1_format[:300]}...")
                else:
                    print("âš ï¸ è‹±æ–‡ Prompt ä¸ä¼šè¿›è¡Œæ ¼å¼è½¬æ¢ï¼Œå¯èƒ½å½±å“ Fin-R1 æ¨¡å‹ç†è§£")
            
            # ç”Ÿæˆå“åº”
            print(f"\n4. ç”Ÿæˆå“åº”...")
            print("ğŸš€ å¼€å§‹ç”Ÿæˆï¼Œè¯·ç¨å€™...")
            
            responses = generator.generate([prompt])
            response = responses[0] if responses else "ç”Ÿæˆå¤±è´¥"
            
            print(f"\n5. ç”Ÿæˆç»“æœ:")
            print("=" * 60)
            print(f"é—®é¢˜: {test_query}")
            print(f"ç­”æ¡ˆ: {response}")
            print("=" * 60)
            
            # åˆ†æå“åº”è¯­è¨€
            print(f"\n6. è¯­è¨€åˆ†æ:")
            
            # æ£€æµ‹å“åº”è¯­è¨€
            try:
                from langdetect import detect
                response_lang = detect(response)
                print(f"   å“åº”è¯­è¨€: {response_lang}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
                has_chinese = any('\u4e00' <= char <= '\u9fff' for char in response)
                print(f"   åŒ…å«ä¸­æ–‡å­—ç¬¦: {'æ˜¯' if has_chinese else 'å¦'}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡å­—ç¬¦
                has_english = any(char.isalpha() and ord(char) < 128 for char in response)
                print(f"   åŒ…å«è‹±æ–‡å­—ç¬¦: {'æ˜¯' if has_english else 'å¦'}")
                
                # åˆ¤æ–­è¯­è¨€ä¸€è‡´æ€§
                if response_lang.startswith('en') and not has_chinese:
                    print("   âœ… è¯­è¨€ä¸€è‡´ï¼šè‹±æ–‡æŸ¥è¯¢å¾—åˆ°è‹±æ–‡å“åº”")
                elif response_lang.startswith('zh') and not has_english:
                    print("   âœ… è¯­è¨€ä¸€è‡´ï¼šä¸­æ–‡æŸ¥è¯¢å¾—åˆ°ä¸­æ–‡å“åº”")
                else:
                    print("   âŒ è¯­è¨€ä¸ä¸€è‡´ï¼šæŸ¥è¯¢å’Œå“åº”è¯­è¨€ä¸åŒ¹é…")
                    
            except Exception as e:
                print(f"   è¯­è¨€æ£€æµ‹å¤±è´¥: {e}")
            
            # æ£€æŸ¥å“åº”è´¨é‡
            print(f"\n7. å“åº”è´¨é‡:")
            length = len(response.strip())
            print(f"   å“åº”é•¿åº¦: {length} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯
            key_terms = ["Apple", "revenue", "billion", "iPhone", "sales"]
            found_terms = [term for term in key_terms if term.lower() in response.lower()]
            print(f"   å…³é”®ä¿¡æ¯: {found_terms}")
            print(f"   å‡†ç¡®æ€§: {'âœ…' if len(found_terms) >= 3 else 'âŒ'} (æ‰¾åˆ°{len(found_terms)}ä¸ªå…³é”®è¯)")
            
            # æ£€æŸ¥æ ¼å¼æ ‡è®°
            unwanted_patterns = ["ã€", "ã€‘", "å›ç­”ï¼š", "Answer:", "---", "===", "___"]
            has_unwanted = any(pattern in response for pattern in unwanted_patterns)
            print(f"   çº¯ç²¹æ€§: {'âœ…' if not has_unwanted else 'âŒ'} (æ— æ ¼å¼æ ‡è®°)")
            
            print("-" * 60)
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_fin_r1_format_conversion():
    """æµ‹è¯• Fin-R1 æ ¼å¼è½¬æ¢é€»è¾‘"""
    
    print("\n=== Fin-R1 æ ¼å¼è½¬æ¢æµ‹è¯• ===")
    print("=" * 60)
    
    try:
        from xlm.components.generator.local_llm_generator import LocalLLMGenerator
        
        generator = LocalLLMGenerator()
        
        # æµ‹è¯•ä¸åŒçš„ Prompt å†…å®¹
        test_cases = [
            {
                "name": "ä¸­æ–‡ Prompt",
                "content": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

æ‘˜è¦ï¼šå¾·èµ›ç”µæ± 2021å¹´ä¸šç»©å¢é•¿ä¸»è¦å—ç›ŠäºiPhoneéœ€æ±‚å¼ºåŠ²ã€‚

è¯¦ç»†å†…å®¹ï¼šå¾·èµ›ç”µæ± 2021å¹´ä¸šç»©é¢„å‘Šæ˜¾ç¤ºï¼Œå…¬å¸é¢„è®¡å®ç°å‡€åˆ©æ¶¦ä¸º6.5äº¿å…ƒè‡³7.5äº¿å…ƒã€‚

é—®é¢˜ï¼šå¾·èµ›ç”µæ± 2021å¹´åˆ©æ¶¦å¢é•¿çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ

å›ç­”ï¼š"""
            },
            {
                "name": "è‹±æ–‡ Prompt",
                "content": """You are a financial analyst. Please answer the following question based on the provided information:

Summary: Apple Inc. reported Q3 2023 revenue of $81.8 billion.

Details: Apple's iPhone sales increased 2.8% to $39.7 billion.

Question: How did Apple perform in Q3 2023?

Answer:"""
            },
            {
                "name": "è‹±æ–‡æ¨¡æ¿ Prompt",
                "content": """You are a highly analytical and precise financial expert. Your task is to answer the user's question **strictly based on the provided context information**.

**CRITICAL: Your output must be a pure, direct answer. Do NOT include any self-reflection, thinking process, prompt analysis, irrelevant comments, format markers (like boxed, numbered lists, bold text), or any form of meta-commentary. Do NOT quote or restate the prompt content. Your answer must end directly and concisely without any follow-up explanations.**

Requirements:
1.  **Strictly adhere to the provided context. Do not use any external knowledge or make assumptions.**
2.  If the context does not contain sufficient information to answer the question, state: "The answer cannot be found in the provided context."
3.  For questions involving financial predictions or future outlook, prioritize information explicitly stated as forecasts or outlooks within the context.
4.  Provide a concise and direct answer in complete sentences.
5.  Do not repeat the question or add conversational fillers.

Context:
Apple Inc. reported Q3 2023 revenue of $81.8 billion, down 1.4% year-over-year.

Question: How did Apple perform in Q3 2023?

"""
            }
        ]
        
        for test_case in test_cases:
            print(f"\næµ‹è¯•: {test_case['name']}")
            print("-" * 40)
            
            content = test_case['content']
            print(f"åŸå§‹å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            print(f"åŒ…å«ä¸­æ–‡å…³é”®è¯: {'æ˜¯' if 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆ' in content else 'å¦'}")
            
            # æµ‹è¯•æ ¼å¼è½¬æ¢
            json_chat = generator.convert_to_json_chat_format(content)
            will_convert = json_chat != content
            
            print(f"ä¼šè¿›è¡Œæ ¼å¼è½¬æ¢: {'æ˜¯' if will_convert else 'å¦'}")
            
            if will_convert:
                print(f"è½¬æ¢åé•¿åº¦: {len(json_chat)} å­—ç¬¦")
                fin_r1_format = generator.convert_json_to_fin_r1_format(json_chat)
                print(f"Fin-R1 æ ¼å¼é•¿åº¦: {len(fin_r1_format)} å­—ç¬¦")
                print(f"Fin-R1 æ ¼å¼é¢„è§ˆ: {fin_r1_format[:200]}...")
            else:
                print("âš ï¸ ä¸ä¼šè¿›è¡Œæ ¼å¼è½¬æ¢")
            
            print("-" * 40)
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_english_prompt_issue()
    test_fin_r1_format_conversion() 