#!/usr/bin/env python3
"""æµ‹è¯•è‹±æ–‡chunkä¿®å¤æ•ˆæœ"""

import json
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent))

def test_english_chunk_fix():
    """æµ‹è¯•è‹±æ–‡chunkä¿®å¤æ•ˆæœ"""
    print("=== æµ‹è¯•è‹±æ–‡chunkä¿®å¤æ•ˆæœ ===")
    
    try:
        from xlm.utils.optimized_data_loader import OptimizedDataLoader
        
        print("1. åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆè‹±æ–‡ï¼‰...")
        train_loader = OptimizedDataLoader(
            data_dir="data",
            max_samples=100,  # åŠ è½½100ä¸ªæ ·æœ¬
            chinese_document_level=True,
            english_chunk_level=True,
            include_eval_data=False  # ä¸åŒ…å«è¯„ä¼°æ•°æ®
        )
        
        train_english = train_loader.english_docs
        
        print(f"   âœ… è‹±æ–‡è®­ç»ƒæ•°æ®åŠ è½½æˆåŠŸ: {len(train_english)} ä¸ªchunks")
        
        # åˆ†æè®­ç»ƒæ•°æ®é•¿åº¦
        train_lengths = [len(doc.content) for doc in train_english]
        train_avg = sum(train_lengths) / len(train_lengths) if train_lengths else 0
        print(f"  è®­ç»ƒæ•°æ®å¹³å‡é•¿åº¦: {train_avg:.0f} å­—ç¬¦")
        print(f"  è®­ç»ƒæ•°æ®é•¿åº¦èŒƒå›´: {min(train_lengths)} - {max(train_lengths)} å­—ç¬¦")
        
        print("\n2. åŠ è½½åŒ…å«è¯„ä¼°æ•°æ®çš„çŸ¥è¯†åº“...")
        eval_loader = OptimizedDataLoader(
            data_dir="data",
            max_samples=100,  # åŠ è½½100ä¸ªæ ·æœ¬
            chinese_document_level=True,
            english_chunk_level=True,
            include_eval_data=True  # åŒ…å«è¯„ä¼°æ•°æ®
        )
        
        eval_english = eval_loader.english_docs
        
        print(f"   âœ… åŒ…å«è¯„ä¼°æ•°æ®çš„çŸ¥è¯†åº“åŠ è½½æˆåŠŸ: {len(eval_english)} ä¸ªchunks")
        
        # åˆ†ç¦»è®­ç»ƒæ•°æ®å’Œè¯„ä¼°æ•°æ®
        train_docs = [doc for doc in eval_english if 'eval' not in doc.metadata.source]
        eval_docs = [doc for doc in eval_english if 'eval' in doc.metadata.source]
        
        print(f"  è®­ç»ƒæ•°æ®chunks: {len(train_docs)}")
        print(f"  è¯„ä¼°æ•°æ®chunks: {len(eval_docs)}")
        
        # åˆ†æè¯„ä¼°æ•°æ®é•¿åº¦
        if eval_docs:
            eval_lengths = [len(doc.content) for doc in eval_docs]
            eval_avg = sum(eval_lengths) / len(eval_lengths)
            print(f"  è¯„ä¼°æ•°æ®å¹³å‡é•¿åº¦: {eval_avg:.0f} å­—ç¬¦")
            print(f"  è¯„ä¼°æ•°æ®é•¿åº¦èŒƒå›´: {min(eval_lengths)} - {max(eval_lengths)} å­—ç¬¦")
            
            # æ£€æŸ¥ä¸€è‡´æ€§
            length_diff = abs(train_avg - eval_avg) / train_avg
            print(f"  é•¿åº¦å·®å¼‚: {length_diff:.2%}")
            
            if length_diff < 0.3:  # å…è®¸30%çš„å·®å¼‚
                print("  âœ… è‹±æ–‡chunké•¿åº¦ä¸€è‡´æ€§è‰¯å¥½")
            else:
                print("  âŒ è‹±æ–‡chunké•¿åº¦å·®å¼‚è¾ƒå¤§")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
        print(f"\n3. ç¤ºä¾‹å¯¹æ¯”...")
        
        print(f"è®­ç»ƒæ•°æ®è‹±æ–‡ç¤ºä¾‹:")
        if train_docs:
            sample_train = train_docs[0]
            print(f"  æ¥æº: {sample_train.metadata.source}")
            print(f"  é•¿åº¦: {len(sample_train.content)} å­—ç¬¦")
            print(f"  å†…å®¹é¢„è§ˆ: {sample_train.content[:200]}...")
        
        print(f"\nè¯„ä¼°æ•°æ®è‹±æ–‡ç¤ºä¾‹:")
        if eval_docs:
            sample_eval = eval_docs[0]
            print(f"  æ¥æº: {sample_eval.metadata.source}")
            print(f"  é•¿åº¦: {len(sample_eval.content)} å­—ç¬¦")
            print(f"  å†…å®¹é¢„è§ˆ: {sample_eval.content[:200]}...")
        
        # æ£€æŸ¥chunkç­–ç•¥
        print(f"\n4. Chunkç­–ç•¥éªŒè¯...")
        
        eval_sources = set()
        for doc in eval_docs:
            eval_sources.add(doc.metadata.source)
        
        print(f"è¯„ä¼°æ•°æ®æ¥æº: {eval_sources}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰chunkåˆ†å‰²
        chunked_docs = [doc for doc in eval_docs if '_chunk_' in doc.metadata.source]
        print(f"åˆ†å‰²çš„chunks: {len(chunked_docs)}")
        
        if chunked_docs:
            print("  âœ… è‹±æ–‡è¯„ä¼°æ•°æ®æ­£ç¡®ä½¿ç”¨äº†chunkåˆ†å‰²ç­–ç•¥")
        else:
            print("  âš ï¸  è‹±æ–‡è¯„ä¼°æ•°æ®æœªè¿›è¡Œchunkåˆ†å‰²")
        
        print(f"\nğŸ‰ è‹±æ–‡chunkä¿®å¤æµ‹è¯•å®Œæˆï¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_english_chunk_fix() 