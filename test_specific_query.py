#!/usr/bin/env python3
"""æµ‹è¯•ç‰¹å®šæŸ¥è¯¢çš„æ£€ç´¢è´¨é‡"""

import json
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent))

def test_specific_query():
    """æµ‹è¯•ç‰¹å®šæŸ¥è¯¢çš„æ£€ç´¢è´¨é‡"""
    print("=== æµ‹è¯•ç‰¹å®šæŸ¥è¯¢æ£€ç´¢è´¨é‡ ===")
    
    # ç›®æ ‡æŸ¥è¯¢
    target_query = "å¾·èµ›ç”µæ± (000049)çš„ä¸‹ä¸€å­£åº¦æ”¶ç›Šé¢„æµ‹å¦‚ä½•ï¼Ÿ"
    print(f"ç›®æ ‡æŸ¥è¯¢: {target_query}")
    
    try:
        from config.parameters import Config
        from xlm.components.retriever.bilingual_retriever import BilingualRetriever
        from xlm.components.encoder.finbert import FinbertEncoder
        from xlm.utils.optimized_data_loader import OptimizedDataLoader
        
        config = Config()
        
        print("\n1. åŠ è½½ç¼–ç å™¨...")
        encoder_ch = FinbertEncoder(
            model_name="models/finetuned_alphafin_zh",
            cache_dir=config.encoder.cache_dir,
        )
        encoder_en = FinbertEncoder(
            model_name="models/finetuned_finbert_tatqa",
            cache_dir=config.encoder.cache_dir,
        )
        print("   âœ… ç¼–ç å™¨åŠ è½½æˆåŠŸ")
        
        print("\n2. åŠ è½½çŸ¥è¯†åº“ï¼ˆåŒ…å«è®­ç»ƒæ•°æ®ï¼‰...")
        data_loader = OptimizedDataLoader(
            data_dir="data",
            max_samples=-1,  # åŠ è½½æ‰€æœ‰æ•°æ®
            chinese_document_level=True,
            english_chunk_level=True,
            include_eval_data=True  # åŒ…å«è¯„ä¼°æ•°æ®
        )
        
        chinese_chunks = data_loader.chinese_docs
        english_chunks = data_loader.english_docs
        
        print(f"   âœ… çŸ¥è¯†åº“åŠ è½½æˆåŠŸ:")
        print(f"      ä¸­æ–‡æ–‡æ¡£æ•°: {len(chinese_chunks)}")
        print(f"      è‹±æ–‡æ–‡æ¡£æ•°: {len(english_chunks)}")
        
        # æ£€æŸ¥çŸ¥è¯†åº“ä¸­æ˜¯å¦æœ‰å¾·èµ›ç”µæ± ç›¸å…³çš„æ–‡æ¡£
        print(f"\n3. æœç´¢çŸ¥è¯†åº“ä¸­çš„å¾·èµ›ç”µæ± ç›¸å…³æ–‡æ¡£...")
        desay_docs = []
        for i, doc in enumerate(chinese_chunks):
            try:
                if doc.content.startswith('{'):
                    doc_data = json.loads(doc.content)
                    content = doc_data.get('context', '') + doc_data.get('content', '')
                else:
                    content = doc.content
                
                if 'å¾·èµ›ç”µæ± ' in content or '000049' in content:
                    desay_docs.append((i, doc, content))
            except:
                pass
        
        print(f"   æ‰¾åˆ° {len(desay_docs)} ä¸ªå¾·èµ›ç”µæ± ç›¸å…³æ–‡æ¡£")
        
        if desay_docs:
            print(f"   å‰3ä¸ªç›¸å…³æ–‡æ¡£:")
            for i, (idx, doc, content) in enumerate(desay_docs[:3]):
                print(f"     {i+1}. ä½ç½®{idx}: {content[:200]}...")
        
        print(f"\n4. åˆ›å»ºæ£€ç´¢å™¨...")
        retriever = BilingualRetriever(
            encoder_en=encoder_en,
            encoder_ch=encoder_ch,
            corpus_documents_en=english_chunks,
            corpus_documents_ch=chinese_chunks,
            use_faiss=True,
            use_gpu=False,
            batch_size=8,
            cache_dir=config.encoder.cache_dir
        )
        print("   âœ… æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
        
        print(f"\n5. æµ‹è¯•ä¸åŒæ£€ç´¢å‚æ•°...")
        
        # æµ‹è¯•ä¸åŒçš„top_kå€¼
        top_k_values = [5, 10, 20, 50, 100]
        
        for top_k in top_k_values:
            print(f"\n--- æµ‹è¯• top_k={top_k} ---")
            
            # æ£€ç´¢
            retrieved_result = retriever.retrieve(
                text=target_query, 
                top_k=top_k, 
                return_scores=True, 
                language='zh'
            )
            
            if isinstance(retrieved_result, tuple):
                retrieved_docs, scores = retrieved_result
            else:
                retrieved_docs = retrieved_result
                scores = []
            
            print(f"   æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªæ–‡æ¡£")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¾·èµ›ç”µæ± ç›¸å…³æ–‡æ¡£
            desay_found = False
            desay_rank = 0
            
            for rank, doc in enumerate(retrieved_docs, 1):
                try:
                    if doc.content.startswith('{'):
                        doc_data = json.loads(doc.content)
                        content = doc_data.get('context', '') + doc_data.get('content', '')
                    else:
                        content = doc.content
                    
                    if 'å¾·èµ›ç”µæ± ' in content or '000049' in content:
                        desay_found = True
                        desay_rank = rank
                        score_info = f" (åˆ†æ•°: {scores[rank-1]:.4f})" if scores and rank <= len(scores) else ""
                        print(f"   âœ… åœ¨ç¬¬{rank}ä½æ‰¾åˆ°å¾·èµ›ç”µæ± ç›¸å…³æ–‡æ¡£{score_info}")
                        print(f"      å†…å®¹: {content[:200]}...")
                        break
                except:
                    pass
            
            if not desay_found:
                print(f"   âŒ æœªæ‰¾åˆ°å¾·èµ›ç”µæ± ç›¸å…³æ–‡æ¡£")
                
                # æ˜¾ç¤ºå‰3ä¸ªæ£€ç´¢ç»“æœ
                print(f"   å‰3ä¸ªæ£€ç´¢ç»“æœ:")
                for i, doc in enumerate(retrieved_docs[:3]):
                    try:
                        if doc.content.startswith('{'):
                            doc_data = json.loads(doc.content)
                            content = doc_data.get('context', '') + doc_data.get('content', '')
                        else:
                            content = doc.content
                        
                        score_info = f" (åˆ†æ•°: {scores[i]:.4f})" if scores and i < len(scores) else ""
                        print(f"     {i+1}. {content[:100]}...{score_info}")
                    except:
                        print(f"     {i+1}. [è§£æå¤±è´¥] {doc.content[:100]}...")
        
        print(f"\n6. å°è¯•æ”¹è¿›æ£€ç´¢è´¨é‡...")
        
        # å°è¯•ä¸åŒçš„æŸ¥è¯¢å˜ä½“
        query_variants = [
            "å¾·èµ›ç”µæ± (000049)çš„ä¸‹ä¸€å­£åº¦æ”¶ç›Šé¢„æµ‹å¦‚ä½•ï¼Ÿ",
            "å¾·èµ›ç”µæ±  000049 ä¸‹ä¸€å­£åº¦æ”¶ç›Šé¢„æµ‹",
            "å¾·èµ›ç”µæ± æ”¶ç›Šé¢„æµ‹",
            "000049 æ”¶ç›Šé¢„æµ‹",
            "å¾·èµ›ç”µæ± (000049)ä¸šç»©é¢„æµ‹"
        ]
        
        print(f"   æµ‹è¯•ä¸åŒæŸ¥è¯¢å˜ä½“...")
        
        for i, query in enumerate(query_variants):
            print(f"\n   å˜ä½“ {i+1}: {query}")
            
            retrieved_result = retriever.retrieve(
                text=query, 
                top_k=20, 
                return_scores=True, 
                language='zh'
            )
            
            if isinstance(retrieved_result, tuple):
                retrieved_docs, scores = retrieved_result
            else:
                retrieved_docs = retrieved_result
                scores = []
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¾·èµ›ç”µæ± ç›¸å…³æ–‡æ¡£
            desay_found = False
            for rank, doc in enumerate(retrieved_docs, 1):
                try:
                    if doc.content.startswith('{'):
                        doc_data = json.loads(doc.content)
                        content = doc_data.get('context', '') + doc_data.get('content', '')
                    else:
                        content = doc.content
                    
                    if 'å¾·èµ›ç”µæ± ' in content or '000049' in content:
                        desay_found = True
                        score_info = f" (åˆ†æ•°: {scores[rank-1]:.4f})" if scores and rank <= len(scores) else ""
                        print(f"     âœ… åœ¨ç¬¬{rank}ä½æ‰¾åˆ°{score_info}")
                        break
                except:
                    pass
            
            if not desay_found:
                print(f"     âŒ æœªæ‰¾åˆ°")
        
        print(f"\n7. åˆ†æç»“æœ...")
        
        if desay_docs:
            print(f"   âœ… çŸ¥è¯†åº“ä¸­åŒ…å«å¾·èµ›ç”µæ± ç›¸å…³æ–‡æ¡£")
            print(f"   ğŸ’¡ å»ºè®®:")
            print(f"     1. å¢åŠ top_kå€¼ä»¥æé«˜å¬å›ç‡")
            print(f"     2. å°è¯•ä¸åŒçš„æŸ¥è¯¢å˜ä½“")
            print(f"     3. æ£€æŸ¥ç¼–ç å™¨æ˜¯å¦é’ˆå¯¹è¿™ç±»æŸ¥è¯¢è¿›è¡Œäº†ä¼˜åŒ–")
            print(f"     4. è€ƒè™‘ä½¿ç”¨é‡æ’åºå™¨æé«˜ç²¾åº¦")
        else:
            print(f"   âŒ çŸ¥è¯†åº“ä¸­ä¸åŒ…å«å¾·èµ›ç”µæ± ç›¸å…³æ–‡æ¡£")
            print(f"   ğŸ’¡ å»ºè®®:")
            print(f"     1. æ£€æŸ¥è®­ç»ƒæ•°æ®æ˜¯å¦åŒ…å«å¾·èµ›ç”µæ± ç›¸å…³ä¿¡æ¯")
            print(f"     2. è€ƒè™‘æ‰©å……çŸ¥è¯†åº“")
            print(f"     3. æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦é—æ¼äº†ç›¸å…³å†…å®¹")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_specific_query() 