#!/usr/bin/env python3
"""
åˆ†æç­›é€‰åçš„è¯„ä¼°æ ·æœ¬
æä¾›è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
"""

import json
import re
from collections import Counter
from pathlib import Path

def analyze_filtered_samples(file_path: str):
    """åˆ†æç­›é€‰åçš„æ ·æœ¬"""
    
    samples = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            samples.append(json.loads(line.strip()))
    
    print(f"ğŸ“Š æ ·æœ¬åˆ†ææŠ¥å‘Š")
    print(f"ğŸ“ æ–‡ä»¶: {file_path}")
    print(f"ğŸ“ˆ æ€»æ ·æœ¬æ•°: {len(samples)}")
    
    # ç»Ÿè®¡instructionæƒ…å†µ
    no_instruction_count = 0
    has_instruction_count = 0
    
    # ç»Ÿè®¡answeræ¨¡å¼
    pattern_answers = []
    normal_answers = []
    
    # ç»Ÿè®¡å…¬å¸åˆ†å¸ƒ
    companies = []
    
    for sample in samples:
        instruction = sample.get("instruction", "").strip()
        answer = sample.get("answer", "")
        company = sample.get("company_name", "Unknown")
        
        # ç»Ÿè®¡instruction
        if not instruction:
            no_instruction_count += 1
        else:
            has_instruction_count += 1
        
        # ç»Ÿè®¡answeræ¨¡å¼
        if re.search(r"è¿™ä¸ªè‚¡ç¥¨çš„ä¸‹æœˆæœ€ç»ˆæ”¶ç›Šç»“æœæ˜¯:.*?(ä¸Šæ¶¨|ä¸‹è·Œ)æ¦‚ç‡:", answer):
            pattern_answers.append(sample)
        else:
            normal_answers.append(sample)
        
        companies.append(company)
    
    print(f"\nğŸ“‹ è¯¦ç»†ç»Ÿè®¡:")
    print(f"   - æ— instructionæ ·æœ¬: {no_instruction_count} ({no_instruction_count/len(samples)*100:.1f}%)")
    print(f"   - æœ‰instructionæ ·æœ¬: {has_instruction_count} ({has_instruction_count/len(samples)*100:.1f}%)")
    print(f"   - åŒ…å«ç‰¹å®šæ¨¡å¼answer: {len(pattern_answers)} ({len(pattern_answers)/len(samples)*100:.1f}%)")
    print(f"   - æ™®é€šanswer: {len(normal_answers)} ({len(normal_answers)/len(samples)*100:.1f}%)")
    
    # å…¬å¸åˆ†å¸ƒ
    company_counter = Counter(companies)
    print(f"\nğŸ¢ å…¬å¸åˆ†å¸ƒ (Top 10):")
    for company, count in company_counter.most_common(10):
        print(f"   - {company}: {count} æ¬¡")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    print(f"\nğŸ“ ç¤ºä¾‹æ ·æœ¬:")
    
    # æ— instructionç¤ºä¾‹
    no_instruction_examples = [s for s in samples if not s.get("instruction", "").strip()]
    if no_instruction_examples:
        print(f"\n1. æ— instructionç¤ºä¾‹:")
        sample = no_instruction_examples[0]
        print(f"   é—®é¢˜: {sample.get('question', 'N/A')}")
        print(f"   ç­”æ¡ˆ: {sample.get('answer', 'N/A')}")
        print(f"   å…¬å¸: {sample.get('company_name', 'N/A')}")
    
    # ç‰¹å®šæ¨¡å¼ç¤ºä¾‹
    if pattern_answers:
        print(f"\n2. ç‰¹å®šæ¨¡å¼answerç¤ºä¾‹:")
        sample = pattern_answers[0]
        print(f"   é—®é¢˜: {sample.get('question', 'N/A')}")
        print(f"   ç­”æ¡ˆ: {sample.get('answer', 'N/A')}")
        print(f"   Instruction: {sample.get('instruction', 'N/A')}")
        print(f"   å…¬å¸: {sample.get('company_name', 'N/A')}")
    
    # ä¿å­˜ç»Ÿè®¡ç»“æœ
    stats = {
        "total_samples": len(samples),
        "no_instruction_count": no_instruction_count,
        "has_instruction_count": has_instruction_count,
        "pattern_answer_count": len(pattern_answers),
        "normal_answer_count": len(normal_answers),
        "company_distribution": dict(company_counter.most_common(20))
    }
    
    stats_file = file_path.replace('.jsonl', '_stats.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {stats_file}")

if __name__ == "__main__":
    file_path = "data/alphafin/alphafin_eval_filtered.jsonl"
    analyze_filtered_samples(file_path) 