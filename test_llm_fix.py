#!/usr/bin/env python3
"""
æµ‹è¯•LLMç”Ÿæˆå™¨ä¿®å¤æ•ˆæœ
éªŒè¯è¾“å…¥æˆªæ–­å’ŒèŠå¤©æ ¼å¼é—®é¢˜æ˜¯å¦è§£å†³
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from xlm.components.generator.local_llm_generator import LocalLLMGenerator
from xlm.components.prompt_templates.prompt_template_loader import PromptTemplateLoader

def test_llm_generator_fix():
    """æµ‹è¯•LLMç”Ÿæˆå™¨ä¿®å¤æ•ˆæœ"""
    print("=" * 80)
    print("ğŸ”§ æµ‹è¯•LLMç”Ÿæˆå™¨ä¿®å¤æ•ˆæœ")
    print("=" * 80)
    
    try:
        # åˆå§‹åŒ–LLMç”Ÿæˆå™¨
        print("1. åˆå§‹åŒ–LLMç”Ÿæˆå™¨...")
        generator = LocalLLMGenerator()
        print(f"âœ… LLMç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ: {generator.model_name}")
        
        # åŠ è½½Promptæ¨¡æ¿
        print("\n2. åŠ è½½Promptæ¨¡æ¿...")
        loader = PromptTemplateLoader()
        template = loader.load_template("multi_stage_chinese_template")
        print(f"âœ… Promptæ¨¡æ¿åŠ è½½æˆåŠŸï¼Œé•¿åº¦: {len(template)} å­—ç¬¦")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        print("\n3. å‡†å¤‡æµ‹è¯•æ•°æ®...")
        context = "å¾·èµ›ç”µæ± ï¼ˆ000049ï¼‰2021å¹´ä¸šç»©é¢„å‘Šæ˜¾ç¤ºï¼Œå…¬å¸è¥æ”¶çº¦193.9äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿5%ï¼Œå‡€åˆ©æ¶¦7.07äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿45.13%ï¼Œå½’æ¯å‡€åˆ©æ¶¦6.37äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿25.5%ã€‚ä¸šç»©è¶…å‡ºé¢„æœŸä¸»è¦æºäºiPhone 12 Pro Maxéœ€æ±‚ä½³åŠç›ˆåˆ©èƒ½åŠ›æå‡ã€‚"
        query = "å¾·èµ›ç”µæ± ï¼ˆ000049ï¼‰2021å¹´åˆ©æ¶¦æŒç»­å¢é•¿çš„ä¸»è¦åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ"
        
        # æ ¼å¼åŒ–Prompt
        print("\n4. æ ¼å¼åŒ–Prompt...")
        prompt = template.format(context=context, query=query)
        print(f"âœ… Promptæ ¼å¼åŒ–å®Œæˆï¼Œé•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        # æ‰“å°Prompté¢„è§ˆ
        print("\n5. Prompté¢„è§ˆ:")
        print("-" * 50)
        print(prompt[:500] + "..." if len(prompt) > 500 else prompt)
        print("-" * 50)
        
        # è°ƒç”¨LLMç”Ÿæˆå™¨
        print("\n6. è°ƒç”¨LLMç”Ÿæˆå™¨...")
        print("ğŸš€ å¼€å§‹ç”Ÿæˆç­”æ¡ˆ...")
        
        responses = generator.generate([prompt])
        response = responses[0] if responses else "ç”Ÿæˆå¤±è´¥"
        
        print("\n7. ç”Ÿæˆç»“æœ:")
        print("=" * 50)
        print("ğŸ“¤ å‘é€çš„Prompté•¿åº¦:", len(prompt), "å­—ç¬¦")
        print("ğŸ“¥ ç”Ÿæˆçš„ç­”æ¡ˆ:")
        print(response)
        print("=" * 50)
        
        # åˆ†æç»“æœ
        print("\n8. ç»“æœåˆ†æ:")
        if "å¾·èµ›ç”µæ± " in response and ("iPhone" in response or "éœ€æ±‚" in response or "ç›ˆåˆ©èƒ½åŠ›" in response):
            print("âœ… ç­”æ¡ˆç›¸å…³æ€§è‰¯å¥½ - åŒ…å«å…³é”®ä¿¡æ¯")
        elif "æ ¹æ®ç°æœ‰ä¿¡æ¯ï¼Œæ— æ³•æä¾›æ­¤é¡¹ä¿¡æ¯" in response:
            print("âœ… ç­”æ¡ˆæ ¼å¼æ­£ç¡® - æ˜ç¡®è¡¨ç¤ºä¿¡æ¯ä¸è¶³")
        else:
            print("âŒ ç­”æ¡ˆå¯èƒ½æœ‰é—®é¢˜ - æœªåŒ…å«é¢„æœŸå†…å®¹")
            
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_llm_generator_fix()
    if success:
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼LLMç”Ÿæˆå™¨ä¿®å¤éªŒè¯æˆåŠŸ")
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•") 